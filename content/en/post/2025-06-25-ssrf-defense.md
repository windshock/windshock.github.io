---
title: "The Limitations of 'Secure' SSRF Patches: Advanced Bypasses and Defense-in-Depth"
date: 2025-06-25
categories: [Web Security, SSRF]
tags: [ssrf, security, defense, web]
description: "A deep dive into why common SSRF defense code is often incomplete, real-world bypasses, and practical, layered mitigation strategies for developers and security engineers."
image: "/images/nosilverbullet.webp"
---

> **No Silver Bullet: Folklore & Modern Meaning**
>
> The phrase "no silver bullet" originated in European folklore, where silver bullets were believed to be uniquely effective against supernatural creatures like werewolves or vampires. The earliest documented use appears in Walter Scott's 1816 _Tales of My Landlord_, and historical cases such as the 1765 Beast of GÃ©vaudan reference silver bullets as a last resort against mysterious threats. Over time, the expression evolved: today, "no silver bullet" means there is no single, simple solution to complex problemsâ€”a message popularized in software engineering by Fred Brooks' 1986 essay. This post applies that lesson to SSRF defense: beware of one-size-fits-all fixes, and look deeper than folklore or quick patches.


# The Limitations of â€œSecureâ€ SSRF Patches: Advanced Bypasses and Defense-in-Depth

## Introduction: Understanding SSRF and Its Risks

Server-Side Request Forgery (SSRF) is a web vulnerability that allows an attacker to trick a server into making HTTP requests to unintended locations. In a typical SSRF attack, the adversary supplies a URL or address that the server-side code fetches â€“ but instead of fetching an expected external resource, the server is coerced into contacting internal services or protected endpoints not normally accessible to the attacker. This can lead to *serious* consequences: attackers may scan internal networks, access database endpoints, or retrieve cloud instance metadata (like AWS EC2 tokens) by exploiting SSRF. Itâ€™s no surprise SSRF has earned a spot in the OWASP Top 10 (2021) and is a growing concern for developers.

> â€œJust use `startsWith('https://trusted.com')` to block SSRF!â€  
> â€” Common advice on StackOverflow (that fails in practice)

Because of its severity, many developers reach for quick patch methods to fix SSRF vulnerabilities. But as the quote above shows, well-intentioned advice often leads to incomplete or bypassable defenses. A quick search online yields plenty of code snippets and StackOverflow answers claiming to **â€œfixâ€ SSRF** by filtering URLs, enforcing domain allowlists, etc. In theory, these patches intend to restrict outgoing requests to safe targets. In practice, however, **many commonly shared SSRF fixes are incomplete**â€”they cover basic cases but **donâ€™t hold up against advanced bypass techniques**.

**In this post, youâ€™ll learn:**
- Why â€œsecureâ€ SSRF patches often fail in real-world scenarios
- How attackers bypass naive defenses with creative payloads
- How to build robust, layered SSRF defenses in Node.js (Express + Axios)
- Practical test strategies and a hands-on SSRF Defense Lab

By the end, youâ€™ll know how to spot incomplete SSRF fixes, understand advanced bypass tricks, and implement defense-in-depth that holds up under real attack. Security requires continuous testing and iterative hardeningâ€”but with the right approach, you can stay a step ahead of attackers.


## Common SSRF Patch Methods (and Why They Fall Short)

Developers under pressure to patch an SSRF bug often implement quick solutions that *seem* to work. Some of the most common SSRF mitigation patterns include:

* **Allowlisting by URL Prefix or Hostname Substring** â€“ e.g. only fetch URLs that start with a specific domain.
* **Basic Hostname Validation** â€“ e.g. parse the user-supplied URL and ensure the hostname equals an expected value.
* **Blocking Private IP Address Ranges by String** â€“ e.g. reject any URLs containing `127.0.0.1` or `localhost`.
* **Filtering Schemes** â€“ e.g. only allow `http://` or `https://` URLs, and block others (FTP, file, etc.).
* **Not Following Redirects** â€“ or so one hopes (some fixes *assume* no redirects without enforcing it).
* **Superficial Checks for Malicious Patterns** â€“ e.g. disallow `file://` in the URL, or attempts to sniff out hex/encoded IPs in the string.

On paper, these measures sound reasonable. In practice, **attackers have developed numerous tricks to evade such filters**. Letâ€™s examine a few pitfalls in naive SSRF defenses and how exploiters get around them:

### 1. NaÃ¯ve Domain Allowlisting via Prefix Matching

One common approach is to allow requests only to a specific trusted domain or base URL. The code might do something like:

```js
// âŒ Vulnerable SSRF check (naive allowlist by prefix)
if (!userUrl.startsWith(allowedBaseUrl)) {
    throw new Error("URL not allowed");
}
```

This looks straightforward â€“ if the user-provided URL doesnâ€™t begin with say, `https://trusted.example.com`, the request is blocked. **The problem**: string matching on URLs can be easily fooled by crafty URL formatting. Attackers often exploit the **`@` notation** in URLs to bypass such checks. In an HTTP URL, anything before an `@` symbol is treated as user credentials (userinfo) for authentication, and the actual host comes **after** the `@`. For example:

* **Intended safe URL:** `https://trusted.example.com/path/file.txt`
* **Malicious URL using `@`:** `https://trusted.example.com@evil.attacker-site.com/path/file.txt`

At a glance, the malicious URL *starts with* `https://trusted.example.com`, so a naive `startsWith()` check passes. However, the true hostname of this URL is `evil.attacker-site.com` (the portion after the `@`). The prefix `trusted.example.com` is simply interpreted as a username by the URL parser. As a result, the server will actually perform the request to the attackerâ€™s domain, not the trusted domain â€“ a successful SSRF bypass.

Real-world case study: The open-source **ChatGPT-Next-Web** project once implemented an SSRF fix using a prefix allowlist for certain API endpoints. It checked that user-supplied URLs began with allowed host prefixes (e.g. a list of trusted WebDAV service URLs). Security researchers discovered this was insufficient. Because the code didnâ€™t enforce a delimiter after the allowed domain, an attacker could append an allowed prefix onto a malicious domain string. For example, if `https://webdav.yandex.com` was allowed, an attacker could use `https://webdav.yandex.com.attacker.tld/evil` â€“ which passes the `.startsWith()` check but actually points to `attacker.tld`. In ChatGPT-Next-Webâ€™s case, this loophole enabled arbitrary HTTPS requests to attacker-controlled servers despite the allowlist â€œfix.â€ In short, simple prefix checks can be **trivially bypassed** by including the trusted string in a larger malicious hostname.

### 2. Shallow Hostname Validation and Subdomain Tricks

A slightly better approach is to actually parse the URL and inspect the hostname. For example, using Nodeâ€™s `url.parse()` or the WHATWG `URL` API, one might extract the hostname and compare it to an allowlist:

```js
const parsed = new URL(userUrl);
if (parsed.hostname !== "trusted.example.com") {
    throw new Error("Hostname not allowed");
}
```

This fixes the `@` issue â€“ since `parsed.hostname` of `https://trusted.example.com@evil.com` would correctly yield `evil.com`. However, developers must still be careful: *string comparison of hostnames* has its own edge cases. Consider subdomains and lookalikes. If the intention is to allow only a specific host, you should ensure **exact** match (or a well-defined pattern). Attackers can register malicious domains that include or mimic allowed names. For instance:

* Allowed host: `api.mycompany.com`
* Attacker registers: `api.mycompany.com.evil.org` (a subdomain of `evil.org`).

A check that naively does `endsWith("api.mycompany.com")` or contains that string could be fooled. Even checking for `.mycompany.com` could be tricked by a domain like `really-trusted.mycompany.com.evil.org`. The ChatGPT-Next-Web exploit above is a prime example of subdomain prefix abuse. The lesson is to **anchor your host validation** â€“ e.g., ensure the entire hostname matches an allowlist entry, or if subdomains of an allowed domain are acceptable, use strict suffix matching that accounts for dot boundaries (like `*.example.com` but not `example.com.evil.com`).

Another often-overlooked aspect is **DNS resolution**: Just because a URLâ€™s hostname looks legitimate doesnâ€™t mean it will resolve to the expected IP. In a DNS rebinding scenario, an attacker controls a domain and can manipulate its DNS responses. Your server might check `parsed.hostname` against an allowlist of, say, attackerâ€™s domain (which obviously wonâ€™t be in the allowlist). But consider if the allowlist is for *external* hosts only (to block internal IPs) â€“ an attackerâ€™s domain could resolve to a private IP after initial validation. For example, a filter might allow any hostname that resolves to a public IP, using a function like `is_external(host)`. The attackerâ€™s domain could initially resolve to a benign public IP for the check, then a second DNS query (when the request is made) returns `127.0.0.1`. If the code isnâ€™t carefully using the same resolved result, this **DNS rebinding** can route a seemingly external hostname to internal resources. Proper mitigations involve resolving the hostname to an IP **once** and validating that IP (and perhaps even forcing the request to that IP), or performing continuous checks if multiple connections occur.

Finally, watch out for **alternative IP notations**. If your code blocks explicit localhost strings or literal `127.0.0.1`, an attacker might supply `2130706433` (which is `0x7F000001` in decimal â€“ the same loopback IP in a different form) or even an IPv6 loopback `::1`. Any robust solution should normalize and validate addresses, not rely solely on string matching for IPs.

### 3. Inadequate Redirect Handling

**HTTP redirection can completely undermine SSRF filters** that donâ€™t account for it. Many HTTP client libraries (Axios, requests, etc.) follow redirects automatically by default. That means your backend might fetch a URL that responds with a 301/302 redirect, and the client will transparently fetch the new location. If your SSRF defense only checks the *initial* URL, an attacker can easily bounce the request through an intermediate site.

For example, suppose your application only allows downloading from `https://cdn.safe-files.com`. An attacker finds that `cdn.safe-files.com` (or an allowed domain) has an **open redirect** vulnerability, or they use a purpose-built redirect service like `302.r3dir.me`. The attacker crafts a URL to the allowed domain that immediately redirects to a malicious or internal address. Your code sees the allowed domain in the request URL and permits it, but then the server follows the redirect to the forbidden target. **By the time the dust settles, your server has made a call to the internal resource** â€“ SSRF success.

A practical demonstration of this uses the service **`302.r3dir.me`**, which is designed to aid SSRF testing by redirecting to a target provided in the URL query. Imagine the target is the AWS EC2 metadata URL `http://169.254.169.254/latest/meta-data/iam/security-credentials/`. An attacker could submit:

```
https://your-allowed-cdn.com@302.r3dir.me/--to/?url=http://169.254.169.254/latest/meta-data/iam/
```

This single URL incorporates both the `@` trick (to satisfy a naive prefix check) and a redirect to the internal AWS metadata service. If the server follows it, the response will be AWS credentials from the metadata! In our example test suite, a similar payload `https://cdn.example.com@302.r3dir.me/--to/?url=http://intranet.com/` was used to simulate a redirect-based bypass. Without proper safeguards, such a request would slip past an allowlist and hit the final target. Indeed, itâ€™s been noted that using `302.r3dir.me` (or a custom redirect server) can bypass poorly implemented SSRF defenses, granting access to internal networks and metadata endpoints.

To make matters worse, **scheme enforcement can be bypassed via redirects as well**. Some developers try to allow only `https://` URLs for extra safety (to avoid cleartext or other protocols). But if redirects arenâ€™t controlled, an attacker can start with an `https://` URL that later redirects to an `http://` URL. Many HTTP libraries will follow an HTTPS-to-HTTP redirect unless explicitly configured not to. As Leviathan Security researchers pointed out, this trick enables attackers to ultimately reach internal HTTP services (which many backend systems and cloud metadata endpoints use) even if the initial URL was HTTPS. Without a redirect limit, your â€œHTTPS-onlyâ€ rule might only apply to the first hop â€“ after that, all bets are off.

### 4. Other Advanced Bypass Techniques

Beyond the big three (prefix tricks, subdomain exploits, and redirects), there are other creative ways SSRF filters have been bypassed:

* **Mixed IP/Domain Formats:** Some browsers/clients allow URLs like `http://127.0.0.1.xip.io` or `http://[::ffff:127.0.0.1]`. These appear as hostnames or IPv6, but effectively point to IPv4 localhost. If a filter isnâ€™t comprehensive (e.g., only checks for â€œ127.0.0.1â€ literal), these can sneak through.
* **HTTP Headers Injection (Less Common):** In rare cases, if user input is directly concatenated into an HTTP request, an attacker might insert header delimiters to alter the request. This is more of an input parsing flaw than SSRF bypass per se, but it underscores the need to use proper libraries for requests.
* **Alternate Schemes (Gopher, File)**: Although most SSRF patches focus on HTTP/HTTPS, remember that if your request function supports other schemes, an attacker might use `file://` to read files or `gopher://` for tricky interactions. Many SSRF exploits of the past used gopher to poke at internal memcached or other services. Ensuring you **only allow the protocols you intend** is vital (and usually thatâ€™s just HTTP/HTTPS for web apps).

In summary, *many of the â€œsimpleâ€ SSRF fixes found online do not account for these edge cases*. A patch might block obvious malicious URLs but still be bypassable by an imaginative attacker. As developers, we have to think like attackers when designing validations. Next, weâ€™ll look at how to build a **more robust SSRF defense** step by step, using Node.js as an example.

## Building a Robust SSRF Defense (Node.js Example)

To truly fix SSRF, a **single check is not enough**. Youâ€™ll want to validate the request URL at multiple layers and use secure library features to avoid mistakes. Letâ€™s walk through a hardened approach using **Node.js (Express + Axios)**, incorporating the lessons from above.

Below is an example of secure coding for a file download endpoint that only allows files from a specific CDN domain. This approach uses URL parsing, an allowlist, interceptors, and strict request options to mitigate SSRF:

```js
import axios from "axios";
import { URL } from "url";
import express from "express";

const R = express.Router();
const ALLOWED_HOSTS = ["cdn.example.com"];  // Whitelisted hostname(s)

// Create an Axios instance with a short timeout
const downloader = axios.create({ timeout: 10000 });

// Attach a request interceptor to enforce URL policies
downloader.interceptors.request.use(config => {
    const u = new URL(config.url, config.baseURL);
    // Enforce HTTPS protocol and allowed hostname
    if (u.protocol !== "https:" || !ALLOWED_HOSTS.includes(u.hostname)) {
        return Promise.reject(new Error(`Blocked hostname: ${u.hostname}`));
    }
    return config;
});

R.get("/file-proxy/download", async (req, res) => {
    const url = req.query.url;
    const fname = req.query.file_name;
    if (!url || !fname) {
        return res.status(400).send("Missing parameters");
    }
    try {
        const resp = await downloader.get(url, {
            responseType: "stream",
            maxRedirects: 0,               // Disallow redirects 
            //validateStatus: status => status < 400  // Treat 3xx as success (so we catch them manually)
        });
        // Set download headers
        res.setHeader("Content-Disposition", `attachment; filename=${encodeURIComponent(fname)}`);
        res.setHeader("Content-Type", resp.headers["content-type"] || "application/octet-stream");
        // Pipe the response stream directly to the client
        resp.data.pipe(res);
    } catch (e) {
        console.error("Blocked or failed download:", e.message);
        res.status(400).send("Invalid or forbidden URL");
    }
});
```

Letâ€™s break down how this implementation counters the earlier bypass techniques:

* **URL Parsing and Host Allowlist:** We use Nodeâ€™s standard `URL` constructor to parse the requested URL (`new URL(config.url)`). This ensures we correctly identify the components of the URL. By checking `u.protocol` and `u.hostname`, we eliminate confusion around tricky formats. For example, `u.hostname` for `https://cdn.cloudfront.net@evil.com/...` will be `evil.com`, so the interceptor will reject it. We only allow hostnames explicitly listed in `ALLOWED_HOSTS`. In this case, the only allowed host is the specific CloudFront domain we trust. If an attacker tries any other host (including subdomains or lookalikes), the request is blocked before it is even sent.

* **HTTPS-Only Enforcement:** The interceptor also checks `u.protocol !== "https:"` and rejects anything that isnâ€™t HTTPS. This means no `http://` (preventing downgrade attacks) and no weird schemes like `file://` â€“ theyâ€™ll be blocked immediately. One thing to note: by itself this HTTPS check could be bypassed by an HTTPS URL that redirects to HTTP (as discussed earlier). Thatâ€™s why we also set `maxRedirects: 0` on the request â€“ to prevent *any* protocol change via redirect.

* **Disabling Redirects:** Setting `maxRedirects: 0` tells Axios **not to follow redirects** at all. If the response is a 302 or other redirect, Axios will return it directly without chasing the Location. In our code, we treat any HTTP status >= 300 as an error (by using a custom `validateStatus` that only considers <400 as okay). This way, a redirect from the allowed host to an unallowed host is caught: the allowed host responded with a redirect, but we didnâ€™t follow it â€“ instead we throw an error and return â€œInvalid URL.â€ This intercepts the scenario of using an open redirect or r3dir.me. In our test, for example, if `cdn.example.com` tried to redirect to `evil.com`, our server would *not* follow; weâ€™d catch it and respond with 400. **Note:** In some cases, you might allow a limited number of redirects but need to validate each hop â€“ that gets complicated fast. Itâ€™s safer to disallow redirects for user-supplied URLs unless absolutely necessary.

* **Centralized Enforcement via Interceptor:** By using an Axios request interceptor, we ensure the policy is applied consistently for every request made with that `downloader` instance. This is better than scattering checks around or relying on developers to always call a validation function. Itâ€™s a form of **defense-in-depth in code** â€“ even if someone forgets to do a manual check before calling `downloader.get()`, the interceptor will kick in. It also makes the code cleaner in the route handler â€“ we simply call `downloader.get(url)` and know that the interceptor will block any disallowed URL upfront.

* **Timeout and Error Handling:** While not directly an SSRF bypass issue, we set a reasonable timeout (10 seconds here) on the Axios instance to avoid hanging on slow or non-responsive endpoints. We also gracefully handle errors: any thrown error (be it from our interceptor or the request itself) results in a 400 response to the client and logs an error. The error message can indicate *why* it was blocked (e.g., â€œBlocked hostname: evil.comâ€), which can be useful in detecting attacks in logs, but be careful not to leak too much detail to end-users.

* **Content Considerations:** In this snippet, after a successful response, we pipe the content out as a download (`attachment; filename=...`). We trust the allowed source to provide legitimate content. If additional validation of the content type or size is needed (for example, ensure itâ€™s actually a PDF or under certain size), that can be added before piping. The primary focus here is on securing the request against SSRF exploits.

With the above measures in place, our Express endpoint would have passed the earlier test cases that defeated the naive implementation. The `startsWith`-based filter was bypassable with `@` and open redirects; our new implementation isnâ€™t, because it checks the true hostname and disallows redirects entirely. In fact, using a nearly identical test suite:

* **Whitelisted domain allowed:** A normal URL to the allowed CDN succeeds (status 200 OK).
* **`@` redirect payload blocked:** The malicious `...cloudfront.net@302.r3dir.me/...` URL is rejected with a 400 and logged (our interceptor sees `hostname = 302.r3dir.me`, which is not allowed).
* **Direct external domain blocked:** A URL to `https://evil.com/...` is immediately blocked by hostname check (not in allowlist).
* **Allowed host redirecting to evil blocked:** If the allowed CDN tries to redirect (we simulate with a 302 via nock in testing), the request is not followed and we return 400.

By using proper URL parsing and enforcing policies at the HTTP client level, weâ€™ve significantly reduced the SSRF risk. But weâ€™re not done yet â€“ truly secure SSRF defense means **multiple layers** of checks.

## Defense-in-Depth: Additional Safeguards

The code-level protections above are a strong start. However, savvy attackers might still look for gaps, especially in complex real-world environments. Here are additional **defense-in-depth measures** that you (and your security team) should consider:

* **Validate DNS Resolution and IP Ranges:** Even after hostname allowlisting, itâ€™s wise to double-check where the domain resolves to. For instance, ensure the IP address of the allowed host is in a range you expect. If your server is running in a cloud environment, be mindful that some cloud hostnames could resolve to internal IPs. Implement a DNS lookup and verify the resulting IP is not a private/internal address (RFC1918 ranges, localhost, link-local, etc.) before making the request. This prevents scenarios where an allowed domain is hijacked or a DNS rebinding tricks the server into targeting an internal IP. Many languages have libraries or functions (like Pythonâ€™s `ipaddress` module or Golangâ€™s `net` package) to check if an IP is in a private network. In Node, you might use `dns.promises.lookup` and then inspect the IP. Be cautious to do the lookup *and* request in a way that avoids race conditions (the interceptor approach above could be extended with a custom DNS resolver that filters IPs).

* **Network Egress Filtering (CIDR Allow/Deny Lists):** Donâ€™t rely solely on application code to enforce SSRF protection. Network-level controls can provide a safety net. For example, if your service should only call a specific external API or CDN, configure firewall rules or a cloud security group to block all other outbound requests. Many cloud providers and container orchestration platforms allow egress restrictions. A Web Application Firewall (WAF) or API gateway can also be configured with rules to prevent traffic to internal IP ranges, adding another layer of defense beyond the app logic.

* **Limit Allowed Ports and Protocols:** If your use-case is only to fetch HTTP/S on standard ports, consider restricting that. An SSRF attacker may try to hit non-HTTP services (like `http://target:22/` to check an SSH server banner, or other ports for port scanning). Your HTTP client might not speak those protocols, but even connecting can yield information. You can often specify allowed ports or disallow non-80/443 in your allowlist policy. Some frameworks let you enforce this in the URL parser (for example, by checking `u.port` or requiring `u.port` is blank or 443/80 if `https/http`). Similarly, ensure only `http` and `https` schemes â€“ no `ftp:`, no `file:` â€“ are ever accepted.

* **Logging and Alerting:** Treat SSRF attempt logs as high-severity events. In our code above, we do `console.error` logging when a download is blocked. In production, youâ€™d want to funnel such logs to a monitoring system. If you see repeated â€œBlocked hostname: 169.254.169.254â€ or the like, thatâ€™s a red flag someone is probing for SSRF. Set up alerts for these patterns. Comprehensive access logs that include the requested URL (or at least the domain) can help incident response trace what an attacker tried to do. Remember that sometimes SSRF is blind (the attacker doesnâ€™t get the response directly), so they might be fuzzing your endpoint and watching side-effects. Good logging might be your only clue something is amiss.

* **Security Testing and Automation:** Given the myriad ways to bypass SSRF filters, itâ€™s important to **continuously test** your defenses. Incorporate SSRF test cases into your QA or CI/CD pipeline. For example, the test suite we showed earlier programmatically tries an `@` payload and an open redirect to ensure the server returns 400, not 200. You can leverage security scanning tools or write unit tests for your validation logic. Static analysis can help too â€“ for instance, using Semgrep or CodeQL queries to detect any use of dangerous patterns (like raw `axios.get(userInput)` without validation). Organizations should also perform periodic penetration testing. Tools like Burp Suite have SSRF payload lists and can automate trying dozens of variants (encoded IPs, etc.) against your endpoints. Make sure your â€œsafeâ€ code actually holds up against these.

* **Keep Dependencies and Knowledge Updated:** The ecosystem around SSRF is evolving. New bypass tricks get discovered (for example, novel URL parsing quirks in different languages or odd behavior in cloud metadata services). Stay updated on security advisories â€“ for instance, the **`nossrf` npm package** was created to prevent SSRF, but even it had a critical bypass discovered. Always use the latest patched versions of any libraries or packages related to URL fetching, and review their changelogs for security fixes. And of course, never disable critical protections like certificate verification on your HTTP client â€“ doing so could let an attacker intercept your â€œsafeâ€ requests or present fake certificates.

In essence, **defense-in-depth means assuming one layer of defense *could* fail**, so you have others to mitigate the impact. We saw how relying just on a prefix check failed; combining hostname + protocol + redirect controls in the code made it much harder to bypass. Adding network rules and continuous testing makes it harder still. The more hurdles an attacker has to jump through, the more likely theyâ€™ll give up or slip up and get detected.

## Conclusion: Never Trust a â€œOne-Size-Fits-Allâ€ SSRF Fix

> **There is no silver bullet.**
>
> Not in folklore. Not in security.
> Security isnâ€™t a one-liner â€” itâ€™s a process: Think. Test. Break. Fix. Repeat.


SSRF vulnerabilities teach us a broader lesson in software security: **beware of silver-bullet fixes.** If you find a code snippet online claiming â€œjust do X to fix SSRFâ€ without accounting for edge cases, be skeptical. Weâ€™ve highlighted how even widely suggested or **â€œsecureâ€ patches can be incomplete** â€“ from ChatGPT-Next-Webâ€™s initial fix being bypassed to the simple allowlist that failed against `@` and redirect tricks. Attackers think outside the box, so our defenses must as well.

---

## SSRF Defense Lab: Practical Testbed

Looking to verify your SSRF defenses in practice? Check out the open-source [SSRF Defense Lab](https://github.com/windshock/ssrf-defense-lab) I created:

- ğŸ§ª Minimal, self-contained Node.js/Express testbed for SSRF security
- ğŸ”§ Secure and vulnerable router examples with real bypass test cases
- ğŸ› ï¸ Automated test utilities for CDN/domain allowlisting, redirect bypass, and more
- ğŸ“‹ All tests must pass for a router to be considered secure

**Project highlights:**
- Reusable SSRF security test utilities
- Secure/vulnerable router code and tests
- Covers common bypasses: `@` tricks, open redirects, non-whitelisted domains
- Easy to run: `npm install && npm test`

Source & docs: [github.com/windshock/ssrf-defense-lab](https://github.com/windshock/ssrf-defense-lab)

---

For developers and security engineers, the key takeaways are:

## Key Takeaways

- **Always validate and sanitize user-controlled URLs.** Rely on proven libraries for parsingâ€”never trust raw string checks.
- **Layer your defenses.** Combine hostname allowlists, protocol checks, DNS/IP validation, and strict redirect handling.
- **Test like an attacker.** Challenge your own defenses with real-world bypass payloads and automated tests.
- **Adopt defense-in-depth.** Use both application logic and network-layer controls to reduce risk and monitor for abuse.
- **Stay ahead of new tricks.** Security is never finishedâ€”keep learning, updating, and adapting.

Preventing SSRF isnâ€™t about a single fixâ€”itâ€™s about building resilient, layered defenses and never letting your guard down. Be proactive: review, test, and challenge your solutions regularly. If you donâ€™t, someone else surely will. Secure by design, and let your defenses grow stronger with every lesson learned.

## References

- [Bypassing SSRF Filters Using r3dir â€” Leviathan Security](https://www.leviathansecurity.com/blog/bypassing-ssrf-filters-using-r3dir)
- [Server-side request forgery (Wikipedia)](https://en.wikipedia.org/wiki/Server-side_request_forgery)
- [Silver Bullet â€“ Archive.org](https://archive.org/details/silverbulletothe0000unse)
- [Snyk Blog: Preventing SSRF in Node.js](https://snyk.io/blog/preventing-ssrf-node-js/)
- [GitHub Patch (NextChat)](https://github.com/ChatGPTNextWeb/NextChat/commit/9fb8fbcc65c29c74473a13715c05725e2b49065d)
- [NextChat SSRF Advisory (GitHub)](https://github.com/ChatGPTNextWeb/NextChat/security/advisories/GHSA-gph5-rx77-3pjg)
- [SSRF Defense Lab (GitHub)](https://github.com/windshock/ssrf-defense-lab)
