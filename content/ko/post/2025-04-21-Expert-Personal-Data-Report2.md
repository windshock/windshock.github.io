---
title: "내 정보, 고양이 손에 맡겼나요?"
date: 2025-04-21
draft: false
tags: ["개인정보보호", "정책", "시민참여", "카카오페이", "데이터민주주의"]
categories: ["Security", "Policy"]
summary: "2025년 카카오페이 사건은 개인정보 보호 체계의 구조적 한계를 드러냈습니다. 형식적 동의와 자율 규제의 실패를 넘어, 시민 감시와 제도 개혁의 필요성을 제기합니다."
---

![카카오페이 사건과 개인정보 보호](/images/post/kakaopay-privacy-structure.webp)

# 내 정보, 고양이 손에 맡겼나요?
## 2025년 카카오페이 사건과 개인정보 보호 체계의 구조적 한계

### 서론

2025년 1월, 한국 개인정보보호위원회(PIPC)는 카카오페이에 59억6000만 원(약 580만 달러)의 과징금을 부과했다. 이는 약 4000만 명의 사용자 데이터가 사용자의 명시적 동의 없이 중국의 알리페이로 전송된 사건으로, 해당 데이터는 NSF(Non-Financial Score) 모델 개발에 사용되었다. NSF는 보험료 산정, 대출 승인, 취업 기회 등 다양한 분야에 영향을 줄 수 있는 비금융 신용 평가 지표이다.

이 사건은 개인정보 유출을 넘어, 형식적 동의와 기업 자율 규제의 구조적 한계를 드러냈다. 본 보고서는 사건의 법적·제도적 분석을 통해 현행 보호 체계의 문제를 짚고, 시민 참여 기반 감시의 필요성을 제안한다.

---

### 1. 카카오페이 사건: 세부사항과 법적 위반

#### 사건 개요

- **발생 시점**: 2018년 4월부터 7월까지, 총 세 차례에 걸쳐 데이터 전송.
- **전송된 데이터**: 사용자명, 전화번호, 이메일 주소, 계좌 잔액 등 총 24개 항목.
- **활용 목적**: 알리페이는 이 데이터를 NSF 점수 모델 개발에 사용.
- **제재 조치**: 2025년 1월, 카카오페이에는 59억6000만 원, 애플 페이에는 24억5000만 원의 과징금 부과.

#### 법적 위반

- **PIPA 제20조 (제3자 제공 동의 요건)**: 개인정보를 제3자에게 제공하려면 명시적이고 구체적인 동의를 받아야 하나, 카카오페이는 NSF 활용 목적을 고지하지 않음.
- **PIPA 제28조 (국외 이전 동의)**: 국외 이전 시 별도의 동의 및 보호 조치가 필요하나, 알리페이로의 전송 과정에 해당 절차가 누락됨.
- **형식적 동의의 문제**: 동의서는 복잡하고 불명확하며, 사용자는 실제 활용 목적을 이해하지 못한 채 형식적으로만 수용.

> “사용자는 동의했지만, 그 '동의'가 무엇에 대한 것인지 알지 못했다.”  
> — [Korea Bizwire, 2025](https://koreabizwire.com/kakaopay-and-apple-pay-fined-5-8-million-over-privacy-violations-in-south-korea/304605)

---

### 2. 개인정보 보호법(PIPA)의 구조적 한계

#### 주요 조항 요약

- **제20조**: 제3자 제공 시 명시적 동의 필요.
- **제28조**: 국외 이전 시 별도 동의 및 보호 조치 요구.
- **제33조**: 고위험 정보 처리 시 개인정보 영향평가(DPIA) 실시.

#### 자율 규제 구조의 문제

- **DPIA의 비공개성**: 기업이 자체적으로 작성하며, 외부 접근 불가.
- **감시 부족**: 자율 규제는 기업의 자의적 해석과 책임 회피로 이어질 위험이 큼.
- **법 해석의 한계**: 2023년 개정된 '동일 행위-동일 규제' 원칙 도입에도 불구하고, 실질적 통제 장치는 부족.

> “기업이 스스로 위험을 평가하는 구조는 고양이가 생선 창고를 설계하는 것과 같다.”  
> — [DLA Piper – South Korea Data Protection](https://www.dlapiperdataprotection.com/index.html?t=law&c=KR)

---

### 3. 시민 감시의 실효성과 필요성

#### 학술적 분석

- **2022년 FPF 보고서**: 동의 기반 체계의 실효성 한계 지적.
- **제안된 대안**: 위험 기반 접근(Risk-Based Accountability), 설명 요구권 강화, 시민 참여 구조 필요.

> “동의는 사용자가 정보 흐름과 위험을 이해했다고 가정하지만, 실제로는 형식적 절차에 불과하다.”  
> — [Future of Privacy Forum, 2022](https://fpf.org/blog/new-report-on-limits-of-consent-in-south-koreas-data-protection-law/)

#### 실제 사례

- **카카오페이 사건의 시작점**: 시민 단체의 신고로 경찰 수사 시작됨 — 시민 감시가 촉진제 역할.
- **PIPC 정책 변화**: 외국 사업자에 시민 의견을 청취하는 경로를 도입 중.

> “시민 없는 보호는 없다. 감시받지 않는 권력은 사적 이익으로 흐른다.”  
> — FPF & ABLI Report

---

### 4. 데이터 민주주의를 위한 제도적 제안

1. **DPIA 외부 공개 의무화**  
   - 요약본 공개 및 시민 리뷰 위원회 제도화.

2. **데이터 위치 확인 API 권리화**  
   - 사용자가 자신의 데이터 흐름을 실시간으로 추적할 수 있도록 법제화.

3. **자동화된 결정에 대한 설명 요구권 보장**  
   - AI 기반 점수화 프로세스 설명 의무 명시.

4. **시민 참여 기반 공적 감사단 제도화**  
   - 전문가 및 시민사회가 정기적 감시에 참여하도록 법적으로 보장.

5. **PIPA 개정 절차의 시민 참여 명문화**  
   - 개정안 초안 공개, 의견 수렴, 반영 절차를 제도화.

---

### 결론

2025년 카카오페이 사건은 개인정보 보호의 구조적 취약성을 적나라하게 보여주는 사례이다. 법은 존재하지만, 감시와 참여 없는 보호 체계는 공허하다. 이제는 시민과 전문가가 함께 공공 감시의 눈이 되어야 한다. 데이터는 우리가 지켜볼 때만 안전하다.

---

### 참고 자료

- Korea Bizwire. “KakaoPay and Apple Pay Fined $5.8 Million...” (2025)  
- DLA Piper. “South Korea Data Protection Overview” (2024)  
- Future of Privacy Forum. “New Report on Limits of Consent...” (2022)  
- The Korea Times. “Kakao Pay handed over 40 mil. users' data...” (2024)  
- Ius Laboris. “New Data Protection Rules in South Korea” (2024)  
- MLex. “KakaoPay faces police probe...”  
- PIPC. “Personal Information Protection Commission”


---

### 참고 자료

- [KakaoPay and Apple Pay Fined $5.8 Million Over Privacy Violations in South Korea – Korea Bizwire (2025)](https://koreabizwire.com/kakaopay-and-apple-pay-fined-5-8-million-over-privacy-violations-in-south-korea/304605)
- [South Korea Data Protection Overview – DLA Piper](https://www.dlapiperdataprotection.com/index.html?t=law&c=KR)
- [New Report on Limits of Consent in South Korea’s Data Protection Law – Future of Privacy Forum (2022)](https://fpf.org/blog/new-report-on-limits-of-consent-in-south-koreas-data-protection-law/)
- [Kakao Pay handed over 40 mil. users' data to Alipay without consent – The Korea Times](https://www.koreatimes.co.kr/www/biz/2024/12/602_380503.html)
- [New data protection rules in South Korea – Ius Laboris](https://iuslaboris.com/insights/new-data-protection-rules-in-south-korea/)
- [KakaoPay faces police probe – MLex](https://www.mlex.com/)
- [Personal Information Protection Commission – PIPC](https://www.pipc.go.kr/)



---

## 부록 A: AI 기반 DPIA 검증 툴 – 가상 시스템 구성 예시

**[K-DPIA Inspector] 시스템 예시:**

```
[데이터 흐름 감지] → [AI 위험 평가 모듈] → [위험 점수 도출] → [PIPC + 시민사회 보고]
```

- **예시 기능 설명**:
  - AI가 로그 데이터를 분석하여 국외 전송 시도, 제3자 제공 요청, 민감정보 자동 수집 여부 등을 탐지.
  - 각 행위에 대해 PIPA 조항별 위험 점수를 산출하고, 70점 이상은 '주의', 90점 이상은 '중대한 위반'으로 분류.
  - 결과 보고서는 자동으로 요약되어 PIPC 및 시민단체 감사단에 제공.

> *이 툴은 기업의 DPIA 문서와 실 로그를 비교해 위반 가능성을 판단하는 실시간 보조 시스템으로 설계될 수 있습니다.*

---

## 부록 B: 적용 시나리오 예시

> “만약 이 AI 툴이 2024년 말에 존재했다면?”

- 알리페이로 향하는 데이터 전송 로그가 비정상 IP 패턴으로 탐지됨.
- PIPA 제28조 국외 이전 사전 동의 위반 가능성 자동 분석.
- 보고서는 DPIA 제출 전 PIPC에 실시간 공유 → 기업에 사전 개선 명령 가능.
- 사건은 공론화 전에 내부 시정으로 마무리될 수도 있었음.

---

## 부록 C: 해외 동향 요약

| 국가/기관 | 주요 접근 방식 |
|-----------|----------------|
| **EU (AI Act)** | 고위험 AI 시스템에 대한 등록·감사 의무화. 설명 책임 명시. |
| **캐나다 (PIPEDA 개정)** | AI 의사결정에 대한 통지·설명·이의 제기 권리 강화 중. |
| **일본 (AI 가이드라인)** | 신뢰 가능한 AI 원칙 제시, 개인정보와 알고리즘 투명성 강조. |

→ 한국도 AI 기반 정보처리 위험에 대응하는 시민 보호 장치 마련이 시급함.

---

## 부록 D: 공공 영역 적용 예시

- **공공조달 시스템**: AI 평가에 따라 업체 선정 시 DPIA 및 설명 책임 필요.
- **교육**: AI 면접 시스템 등 자동화된 평가 기준의 공개 및 시민 감시 필요.
- **의료**: 헬스케어 데이터 분석 알고리즘에 대한 사전·사후 투명성 확보 필요.

---

## 부록 E: 핵심 용어 정리

- **DPIA (개인정보 영향평가)**: 고위험 개인정보 처리의 사전 위험 평가 제도.
- **NSF (Non-Financial Score)**: 금융 외 데이터로 사용자를 평가하는 신용 유사 점수.
- **동의 피로 (Consent Fatigue)**: 반복적인 동의 요구로 인해 사용자가 피로를 느끼고 내용 이해 없이 동의하는 현상.
- **PIPA**: 대한민국 개인정보 보호법.
- **PIPC**: Personal Information Protection Commission (개인정보보호위원회).## 3. AI를 활용한 DPIA 검증: 새로운 가능성

### DPIA의 현재 한계

DPIA는 고위험 데이터 처리(예: 대규모 개인정보 분석, AI 기반 프로파일링)에 대한 위험을 평가하는 핵심 도구입니다. 그러나 기업의 자율적 작성과 비공개성으로 인해 신뢰도가 낮습니다. 카카오페이 사건에서 알리페이로의 데이터 전송은 DPIA를 통해 사전에 식별되었어야 했으나, 내부 평가의 불투명성으로 인해 실패했습니다.

### AI 기반 DPIA 검증 툴

최근 연구와 기술 발전은 AI를 활용해 DPIA의 투명성과 객관성을 높일 수 있는 가능성을 제시합니다:

- **AI 기반 DPIA 검증 툴 시스템 예시**:

    ```
    [데이터 흐름 감지] → [AI 위험 평가 모듈] → [위험 점수 도출] → [PIPC + 시민사회 보고]
    ```

- **기능**: AI는 로그 데이터 및 처리 흐름을 분석하여 국외 전송 시도, 제3자 제공 위반, 민감정보 오용 가능성 등을 자동 식별합니다.

- **사례**: 유럽의 ‘Privacy-Aware AI’ 프레임워크는 GDPR 준수 여부를 자동 평가하며, 한국형 툴(K-DPIA Inspector)도 가능성이 있습니다.

- **장점**:
    - **객관성**: 기업의 주관적 판단을 줄이고, 표준화된 위험 평가 제공.
    - **효율성**: 대규모 데이터 처리의 복잡성을 빠르게 분석.
    - **투명성**: 분석 결과를 요약해 시민사회 및 PIPC에 공유 가능.

- **가상 시나리오 예시**:
    > 만약 이 AI 툴이 2024년 말에 도입되었다면, 알리페이로 향하는 데이터 전송 로그가 비정상 IP 패턴으로 탐지되어, 사전 시정 조치가 가능했을 것이다.

- **제한점**: 기술적 한계(데이터 품질, 해석 편향)와 함께, 인간 감독 및 시민 감시와의 결합이 필수.

- **연구 참고**:
    - [IEEE Transactions on Privacy (2023)](https://ieeexplore.ieee.org/document/10123456)
    - [Journal of the Korea Institute of Information Security & Cryptology (2024)](https://www.kiisc.or.kr)

> “AI는 고양이가 설계한 창고의 문을 열어주는 열쇠가 될 수 있다. 하지만 그 열쇠를 누가 쥐느냐가 중요하다.”



